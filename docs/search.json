[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Welcome!",
    "text": "Welcome!\nWelcome to Ecosystem Science and Sustainability 523c: Environmental Data Science Applications: Water Resources! This class is meant to build on the technical skills you learned in ESS 523a, with a focus on water resource examples. We will cover a range of topics, including data science tools, working with vector and raster data, and machine learning."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis website, including all slides, are made with Quarto. Please submit an issue on the GitHub repo for this course if you find something that could be fixed or improved.\nWe borrow significant content from the amazing R community and do our best to curate and design course content for students."
  },
  {
    "objectID": "index.html#reuse-and-licensing",
    "href": "index.html#reuse-and-licensing",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Reuse and licensing",
    "text": "Reuse and licensing\n\nUnless otherwise noted (i.e.¬†not an original creation and reused from another source), these educational materials are licensed under Apache 2."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Schedule",
    "text": "Schedule\n\nComponent 1: Data Science Tools\n Week 01: Level Setting\n Tech Talk 01: Quarto/Flextable\n Lab 01: Lab 1: COVID Trends\n\n\n\nComponent 2: Working with Vector Data\n Week 02: Projections & Measures\n Tech Talk 02: Interactive Mapping\n Lab 02: Lab 2: Border summaries\n Lab 02: Lab 2: Hints & Tricks\n\n Week 03: Predicates, Simplification $ Tesselations\n Tech Talk 03: Functions\n Lab 03: Lab 3: Dams in the US\n\n\n\nComponent 3: Working with Raster Data\n Week 04: Raster‚Äôs in R\n Tech Talk 04: STAC\nLab 04: Lab 4: Remote Sensing\n\n Week 05: Terrain Modeling\n Tech Talk 01:OSM HAND\n Lab 05: Lab 5: Terrain & Flood Modeling\n\n\n\nComponent 3: Machine Learning\n Week 06: Feature Engineering & Model Workflows\n Tech Talk 08: Model Options\n Lab 06: Lab 6: CAMELS Data Part 1\n\n Week 07: Model Evaluation & Tuning\n Tech Talk 07: Wrap up\n Lab 07: Lab 6: CAMELS Data Part 2"
  },
  {
    "objectID": "index.html#component-1-data-science-tools",
    "href": "index.html#component-1-data-science-tools",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 1: Data Science Tools",
    "text": "Component 1: Data Science Tools\n Week 01: Level Setting  Lab 01: COVID Trends"
  },
  {
    "objectID": "index.html#component-2-working-with-vector-data",
    "href": "index.html#component-2-working-with-vector-data",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 2: Working with Vector Data",
    "text": "Component 2: Working with Vector Data\n Week 02: Projections & Measures  Lab 02: 100 mile border zone\n Week 03: Predicates & Tesselations  Lab 03: Dams in the US"
  },
  {
    "objectID": "index.html#component-3-working-with-raster-data",
    "href": "index.html#component-3-working-with-raster-data",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 3: Working with Raster Data",
    "text": "Component 3: Working with Raster Data\n Week 04: Raster‚Äôs in R  Lab 04: Remote Sensing\n Week 05: Terrain Mapping  Lab 05: Terrain & Flood Modeling"
  },
  {
    "objectID": "index.html#component-3-machine-learning",
    "href": "index.html#component-3-machine-learning",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 3: Machine Learning",
    "text": "Component 3: Machine Learning\nBuild confidence in wrangling, visualizing, and analyzing data. This section covers importing and cleaning data sets, working with joins, and creating effective visualizations. You‚Äôll also delve into study design, hypothesis testing, and statistical analyses spanning uni-variate, bivariate, and multivariate techniques.\n Week 06: Feature Engineering & Model Setup  Lab 06: \n Week 07:   Lab 07:"
  },
  {
    "objectID": "slides/week-1.html#getting-started-with-r-for-data-science",
    "href": "slides/week-1.html#getting-started-with-r-for-data-science",
    "title": "Week 1",
    "section": "üöÄ Getting Started with R for Data Science",
    "text": "üöÄ Getting Started with R for Data Science\n\nWelcome to 523C: Environmental Data Science Applications: Water Resources!\nThis first lecture will introduce essential, high-level topics to help you build a strong foundation in R for environmental data science.\nThroughout the lecture, you will be asked to assess your comfort level with various topics via a Google survey.\nThe survey results will help tailor the course focus, ensuring that we reinforce challenging concepts while avoiding unnecessary review of familiar topics."
  },
  {
    "objectID": "slides/week-1.html#google-survey",
    "href": "slides/week-1.html#google-survey",
    "title": "Week 1",
    "section": "Google Survey",
    "text": "Google Survey\n\nPlease open this survey and answer the questions as we work through this lecture.\nYour responses will provide valuable insights into areas where additional explanations or hands-on exercises may be beneficial.\n\nGoogle Survey"
  },
  {
    "objectID": "slides/week-1.html#data-types",
    "href": "slides/week-1.html#data-types",
    "title": "Week 1",
    "section": "Data Types",
    "text": "Data Types\nR has five principal data types (excluding raw and complex):\n\nCharacter: A string of text, represented with quotes (e.g., ‚Äúhello‚Äù).\n\nUsed to store words, phrases, and categorical data.\n\nInteger: A whole number, explicitly defined with an L suffix (e.g., 42L).\n\nStored more efficiently than numeric values when decimals are not needed.\n\nNumeric: A floating-point number, used for decimal values (e.g., 3.1415).\n\nThis is the default type for numbers in R.\n\nBoolean (Logical): A logical value that represents TRUE or FALSE.\n\nCommonly used in logical operations and conditional statements.\n\n\n\ncharacter &lt;- \"a\"\ninteger &lt;- 1L\nnumeric &lt;- 3.3\nboolean &lt;- TRUE"
  },
  {
    "objectID": "slides/week-1.html#data-structures",
    "href": "slides/week-1.html#data-structures",
    "title": "Week 1",
    "section": "Data Structures",
    "text": "Data Structures\n\nWhen working with multiple values, we need data structures to store and manipulate data efficiently.\nR provides several types of data structures, each suited for different use cases.\n\nVector\n\nA vector is the most basic data structure in R and contains elements of the same type.\nVectors are created using the c() function.\n\n\nchar.vec &lt;- c(\"a\", \"b\", \"c\")\nboolean.vec &lt;- c(TRUE, FALSE, TRUE)\n\n\nLists allow for heterogeneous data types.\n\n\nlist &lt;- list(a = c(1,2,3),\n            b = c(TRUE, FALSE),\n            c = \"test\")"
  },
  {
    "objectID": "slides/week-1.html#installing-packages",
    "href": "slides/week-1.html#installing-packages",
    "title": "Week 1",
    "section": "üì¶ Installing Packages",
    "text": "üì¶ Installing Packages\n\nR has a vast ecosystem of packages that extend its capabilities both on CRAN and github\nTo install a package from CRAN, use install.packages().\nTo install a package from Github, use remotes::install_github()`.\nWe‚Äôll start by installing palmerpenguins, which contains a dataset on penguins.\n\n\ninstall.packages('palmerpenguins')"
  },
  {
    "objectID": "slides/week-1.html#attachingloading-packages",
    "href": "slides/week-1.html#attachingloading-packages",
    "title": "Week 1",
    "section": "Attaching/Loading Packages",
    "text": "Attaching/Loading Packages\n\nTo use an installed package, you need to load it in your current working session using library().\nHere, we load palmerpenguins for dataset exploration and tidyverse for data science workflows.\n\n\nlibrary(palmerpenguins) # üêß Fun dataset about penguins!\nlibrary(tidyverse)      # üõ† Essential for data science in R"
  },
  {
    "objectID": "slides/week-1.html#help-documentation",
    "href": "slides/week-1.html#help-documentation",
    "title": "Week 1",
    "section": "Help & Documentation",
    "text": "Help & Documentation\n\nR has built-in documentation that provides information about functions and datasets.\nTo access documentation, use ?function_name.\nExample: Viewing the help page for the penguins dataset.\n\n\n?penguins\n\n\nYou can also use help.search(\"keyword\") to look up topics of interest.\nFor vignettes (detailed guides), use vignette(\"package_name\")."
  },
  {
    "objectID": "slides/week-1.html#quarto-communication",
    "href": "slides/week-1.html#quarto-communication",
    "title": "Week 1",
    "section": "Quarto: Communication",
    "text": "Quarto: Communication\n\nIn this class we will use Quarto, a more modern, cross langauge version of Rmarkdown\nIf you are comfortable with Rmd, you‚Äôll quickly be able to transition to Qmd\nIf you are new to Rmd, you‚Äôll be able to learn the latest and greatest"
  },
  {
    "objectID": "slides/week-1.html#tidyverse-a-swiss-army-knife-for-data-science-r",
    "href": "slides/week-1.html#tidyverse-a-swiss-army-knife-for-data-science-r",
    "title": "Week 1",
    "section": "üåü Tidyverse: A Swiss Army Knife for Data Science R ",
    "text": "üåü Tidyverse: A Swiss Army Knife for Data Science R \n\nThe tidyverse is a collection of packages designed for data science.\nWe can see what it includes using the tidyverse_packages function:\n\n\ntidyverse_packages()\n#&gt;  [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n#&gt;  [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n#&gt;  [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n#&gt; [13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n#&gt; [17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n#&gt; [21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n#&gt; [25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n#&gt; [29] \"tidyr\"         \"xml2\"          \"tidyverse\""
  },
  {
    "objectID": "slides/week-1.html#glimpse",
    "href": "slides/week-1.html#glimpse",
    "title": "Week 1",
    "section": "glimpse ",
    "text": "glimpse \n\nThe glimpse() function provides a concise summary of a dataset.\n\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "slides/week-1.html#readr",
    "href": "slides/week-1.html#readr",
    "title": "Week 1",
    "section": "readr ",
    "text": "readr \n\nThe readr package provides functions for reading data into R.\nThe read_csv() function reads comma-separated files.\nThe read_tsv() function reads tab-separated files.\nThe read_delim() function reads files with custom delimiters.\nIn all cases, more intellegent parsing is done than with base R equivalents.\n\nread_csv \n\npath = 'https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv'\n\n# base R\nread.csv(path) |&gt; \n  head()\n#&gt;    fips        LON      LAT\n#&gt; 1  1061  -85.83575 31.09404\n#&gt; 2  8125 -102.42587 40.00307\n#&gt; 3 17177  -89.66239 42.35138\n#&gt; 4 28153  -88.69577 31.64132\n#&gt; 5 34041  -74.99570 40.85940\n#&gt; 6 46051  -96.76981 45.17255\n\n# More inutitive readr\nread_csv(path) |&gt; \n  head()\n#&gt; # A tibble: 6 √ó 3\n#&gt;   fips     LON   LAT\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 01061  -85.8  31.1\n#&gt; 2 08125 -102.   40.0\n#&gt; 3 17177  -89.7  42.4\n#&gt; 4 28153  -88.7  31.6\n#&gt; 5 34041  -75.0  40.9\n#&gt; 6 46051  -96.8  45.2"
  },
  {
    "objectID": "slides/week-1.html#dplyr",
    "href": "slides/week-1.html#dplyr",
    "title": "Week 1",
    "section": "dplyr ",
    "text": "dplyr \n\nThe dplyr package provides functions for data manipulation throuhg ‚Äòa grammar for data manipulation‚Äô.\nIt provides capabilities similar to SQL for data manipulation.\nIt includes functions for viewing, filtering, selecting, mutating, summarizing, and joining data."
  },
  {
    "objectID": "slides/week-1.html#left_join",
    "href": "slides/week-1.html#left_join",
    "title": "Week 1",
    "section": "left_join ",
    "text": "left_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  left_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#right_join",
    "href": "slides/week-1.html#right_join",
    "title": "Week 1",
    "section": "right_join ",
    "text": "right_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#inner_join",
    "href": "slides/week-1.html#inner_join",
    "title": "Week 1",
    "section": "inner_join ",
    "text": "inner_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#full_join",
    "href": "slides/week-1.html#full_join",
    "title": "Week 1",
    "section": "full_join ",
    "text": "full_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#ggplot2-visualization",
    "href": "slides/week-1.html#ggplot2-visualization",
    "title": "Week 1",
    "section": "ggplot2: Visualization ",
    "text": "ggplot2: Visualization \n\nThe ggplot2 package is used for data visualization.\nIt is based on the ‚Äúgrammar of graphics‚Äù, which allows for a high level of customization.\nggplot2 is built on the concept of layers, where each layer adds a different element to the plot."
  },
  {
    "objectID": "slides/week-1.html#tidyr",
    "href": "slides/week-1.html#tidyr",
    "title": "Week 1",
    "section": "tidyr ",
    "text": "tidyr \n\nThe tidyr package provides functions for data reshaping.\nIt includes functions for pivoting and nesting data."
  },
  {
    "objectID": "slides/week-1.html#drop_na",
    "href": "slides/week-1.html#drop_na",
    "title": "Week 1",
    "section": "drop_na",
    "text": "drop_na\n\nThe drop_na() function is used to remove rows with missing values.\n\n\npenguins |&gt; \n  drop_na()\n#&gt; # A tibble: 333 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  5 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  6 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  7 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  8 Adelie  Torgersen           41.1          17.6               182        3200\n#&gt;  9 Adelie  Torgersen           38.6          21.2               191        3800\n#&gt; 10 Adelie  Torgersen           34.6          21.1               198        4400\n#&gt; # ‚Ñπ 323 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nnest / unnest\n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;"
  },
  {
    "objectID": "slides/week-1.html#broom",
    "href": "slides/week-1.html#broom",
    "title": "Week 1",
    "section": "broom ",
    "text": "broom \n\nThe broom package is used to tidy model outputs.\nIt provides functions to convert model outputs into tidy data frames.\nExample: Tidying the model output."
  },
  {
    "objectID": "slides/week-1.html#purr",
    "href": "slides/week-1.html#purr",
    "title": "Week 1",
    "section": "purr",
    "text": "purr\n\nThe purrr package is used for functional programming.\nIt provides functions for working with lists and vectors.\n\nmap\n\nThe map() function is used to apply a function to each element of a list.\nIt is useful when you want to iterate over a list.\nExample: Fitting a linear model to each species in the penguins dataset.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)))\n#&gt; # A tibble: 3 √ó 3\n#&gt;   species   data               lm    \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;\n\nmap_*\n\nThe map_*() functions are used to extract specific outputs from a list.\nThey are useful when you want to extract specific outputs from a list.\nExample: Extracting the R-squared values (doubles) from the linear models.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm, ~summary(.x)$r.squared))\n#&gt; # A tibble: 3 √ó 4\n#&gt;   species   data               lm        r2\n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;   0.219\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;   0.494\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412\n\nmap2\n\nThe map2() function is used to iterate over two lists in parallel.\nIt is useful when you want to apply a function to two lists simultaneously.\nExample: Augmenting the linear models with the original data.\n\n\npenguins |&gt; \n  drop_na() |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm_mod = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm_mod, ~summary(.x)$r.squared),\n         a  = map2(lm_mod, data, ~broom::augment(.x, .y))) \n#&gt; # A tibble: 3 √ó 5\n#&gt;   species   data               lm_mod    r2 a                  \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt; &lt;list&gt;             \n#&gt; 1 Adelie    &lt;tibble [146 √ó 7]&gt; &lt;lm&gt;   0.216 &lt;tibble [146 √ó 13]&gt;\n#&gt; 2 Gentoo    &lt;tibble [119 √ó 7]&gt; &lt;lm&gt;   0.506 &lt;tibble [119 √ó 13]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412 &lt;tibble [68 √ó 13]&gt;"
  },
  {
    "objectID": "slides/week-1.html#unit-3-machine-learning",
    "href": "slides/week-1.html#unit-3-machine-learning",
    "title": "Week 1",
    "section": "Unit 3: Machine Learning",
    "text": "Unit 3: Machine Learning\n\nlibrary(tidymodels)\ntidymodels_packages()\n#&gt;  [1] \"broom\"        \"cli\"          \"conflicted\"   \"dials\"        \"dplyr\"       \n#&gt;  [6] \"ggplot2\"      \"hardhat\"      \"infer\"        \"modeldata\"    \"parsnip\"     \n#&gt; [11] \"purrr\"        \"recipes\"      \"rlang\"        \"rsample\"      \"rstudioapi\"  \n#&gt; [16] \"tibble\"       \"tidyr\"        \"tune\"         \"workflows\"    \"workflowsets\"\n#&gt; [21] \"yardstick\"    \"tidymodels\""
  },
  {
    "objectID": "slides/week-1.html#seeds-for-reproducability",
    "href": "slides/week-1.html#seeds-for-reproducability",
    "title": "Week 1",
    "section": "Seeds for reproducability",
    "text": "Seeds for reproducability"
  },
  {
    "objectID": "slides/week-1.html#rsamples-for-resampling-and-cross-validation",
    "href": "slides/week-1.html#rsamples-for-resampling-and-cross-validation",
    "title": "Week 1",
    "section": "rsamples for resampling and cross-validation",
    "text": "rsamples for resampling and cross-validation\n\nThe rsample package is used for resampling and cross-validation.\nIt provides functions for creating resamples and cross-validation folds.\nExample: Creating a 5-fold cross-validation object for the penguins dataset.\n\n\nset.seed(123)\n\n(penguins_split &lt;- initial_split(drop_na(penguins), prop = 0.8, strata = species))\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;265/68/333&gt;\npenguins_train  &lt;- training(penguins_split)\npenguins_test   &lt;- testing(penguins_split)\n\npenguin_folds &lt;- vfold_cv(penguins_train, v = 5)"
  },
  {
    "objectID": "slides/week-1.html#recipes-for-feature-engineering",
    "href": "slides/week-1.html#recipes-for-feature-engineering",
    "title": "Week 1",
    "section": "recipes for feature engineering ",
    "text": "recipes for feature engineering \n\nThe recipes package is used for feature engineering.\nIt provides functions for preprocessing data before modeling.\nExample: Defining a recipe for feature engineering the penguins dataset.\n\n\n# Define recipe for feature engineering\npenguin_recipe &lt;- recipe(species ~ ., data = penguins_train) |&gt;\n  step_impute_knn(all_predictors()) |&gt;         # Impute missing values\n  step_normalize(all_numeric_predictors())     # Normalize numeric features"
  },
  {
    "objectID": "slides/week-1.html#parsnip-for-model-selection",
    "href": "slides/week-1.html#parsnip-for-model-selection",
    "title": "Week 1",
    "section": "Parsnip for model selection ",
    "text": "Parsnip for model selection \n\nThe parsnip package is used for model implementation\nIt provides functions for defining models types, engines, and modes.\nExample: Defining models for logistic regression, random forest, and decision tree.\n\n\n# Define models\nlog_reg_model &lt;- multinom_reg() |&gt; \n  set_engine(\"nnet\")  |&gt; \n  set_mode(\"classification\")\n\nrf_model &lt;- rand_forest(trees = 500) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\ndt_model &lt;- decision_tree() |&gt; \n  set_mode(\"classification\")"
  },
  {
    "objectID": "slides/week-1.html#workflows-for-model-execution",
    "href": "slides/week-1.html#workflows-for-model-execution",
    "title": "Week 1",
    "section": "Workflows for model execution ",
    "text": "Workflows for model execution \n\nThe workflows package is used for model execution.\nIt provides functions for defining and executing workflows.\nExample: Creating a workflow for logistic regression.\n\n\n# Create workflow\nlog_reg_workflow &lt;- workflow() |&gt;\n  add_model(log_reg_model) |&gt;\n  add_recipe(penguin_recipe) |&gt; \n  fit_resamples(resamples = penguin_folds, \n                metrics = metric_set(roc_auc, accuracy))"
  },
  {
    "objectID": "slides/week-1.html#yardstick-for-model-evaluation",
    "href": "slides/week-1.html#yardstick-for-model-evaluation",
    "title": "Week 1",
    "section": "yardstick for model evaluation ",
    "text": "yardstick for model evaluation \n\ncollect_metrics(log_reg_workflow)\n#&gt; # A tibble: 2 √ó 6\n#&gt;   .metric  .estimator  mean     n std_err .config             \n#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy multiclass     1     5       0 Preprocessor1_Model1\n#&gt; 2 roc_auc  hand_till      1     5       0 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/week-1.html#workflowsets-for-model-comparison",
    "href": "slides/week-1.html#workflowsets-for-model-comparison",
    "title": "Week 1",
    "section": "workflowsets for model comparison ",
    "text": "workflowsets for model comparison \n\nThe workflowsets package is used for model comparison.\nIt provides functions for comparing multiple models usingthe purrr mapping paradigm\nExample: Comparing logistic regression, random forest, and decision tree models.\n\n\n(workflowset &lt;- workflow_set(list(penguin_recipe), \n                             list(log_reg_model, rf_model, dt_model)) |&gt; \n  workflow_map(\"fit_resamples\", \n               resamples = penguin_folds, \n               metrics = metric_set(roc_auc, accuracy)))\n#&gt; # A workflow set/tibble: 3 √ó 4\n#&gt;   wflow_id             info             option    result   \n#&gt;   &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 recipe_multinom_reg  &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n#&gt; 2 recipe_rand_forest   &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n#&gt; 3 recipe_decision_tree &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;"
  },
  {
    "objectID": "slides/week-1.html#model-validation",
    "href": "slides/week-1.html#model-validation",
    "title": "Week 1",
    "section": "Model Validation  ",
    "text": "Model Validation  \n\nFinally, we can validate the model on the test set\nThe augment() function is used to add model predictions and residuals to the dataset.\nThe conf_mat() function is used to create a confusion matrix.\nExample: Validating the logistic regression model on the test set.\n\n\nworkflow() |&gt; \n  # Add model and recipe\n  add_model(log_reg_model) |&gt;\n  add_recipe(penguin_recipe) |&gt;\n  # Train model\n  fit(data = penguins_train) |&gt; \n  # Fit trained model to test set\n  fit(data = penguins_test) |&gt;  \n  # Extract Predictions\n  augment(penguins_test) |&gt; \n  conf_mat(truth = species, estimate = .pred_class) \n#&gt;            Truth\n#&gt; Prediction  Adelie Chinstrap Gentoo\n#&gt;   Adelie        30         0      0\n#&gt;   Chinstrap      0        14      0\n#&gt;   Gentoo         0         0     24"
  },
  {
    "objectID": "slides/week-1.html#io",
    "href": "slides/week-1.html#io",
    "title": "Week 1",
    "section": "I/O ",
    "text": "I/O \n\nThe st_read() function is used to read spatial data.\nIt is useful when you want to import spatial data into R for local or remote files.\nExample: Reading a Major Global Rivers."
  },
  {
    "objectID": "slides/week-1.html#geometries",
    "href": "slides/week-1.html#geometries",
    "title": "Week 1",
    "section": "Geometries ",
    "text": "Geometries \n\nThe geometry column contains the spatial information.\nIt is stored as a list-column of sfc objects.\nExample: Accessing the first geometry in the rivers dataset.\n\n\nrivers$geometry[1]\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 144.8258 ymin: 61.40833 xmax: 160.7636 ymax: 68.8008\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#data-manipulation",
    "href": "slides/week-1.html#data-manipulation",
    "title": "Week 1",
    "section": "Data Manipulation ",
    "text": "Data Manipulation \n\nAll dplyr verbs work with sf objects.\nExample: Filtering the rivers dataset to include only the Mississippi River.\n\n\nmississippi &lt;- filter(rivers, SYSTEM == \"Mississippi\")\nlarimer     &lt;- filter(counties, name == \"Larimer\")"
  },
  {
    "objectID": "slides/week-1.html#measures",
    "href": "slides/week-1.html#measures",
    "title": "Week 1",
    "section": "Measures ",
    "text": "Measures \n\nThe st_length() function is used to calculate the length of a geometry.\nThe st_area() function is used to calculate the area of a geometry.\nThe st_distance() function is used to calculate the distance between two geometries.\nExample: Calculating the length of the Mississippi River and the area of Larimer County.\n\n\nst_length(mississippi)\n#&gt; Units: [m]\n#&gt; [1] 1912869 3147943 3331900 1785519\n\nst_area(larimer)\n#&gt; 6813621254 [m^2]\n\nst_distance(larimer, mississippi)\n#&gt; Units: [m]\n#&gt;          [,1]    [,2]   [,3]    [,4]\n#&gt; [1,] 116016.6 1009375 526454 1413983"
  },
  {
    "objectID": "slides/week-1.html#predicates",
    "href": "slides/week-1.html#predicates",
    "title": "Week 1",
    "section": "Predicates ",
    "text": "Predicates \n\nSpatial predicates are used to check relationships between geometries using the DE-9IM model.\nThe st_intersects() function is used to check if geometries intersect.\nThe st_filter() function is used to filter geometries based on a predicate.\n\n\n\n\nst_intersects(counties, mississippi)\n#&gt; Sparse geometry binary predicate list of length 3108, where the\n#&gt; predicate was `intersects'\n#&gt; first 10 elements:\n#&gt;  1: (empty)\n#&gt;  2: (empty)\n#&gt;  3: (empty)\n#&gt;  4: (empty)\n#&gt;  5: (empty)\n#&gt;  6: (empty)\n#&gt;  7: (empty)\n#&gt;  8: (empty)\n#&gt;  9: (empty)\n#&gt;  10: (empty)\n\n\n\nints &lt;- st_filter(counties, mississippi, .predicate = st_intersects)\n\nggplot() + \n  geom_sf(data = ints) +\n  geom_sf(data = mississippi, col = \"blue\") + \n  theme_bw()"
  },
  {
    "objectID": "slides/week-1.html#io-1",
    "href": "slides/week-1.html#io-1",
    "title": "Week 1",
    "section": "I/O ",
    "text": "I/O \n\nAny raster format that GDAL can read, can be read with rast().\nThe package loads the native GDAL src library (like sf)\nrast reads data headers, not data itself, until needed.\nExample: Reading a GeoTIF of Colorado elevation.\n\n\n(elev = terra::rast('data/colorado_elevation.tif'))\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 16893, 21395, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -1146465, -504615, 1566915, 2073705  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source      : colorado_elevation.tif \n#&gt; name        : CONUS_dem \n#&gt; min value   :     98679 \n#&gt; max value   :    439481"
  },
  {
    "objectID": "slides/week-1.html#cropmask",
    "href": "slides/week-1.html#cropmask",
    "title": "Week 1",
    "section": "Crop/Mask ",
    "text": "Crop/Mask \n\nThe crop() function is used to crop a raster to a specific extent.\nIt is useful when you want to work with a subset of the data.\ncrop extracts data (whether from a remote or local source)\nThe mask() function is used to mask a raster using a vector or other extent, keeping only the data within the mask.\nInput extents must match the CRS of the raster data\nExample: Cropping then masking the elevation raster to Larimer County.\n\n\n\n\nlarimer_5070 &lt;- st_transform(larimer, crs(elev))\n\nlarimer_elev = crop(elev, larimer_5070)\n\nplot(larimer_elev)\n\n\n\n\n\n\n\n\n\n\nlarimer_mask &lt;- mask(larimer_elev, larimer_5070)\nplot(larimer_mask)"
  },
  {
    "objectID": "slides/week-1.html#summary-algebra",
    "href": "slides/week-1.html#summary-algebra",
    "title": "Week 1",
    "section": "Summary / Algebra ",
    "text": "Summary / Algebra \n\nRasters can be added, subtracted, multiplied, and divided\nAny form of map algebra can be done with rasters\nFor example, multiplying the Larimer mask by 2\n\n\n\nraw\n\nlarimer_mask\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        : CONUS_dem \n#&gt; min value   :    145787 \n#&gt; max value   :    412773\n\n\nData Operation\n\nelev2 &lt;- larimer_mask^2\n\n\nrast modified by rast\n\nlarimer_mask / elev2\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        :    CONUS_dem \n#&gt; min value   : 2.422639e-06 \n#&gt; max value   : 6.859322e-06\n\n\nstatistical methods\n\n(scaled = scale(larimer_mask))\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        : CONUS_dem \n#&gt; min value   : -1.562331 \n#&gt; max value   :  3.053412"
  },
  {
    "objectID": "slides/week-1.html#raster-data-store",
    "href": "slides/week-1.html#raster-data-store",
    "title": "Week 1",
    "section": "Raster data store",
    "text": "Raster data store\n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#focal",
    "href": "slides/week-1.html#focal",
    "title": "Week 1",
    "section": "Focal ",
    "text": "Focal \n\nThe focal() function is used to calculate focal statistics.\nIt is useful when you want to calculate statistics for each cell based on its neighbors.\nExample: Calculating the mean elevation within a 30-cell window to remove the NAs we just created\n\n\nxx = terra::focal(larimer_elev, win = 30, fun  = \"mean\", na.policy=\"only\")\nplot(xx)"
  },
  {
    "objectID": "slides/week-1.html#drop_na-na.omit",
    "href": "slides/week-1.html#drop_na-na.omit",
    "title": "Week 1",
    "section": "drop_na / na.omit ",
    "text": "drop_na / na.omit \n\nThe drop_na() function is used to remove rows with missing values.\n\n\npenguins |&gt; \n  drop_na()\n#&gt; # A tibble: 333 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  5 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  6 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  7 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  8 Adelie  Torgersen           41.1          17.6               182        3200\n#&gt;  9 Adelie  Torgersen           38.6          21.2               191        3800\n#&gt; 10 Adelie  Torgersen           34.6          21.1               198        4400\n#&gt; # ‚Ñπ 323 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nnest / unnest \n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;"
  },
  {
    "objectID": "slides/week-1.html#unions-combines",
    "href": "slides/week-1.html#unions-combines",
    "title": "Week 1",
    "section": "Unions / Combines ",
    "text": "Unions / Combines \n\nThe st_union() function is used to combine geometries.\nIt is useful when you want to merge geometries.\n\n\nmississippi\n#&gt; Simple feature collection with 4 features and 4 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112 ymin: 28.92983 xmax: -77.86168 ymax: 48.16158\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 4 √ó 5\n#&gt;   NAME        SYSTEM      MILES KILOMETERS                              geometry\n#&gt; * &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;                 &lt;MULTILINESTRING [¬∞]&gt;\n#&gt; 1 Arkansas    Mississippi 1446.      2327. ((-106.3789 39.36165, -106.3295 39.3‚Ä¶\n#&gt; 2 Mississippi Mississippi 2385.      3838. ((-95.02364 47.15609, -94.98973 47.3‚Ä¶\n#&gt; 3 Missouri    Mississippi 2739.      4408. ((-110.5545 44.76081, -110.6122 44.7‚Ä¶\n#&gt; 4 Ohio        Mississippi 1368.      2202. ((-89.12166 36.97756, -89.17502 37.0‚Ä¶\n\nst_union(mississippi)\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112 ymin: 28.92983 xmax: -77.86168 ymax: 48.16158\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#terra",
    "href": "slides/week-1.html#terra",
    "title": "Week 1",
    "section": "terra ",
    "text": "terra \n\nThe terra package is used for working with raster data.\nIt provides functions for reading, writing, and manipulating raster data.\n\n\nlibrary(terra)\ngdal()\n#&gt; [1] \"3.10.1\""
  },
  {
    "objectID": "slides/week-1.html#dplyr-1",
    "href": "slides/week-1.html#dplyr-1",
    "title": "Week 1",
    "section": "dplyr ",
    "text": "dplyr \n\nThe dplyr package provides functions for data manipulation.\nIt includes functions for filtering, selecting, mutating, summarizing, and joining data.\n\nselect \n\nThe select() function is used to select columns from a dataset.\nIt is useful when you want to work with specific columns.\nExample: Selecting the species column from the penguins dataset.\n\n\nselect(penguins, species)\n#&gt; # A tibble: 344 √ó 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ‚Ñπ 334 more rows\n\nfilter \n\nThe filter() function is used to filter rows based on a condition.\nIt is useful when you want to work with specific rows.\nExample: Filtering the penguins dataset to include only Adelie penguins.\n\n\nfilter(penguins, species == \"Adelie\")\n#&gt; # A tibble: 152 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 142 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nmutate \n\nThe mutate() function is used to create new columns or modify existing ones.\nIt is useful when you want to add new information to your dataset.\nExample: Creating a new column bill_length_cm from bill_length_mm.\n\nNote the use of the tidy_select helper starts_with\n\nmutate(penguins, bill_length_cm = bill_length_mm / 100) |&gt; \n  select(starts_with(\"bill\"))\n#&gt; # A tibble: 344 √ó 3\n#&gt;    bill_length_mm bill_depth_mm bill_length_cm\n#&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt;  1           39.1          18.7          0.391\n#&gt;  2           39.5          17.4          0.395\n#&gt;  3           40.3          18            0.403\n#&gt;  4           NA            NA           NA    \n#&gt;  5           36.7          19.3          0.367\n#&gt;  6           39.3          20.6          0.393\n#&gt;  7           38.9          17.8          0.389\n#&gt;  8           39.2          19.6          0.392\n#&gt;  9           34.1          18.1          0.341\n#&gt; 10           42            20.2          0.42 \n#&gt; # ‚Ñπ 334 more rows\n\nsummarize \n\nThe summarize() function is used to aggregate data.\nIt is useful when you want to calculate summary statistics.\nIt always produces a one-row output.\nExample: Calculating the mean bill_length_mm for all penguins\n\n\nsummarize(penguins, bill_length_mm = mean(bill_length_mm, na.rm = TRUE))\n#&gt; # A tibble: 1 √ó 1\n#&gt;   bill_length_mm\n#&gt;            &lt;dbl&gt;\n#&gt; 1           43.9\n\ngroup_by / ungroup \n\nThe group_by() function is used to group data by one or more columns.\nIt is useful when you want to perform operations on groups.\nIt does this by adding a grouped_df class to the dataset.\nThe ungroup() function removes grouping from a dataset.\n\n\ngroups &lt;- group_by(penguins, species)\n\ndplyr::group_keys(groups)\n#&gt; # A tibble: 3 √ó 1\n#&gt;   species  \n#&gt;   &lt;fct&gt;    \n#&gt; 1 Adelie   \n#&gt; 2 Chinstrap\n#&gt; 3 Gentoo\ndplyr::group_indices(groups)[1:5]\n#&gt; [1] 1 1 1 1 1\n\nGroup operations\n\nExample: Grouping the penguins dataset by species and calculating the mean bill_length_mm.\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(bill_length_mm = mean(bill_length_mm, na.rm = TRUE)) |&gt; \n  ungroup()\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   bill_length_mm\n#&gt;   &lt;fct&gt;              &lt;dbl&gt;\n#&gt; 1 Adelie              38.8\n#&gt; 2 Chinstrap           48.8\n#&gt; 3 Gentoo              47.5\n\nJoins \n\nThe dplyr package provides functions for joining datasets.\nCommon join functions include inner_join(), left_join(), right_join(), and full_join().\nJoins are used to combine datasets based on shared keys (primary and foreign).\n\nMutating joins \n\nMutating joins add columns from one dataset to another based on a shared key.\nExample: Adding species information to the penguins dataset based on the species_id.\n\n\nspecies &lt;- tribble(\n  ~species_id, ~species,\n  1, \"Adelie\",\n  2, \"Chinstrap\",\n  3, \"Gentoo\"\n)"
  },
  {
    "objectID": "slides/week-1.html#section",
    "href": "slides/week-1.html#section",
    "title": "Week 1",
    "section": "%>% / |> ",
    "text": "%&gt;% / |&gt; \n\nThe pipe operator %&gt;% is used to chain operations in R.\nThe pipe operator |&gt; is a base R version of %&gt;% introduced in R 4.1.\nThe pipe passes what on the ‚Äúleft hand‚Äù side to the function on the ‚Äúright hand‚Äù side as the first argument.\n\n\npenguins |&gt; \n  glimpse()\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "slides/week-1.html#select",
    "href": "slides/week-1.html#select",
    "title": "Week 1",
    "section": "select ",
    "text": "select \n\nThe select() function is used to select columns from a dataset.\nIt is useful when you want to work with specific columns.\nExample: Selecting the species column from the penguins dataset.\n\n\nselect(penguins, species)\n#&gt; # A tibble: 344 √ó 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#filter",
    "href": "slides/week-1.html#filter",
    "title": "Week 1",
    "section": "filter ",
    "text": "filter \n\nThe filter() function is used to filter rows based on a condition.\nIt is useful when you want to work with specific rows.\nExample: Filtering the penguins dataset to include only Adelie penguins.\n\n\nfilter(penguins, species == \"Adelie\")\n#&gt; # A tibble: 152 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 142 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#mutate",
    "href": "slides/week-1.html#mutate",
    "title": "Week 1",
    "section": "mutate ",
    "text": "mutate \n\nThe mutate() function is used to create new columns or modify existing ones.\nIt is useful when you want to add new information to your dataset.\nExample: Creating a new column bill_length_cm from bill_length_mm.\n\nNote the use of the tidy_select helper starts_with\n\nmutate(penguins, bill_length_cm = bill_length_mm / 100) |&gt; \n  select(starts_with(\"bill\"))\n#&gt; # A tibble: 344 √ó 3\n#&gt;    bill_length_mm bill_depth_mm bill_length_cm\n#&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt;  1           39.1          18.7          0.391\n#&gt;  2           39.5          17.4          0.395\n#&gt;  3           40.3          18            0.403\n#&gt;  4           NA            NA           NA    \n#&gt;  5           36.7          19.3          0.367\n#&gt;  6           39.3          20.6          0.393\n#&gt;  7           38.9          17.8          0.389\n#&gt;  8           39.2          19.6          0.392\n#&gt;  9           34.1          18.1          0.341\n#&gt; 10           42            20.2          0.42 \n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#summarize",
    "href": "slides/week-1.html#summarize",
    "title": "Week 1",
    "section": "summarize ",
    "text": "summarize \n\nThe summarize() function is used to aggregate data.\nIt is useful when you want to calculate summary statistics.\nIt always produces a one-row output.\nExample: Calculating the mean bill_length_mm for all penguins\n\n\nsummarize(penguins, bill_length_mm = mean(bill_length_mm, na.rm = TRUE))\n#&gt; # A tibble: 1 √ó 1\n#&gt;   bill_length_mm\n#&gt;            &lt;dbl&gt;\n#&gt; 1           43.9"
  },
  {
    "objectID": "slides/week-1.html#group_by-ungroup",
    "href": "slides/week-1.html#group_by-ungroup",
    "title": "Week 1",
    "section": "group_by / ungroup ",
    "text": "group_by / ungroup \n\nThe group_by() function is used to group data by one or more columns.\nIt is useful when you want to perform operations on groups.\nIt does this by adding a grouped_df class to the dataset.\nThe ungroup() function removes grouping from a dataset.\n\n\ngroups &lt;- group_by(penguins, species)\n\ndplyr::group_keys(groups)\n#&gt; # A tibble: 3 √ó 1\n#&gt;   species  \n#&gt;   &lt;fct&gt;    \n#&gt; 1 Adelie   \n#&gt; 2 Chinstrap\n#&gt; 3 Gentoo\ndplyr::group_indices(groups)[1:5]\n#&gt; [1] 1 1 1 1 1"
  },
  {
    "objectID": "slides/week-1.html#group-operations",
    "href": "slides/week-1.html#group-operations",
    "title": "Week 1",
    "section": "Group operations ",
    "text": "Group operations \n\nExample: Grouping the penguins dataset by species and calculating the mean bill_length_mm.\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(bill_length_mm = mean(bill_length_mm, na.rm = TRUE)) |&gt; \n  ungroup()\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   bill_length_mm\n#&gt;   &lt;fct&gt;              &lt;dbl&gt;\n#&gt; 1 Adelie              38.8\n#&gt; 2 Chinstrap           48.8\n#&gt; 3 Gentoo              47.5"
  },
  {
    "objectID": "slides/week-1.html#joins",
    "href": "slides/week-1.html#joins",
    "title": "Week 1",
    "section": "Joins ",
    "text": "Joins \n\nThe dplyr package provides functions for joining datasets.\nCommon join functions include inner_join(), left_join(), right_join(), and full_join().\nJoins are used to combine datasets based on shared keys (primary and foreign)."
  },
  {
    "objectID": "slides/week-1.html#mutating-joins",
    "href": "slides/week-1.html#mutating-joins",
    "title": "Week 1",
    "section": "Mutating joins ",
    "text": "Mutating joins \n\nMutating joins add columns from one dataset to another based on a shared key.\nExample: Adding species information to the penguins dataset based on the species_id.\n\n\nspecies &lt;- tribble(\n  ~species_id, ~species,\n  1, \"Adelie\",\n  2, \"Chinstrap\",\n  3, \"Gentoo\"\n)"
  },
  {
    "objectID": "slides/week-1.html#filtering-joins",
    "href": "slides/week-1.html#filtering-joins",
    "title": "Week 1",
    "section": "Filtering Joins ",
    "text": "Filtering Joins \n\nFiltering joins retain only rows that match between datasets.\nExample: Filtering the penguins dataset to include only rows with matching species_id.\n\n\nselect(penguins, species, contains('bill')) |&gt; \n  semi_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 3\n#&gt;    species bill_length_mm bill_depth_mm\n#&gt;    &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7\n#&gt;  2 Adelie            39.5          17.4\n#&gt;  3 Adelie            40.3          18  \n#&gt;  4 Adelie            NA            NA  \n#&gt;  5 Adelie            36.7          19.3\n#&gt;  6 Adelie            39.3          20.6\n#&gt;  7 Adelie            38.9          17.8\n#&gt;  8 Adelie            39.2          19.6\n#&gt;  9 Adelie            34.1          18.1\n#&gt; 10 Adelie            42            20.2\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#ggplot",
    "href": "slides/week-1.html#ggplot",
    "title": "Week 1",
    "section": "ggplot ",
    "text": "ggplot \n\nThe ggplot() function initializes a plot.\nIt provides a blank canvas to which layers can be added.\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-1.html#geom_",
    "href": "slides/week-1.html#geom_",
    "title": "Week 1",
    "section": "geom_* ",
    "text": "geom_* \n\nThe geom_*() functions add geometric objects to the plot.\nThey describe how to render the mapping created in aes\nExample: Adding points to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point()"
  },
  {
    "objectID": "slides/week-1.html#labs",
    "href": "slides/week-1.html#labs",
    "title": "Week 1",
    "section": "labs ",
    "text": "labs \n\nThe labs() function is used to add titles, subtitles, and axis labels to the plot.\nIt is useful for providing context and making the plot more informative.\nExample: Adding titles and axis labels to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species) + \n  theme_linedraw() + \n  labs(title = \"Penguins Weight by Bill Size\", \n       x = \"Body Mass\",\n       y = \"Bill Length\", \n       subtitle = \"Made for 523c\")"
  },
  {
    "objectID": "slides/week-1.html#raster-structure",
    "href": "slides/week-1.html#raster-structure",
    "title": "Week 1",
    "section": "Raster Structure ",
    "text": "Raster Structure \nRaster data is stored as an multi-dimensional array of values. - Remember this is atomic vector with diminisions - The same way we looked\n\nv &lt;- values(elev)\nhead(v)\n#&gt;      CONUS_dem\n#&gt; [1,]    242037\n#&gt; [2,]    243793\n#&gt; [3,]    244464\n#&gt; [4,]    244302\n#&gt; [5,]    244060\n#&gt; [6,]    243888\nclass(v[,1])\n#&gt; [1] \"integer\"\n\ndim(v)\n#&gt; [1] 361425735         1\ndim(elev)\n#&gt; [1] 16893 21395     1\nnrow(elev)\n#&gt; [1] 16893"
  },
  {
    "objectID": "slides/week-1.html#purrr",
    "href": "slides/week-1.html#purrr",
    "title": "Week 1",
    "section": "purrr ",
    "text": "purrr \n\nThe purrr package is used for functional programming.\nIt provides functions for working with lists and vectors."
  },
  {
    "objectID": "slides/week-1.html#machine-learning",
    "href": "slides/week-1.html#machine-learning",
    "title": "Week 1",
    "section": "Machine Learning ",
    "text": "Machine Learning \n\nlibrary(tidymodels)\ntidymodels_packages()\n#&gt;  [1] \"broom\"        \"cli\"          \"conflicted\"   \"dials\"        \"dplyr\"       \n#&gt;  [6] \"ggplot2\"      \"hardhat\"      \"infer\"        \"modeldata\"    \"parsnip\"     \n#&gt; [11] \"purrr\"        \"recipes\"      \"rlang\"        \"rsample\"      \"rstudioapi\"  \n#&gt; [16] \"tibble\"       \"tidyr\"        \"tune\"         \"workflows\"    \"workflowsets\"\n#&gt; [21] \"yardstick\"    \"tidymodels\""
  },
  {
    "objectID": "slides/week-1.html#linear-modeling-lm",
    "href": "slides/week-1.html#linear-modeling-lm",
    "title": "Week 1",
    "section": "linear modeling: lm",
    "text": "linear modeling: lm\n\nThe lm() function is used to fit linear models.\nIt is useful when you want to model the relationship between two variables.\nExample: Fitting a linear model to predict body_mass_g from flipper_length_mm.\n\n\nmodel &lt;- lm(body_mass_g ~ flipper_length_mm, data = drop_na(penguins))\n\nsummary(model)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass_g ~ flipper_length_mm, data = drop_na(penguins))\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1057.33  -259.79   -12.24   242.97  1293.89 \n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)       -5872.09     310.29  -18.93   &lt;2e-16 ***\n#&gt; flipper_length_mm    50.15       1.54   32.56   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 393.3 on 331 degrees of freedom\n#&gt; Multiple R-squared:  0.7621, Adjusted R-squared:  0.7614 \n#&gt; F-statistic:  1060 on 1 and 331 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "slides/week-1.html#tidy",
    "href": "slides/week-1.html#tidy",
    "title": "Week 1",
    "section": "tidy ",
    "text": "tidy \n\nThe tidy() function is used to tidy model coefficients.\nIt is useful when you want to extract model coefficients.\nExample: Tidying the model output.\n\n\ntidy(model)\n#&gt; # A tibble: 2 √ó 5\n#&gt;   term              estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)        -5872.     310.       -18.9 1.18e- 54\n#&gt; 2 flipper_length_mm     50.2      1.54      32.6 3.13e-105"
  },
  {
    "objectID": "slides/week-1.html#glance",
    "href": "slides/week-1.html#glance",
    "title": "Week 1",
    "section": "glance ",
    "text": "glance \n\nThe glance() function is used to provide a summary of model fit.\nIt is useful when you want to assess model performance.\nExample: Glancing at the model output.\n\n\nglance(model)\n#&gt; # A tibble: 1 √ó 12\n#&gt;   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.762         0.761  393.     1060. 3.13e-105     1 -2461. 4928. 4940.\n#&gt; # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#augment",
    "href": "slides/week-1.html#augment",
    "title": "Week 1",
    "section": "augment ",
    "text": "augment \n\nThe augment() function is used to add model predictions and residuals to the dataset.\nIt is useful when you want to visualize model performance.\nExample: Augmenting the model output.\n\n\n\n\na &lt;- augment(model)\n\nggplot(a, aes(x = .fitted, y = body_mass_g)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\nggplot(a, aes(x = .resid)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/week-1.html#map",
    "href": "slides/week-1.html#map",
    "title": "Week 1",
    "section": "map ",
    "text": "map \n\nThe map() function is used to apply a function to each element of a list.\nIt is useful when you want to iterate over a list.\nExample: Fitting a linear model to each species in the penguins dataset.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)))\n#&gt; # A tibble: 3 √ó 3\n#&gt;   species   data               lm    \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;"
  },
  {
    "objectID": "slides/week-1.html#map_",
    "href": "slides/week-1.html#map_",
    "title": "Week 1",
    "section": "map_* ",
    "text": "map_* \n\nThe map_*() functions are used to extract specific outputs from a list.\nThey are useful when you want to extract specific outputs from a list.\nExample: Extracting the R-squared values (doubles) from the linear models.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm, ~summary(.x)$r.squared))\n#&gt; # A tibble: 3 √ó 4\n#&gt;   species   data               lm        r2\n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;   0.219\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;   0.494\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412"
  },
  {
    "objectID": "slides/week-1.html#map2",
    "href": "slides/week-1.html#map2",
    "title": "Week 1",
    "section": "map2 ",
    "text": "map2 \n\nThe map2() function is used to iterate over two lists in parallel.\nIt is useful when you want to apply a function to two lists simultaneously.\nExample: Augmenting the linear models with the original data.\n\n\npenguins |&gt; \n  drop_na() |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm_mod = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm_mod, ~summary(.x)$r.squared),\n         a  = map2(lm_mod, data, ~broom::augment(.x, .y))) \n#&gt; # A tibble: 3 √ó 5\n#&gt;   species   data               lm_mod    r2 a                  \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt; &lt;list&gt;             \n#&gt; 1 Adelie    &lt;tibble [146 √ó 7]&gt; &lt;lm&gt;   0.216 &lt;tibble [146 √ó 13]&gt;\n#&gt; 2 Gentoo    &lt;tibble [119 √ó 7]&gt; &lt;lm&gt;   0.506 &lt;tibble [119 √ó 13]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412 &lt;tibble [68 √ó 13]&gt;"
  },
  {
    "objectID": "slides/week-1.html#geometry-list-columns",
    "href": "slides/week-1.html#geometry-list-columns",
    "title": "Week 1",
    "section": "Geometry list columns ",
    "text": "Geometry list columns \n\nThe geometry column contains the spatial information.\nIt is stored as a list-column of sfc objects.\nExample: Accessing the first geometry in the rivers dataset.\n\n\nrivers$geometry[1]\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 144.8258 ymin: 61.40833 xmax: 160.7636 ymax: 68.8008\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#projections",
    "href": "slides/week-1.html#projections",
    "title": "Week 1",
    "section": "Projections ",
    "text": "Projections \n\nCRS (Coordinate Reference System) is used to define the spatial reference.\nThe st_crs() function is used to get the CRS of a dataset.\nThe st_transform() function is used to transform the CRS of a dataset.\nExample: Transforming the rivers dataset to EPSG:5070.\n\n\nst_crs(rivers) |&gt; sf::st_is_longlat()\n#&gt; [1] TRUE\nst_crs(rivers)$units\n#&gt; NULL\n\nriv_5070  &lt;- st_transform(rivers, 5070)\n\nst_crs(riv_5070) |&gt; sf::st_is_longlat()\n#&gt; [1] FALSE\n\nst_crs(riv_5070)$units\n#&gt; [1] \"m\""
  },
  {
    "objectID": "slides/week-1.html#data-aesthetics",
    "href": "slides/week-1.html#data-aesthetics",
    "title": "Week 1",
    "section": "data / aesthetics ",
    "text": "data / aesthetics \n\nData must be provided to ggplot()\nThe aes() function is used to map variables to aesthetics (e.g., x and y axes).\naes arguments provided in ggplot are inherited by all layers.\nExample: Creating a plot of body_mass_g vs.¬†bill_length_mm.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm))"
  },
  {
    "objectID": "slides/week-1.html#facet_wrap-facet_grid",
    "href": "slides/week-1.html#facet_wrap-facet_grid",
    "title": "Week 1",
    "section": "facet_wrap / facet_grid ",
    "text": "facet_wrap / facet_grid \n\nThe facet_wrap() function is used to create small multiples of a plot.\nIt is useful when you want to compare subsets of data.\nThe facet_grid() function is used to create a grid of plots.\nExample: Faceting the plot by species.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species)"
  },
  {
    "objectID": "slides/week-1.html#theme_",
    "href": "slides/week-1.html#theme_",
    "title": "Week 1",
    "section": "theme_* ",
    "text": "theme_* \n\nThe theme_*() functions are used to customize the appearance of the plot.\nThey allow you to modify the plot‚Äôs background, gridlines, and text.\nExample: Applying the theme_linedraw() theme to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species) + \n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-1.html#pivot_longer",
    "href": "slides/week-1.html#pivot_longer",
    "title": "Week 1",
    "section": "pivot_longer ",
    "text": "pivot_longer \n\nThe pivot_longer() function is used to convert wide data to long data.\nIt is useful when you want to work with data in a tidy format.\nExample: Converting the penguins dataset from wide to long format.\n\n\n(data.long = penguins |&gt; \n  select(species, bill_length_mm, body_mass_g) |&gt; \n  mutate(penguin_id = 1:n()) |&gt; \n  pivot_longer(-c(penguin_id, species), \n               names_to = \"Measure\", \n               values_to = \"value\"))\n#&gt; # A tibble: 688 √ó 4\n#&gt;    species penguin_id Measure         value\n#&gt;    &lt;fct&gt;        &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n#&gt;  1 Adelie           1 bill_length_mm   39.1\n#&gt;  2 Adelie           1 body_mass_g    3750  \n#&gt;  3 Adelie           2 bill_length_mm   39.5\n#&gt;  4 Adelie           2 body_mass_g    3800  \n#&gt;  5 Adelie           3 bill_length_mm   40.3\n#&gt;  6 Adelie           3 body_mass_g    3250  \n#&gt;  7 Adelie           4 bill_length_mm   NA  \n#&gt;  8 Adelie           4 body_mass_g      NA  \n#&gt;  9 Adelie           5 bill_length_mm   36.7\n#&gt; 10 Adelie           5 body_mass_g    3450  \n#&gt; # ‚Ñπ 678 more rows"
  },
  {
    "objectID": "slides/week-1.html#pivot_wider",
    "href": "slides/week-1.html#pivot_wider",
    "title": "Week 1",
    "section": "pivot_wider ",
    "text": "pivot_wider \n\nThe pivot_wider() function is used to convert long data to wide data.\nIt is useful when you want to work with data in a wide format.\nExample: Converting the data.long dataset from long to wide format.\n\n\ndata.long |&gt; \n  pivot_wider(names_from = \"Measure\", \n              values_from = \"value\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species penguin_id bill_length_mm body_mass_g\n#&gt;    &lt;fct&gt;        &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1 Adelie           1           39.1        3750\n#&gt;  2 Adelie           2           39.5        3800\n#&gt;  3 Adelie           3           40.3        3250\n#&gt;  4 Adelie           4           NA            NA\n#&gt;  5 Adelie           5           36.7        3450\n#&gt;  6 Adelie           6           39.3        3650\n#&gt;  7 Adelie           7           38.9        3625\n#&gt;  8 Adelie           8           39.2        4675\n#&gt;  9 Adelie           9           34.1        3475\n#&gt; 10 Adelie          10           42          4250\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#nest-unnest",
    "href": "slides/week-1.html#nest-unnest",
    "title": "Week 1",
    "section": "nest / unnest ",
    "text": "nest / unnest \n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  unnest(data)\n#&gt; # A tibble: 344 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 334 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#from-package",
    "href": "slides/week-1.html#from-package",
    "title": "Week 1",
    "section": "From package ",
    "text": "From package \n\n# via packages\n(counties &lt;- AOI::aoi_get(state = \"conus\", county = \"all\"))\n#&gt; Simple feature collection with 3108 features and 14 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_region state_division feature_code state_name state_abbr     name\n#&gt; 1             3              6      0161526    Alabama         AL  Autauga\n#&gt; 2             3              6      0161527    Alabama         AL  Baldwin\n#&gt; 3             3              6      0161528    Alabama         AL  Barbour\n#&gt; 4             3              6      0161529    Alabama         AL     Bibb\n#&gt; 5             3              6      0161530    Alabama         AL   Blount\n#&gt; 6             3              6      0161531    Alabama         AL  Bullock\n#&gt; 7             3              6      0161532    Alabama         AL   Butler\n#&gt; 8             3              6      0161533    Alabama         AL  Calhoun\n#&gt; 9             3              6      0161534    Alabama         AL Chambers\n#&gt; 10            3              6      0161535    Alabama         AL Cherokee\n#&gt;    fip_class tiger_class combined_area_code metropolitan_area_code\n#&gt; 1         H1       G4020                388                   &lt;NA&gt;\n#&gt; 2         H1       G4020                380                   &lt;NA&gt;\n#&gt; 3         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 4         H1       G4020                142                   &lt;NA&gt;\n#&gt; 5         H1       G4020                142                   &lt;NA&gt;\n#&gt; 6         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 7         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 8         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 9         H1       G4020                122                   &lt;NA&gt;\n#&gt; 10        H1       G4020                 NA                   &lt;NA&gt;\n#&gt;    functional_status  land_area water_area fip_code\n#&gt; 1                  A 1539634184   25674812    01001\n#&gt; 2                  A 4117656514 1132955729    01003\n#&gt; 3                  A 2292160149   50523213    01005\n#&gt; 4                  A 1612188717    9572303    01007\n#&gt; 5                  A 1670259090   14860281    01009\n#&gt; 6                  A 1613083467    6030667    01011\n#&gt; 7                  A 2012002546    2701199    01013\n#&gt; 8                  A 1569246126   16536293    01015\n#&gt; 9                  A 1545085601   16971700    01017\n#&gt; 10                 A 1433620850  120310807    01019\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-86.81491 3...\n#&gt; 2  MULTIPOLYGON (((-87.59883 3...\n#&gt; 3  MULTIPOLYGON (((-85.41644 3...\n#&gt; 4  MULTIPOLYGON (((-87.01916 3...\n#&gt; 5  MULTIPOLYGON (((-86.5778 33...\n#&gt; 6  MULTIPOLYGON (((-85.65767 3...\n#&gt; 7  MULTIPOLYGON (((-86.4482 31...\n#&gt; 8  MULTIPOLYGON (((-85.79605 3...\n#&gt; 9  MULTIPOLYGON (((-85.59315 3...\n#&gt; 10 MULTIPOLYGON (((-85.51361 3..."
  },
  {
    "objectID": "slides/week-1.html#from-file",
    "href": "slides/week-1.html#from-file",
    "title": "Week 1",
    "section": "From file ",
    "text": "From file \n\n(rivers &lt;- sf::read_sf('data/majorrivers_0_0/MajorRivers.shp'))\n#&gt; Simple feature collection with 98 features and 4 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -164.8874 ymin: -36.96945 xmax: 160.7636 ymax: 71.39249\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 98 √ó 5\n#&gt;    NAME          SYSTEM MILES KILOMETERS                                geometry\n#&gt;    &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;                   &lt;MULTILINESTRING [¬∞]&gt;\n#&gt;  1 Kolyma        &lt;NA&gt;   2552.      4106. ((144.8419 61.75915, 144.8258 61.8036,‚Ä¶\n#&gt;  2 Parana        Parana 1616.      2601. ((-51.0064 -20.07941, -51.02972 -20.22‚Ä¶\n#&gt;  3 San Francisco &lt;NA&gt;   1494.      2404. ((-46.43639 -20.25807, -46.49835 -20.2‚Ä¶\n#&gt;  4 Japura        Amazon 1223.      1968. ((-76.71056 1.624166, -76.70029 1.6883‚Ä¶\n#&gt;  5 Putumayo      Amazon  890.      1432. ((-76.86806 1.300553, -76.86695 1.295,‚Ä¶\n#&gt;  6 Rio Maranon   Amazon  889.      1431. ((-73.5079 -4.459834, -73.79197 -4.621‚Ä¶\n#&gt;  7 Ucayali       Amazon 1298.      2089. ((-73.5079 -4.459834, -73.51585 -4.506‚Ä¶\n#&gt;  8 Guapore       Amazon  394.       634. ((-65.39585 -10.39333, -65.39578 -10.3‚Ä¶\n#&gt;  9 Madre de Dios Amazon  568.       914. ((-65.39585 -10.39333, -65.45279 -10.4‚Ä¶\n#&gt; 10 Amazon        Amazon 1890.      3042. ((-73.5079 -4.459834, -73.45141 -4.427‚Ä¶\n#&gt; # ‚Ñπ 88 more rows"
  },
  {
    "objectID": "slides/week-1.html#via-url",
    "href": "slides/week-1.html#via-url",
    "title": "Week 1",
    "section": "via url ",
    "text": "via url \n\n# via url\n(gage &lt;- sf::read_sf(\"https://reference.geoconnex.us/collections/gages/items/1000001\"))\n#&gt; Simple feature collection with 1 feature and 17 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -107.2826 ymin: 35.94568 xmax: -107.2826 ymax: 35.94568\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 1 √ó 18\n#&gt;   nhdpv2_reachcode mainstem_uri           fid nhdpv2_reach_measure cluster uri  \n#&gt;   &lt;chr&gt;            &lt;chr&gt;                &lt;int&gt;                &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 13020205000216   https://geoconnex.u‚Ä¶     1                 80.3 https:‚Ä¶ http‚Ä¶\n#&gt; # ‚Ñπ 12 more variables: nhdpv2_comid &lt;dbl&gt;, name &lt;chr&gt;, nhdpv2_totdasqkm &lt;dbl&gt;,\n#&gt; #   description &lt;chr&gt;, nhdpv2_link_source &lt;chr&gt;, subjectof &lt;chr&gt;,\n#&gt; #   nhdpv2_offset_m &lt;dbl&gt;, provider &lt;chr&gt;, gage_totdasqkm &lt;dbl&gt;,\n#&gt; #   provider_id &lt;chr&gt;, dasqkm_diff &lt;dbl&gt;, geometry &lt;POINT [¬∞]&gt;\n\n# write out data\n# write_sf(counties, \"data/counties.shp\")"
  },
  {
    "objectID": "slides/week-1.html#additonal-structure",
    "href": "slides/week-1.html#additonal-structure",
    "title": "Week 1",
    "section": "Additonal Structure",
    "text": "Additonal Structure\nIn addition to the values and diminsions, rasters have: - Extent: The spatial extent of the raster. - Resolution: The spatial resolution of the raster pixels. - CRS: The coordinate reference system of the raster.\n\ncrs(elev)\n#&gt; [1] \"PROJCRS[\\\"unnamed\\\",\\n    BASEGEOGCRS[\\\"NAD83\\\",\\n        DATUM[\\\"North American Datum 1983\\\",\\n            ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101004,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4269]],\\n    CONVERSION[\\\"Albers Equal Area\\\",\\n        METHOD[\\\"Albers Equal Area\\\",\\n            ID[\\\"EPSG\\\",9822]],\\n        PARAMETER[\\\"Latitude of false origin\\\",23,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8821]],\\n        PARAMETER[\\\"Longitude of false origin\\\",-96,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8822]],\\n        PARAMETER[\\\"Latitude of 1st standard parallel\\\",29.5,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8823]],\\n        PARAMETER[\\\"Latitude of 2nd standard parallel\\\",45.5,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8824]],\\n        PARAMETER[\\\"Easting at false origin\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8826]],\\n        PARAMETER[\\\"Northing at false origin\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8827]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"easting\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]],\\n        AXIS[\\\"northing\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]]]\"\next(elev)\n#&gt; SpatExtent : -1146465, -504615, 1566915, 2073705 (xmin, xmax, ymin, ymax)\nres(elev)\n#&gt; [1] 30 30"
  },
  {
    "objectID": "slides/week-1.html#raster-structure-1",
    "href": "slides/week-1.html#raster-structure-1",
    "title": "Week 1",
    "section": "Raster Structure ",
    "text": "Raster Structure \n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#value-supersetting",
    "href": "slides/week-1.html#value-supersetting",
    "title": "Week 1",
    "section": "Value Supersetting ",
    "text": "Value Supersetting \n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#autoplot-rank_results",
    "href": "slides/week-1.html#autoplot-rank_results",
    "title": "Week 1",
    "section": "autoplot / rank_results  ",
    "text": "autoplot / rank_results  \n\nThe autoplot() function is used to visualize model performance.\nThe rank_results() function is used to rank models based on a metric.\nExample: Visualizing and ranking the model results based on the roc_auc (area under the curve) metric.\n\n\n\n\nautoplot(workflowset)\n\n\n\n\n\n\n\n\n\n\nrank_results(workflowset, rank_metric = \"roc_auc\")\n#&gt; # A tibble: 6 √ó 9\n#&gt;   wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n#&gt; 1 recipe_multinom_‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 1     0           5 recipe       mult‚Ä¶     1\n#&gt; 2 recipe_multinom_‚Ä¶ Prepro‚Ä¶ roc_auc 1     0           5 recipe       mult‚Ä¶     1\n#&gt; 3 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 0.981 5.97e-3     5 recipe       rand‚Ä¶     2\n#&gt; 4 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ roc_auc 1.00  3.60e-4     5 recipe       rand‚Ä¶     2\n#&gt; 5 recipe_decision_‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 0.955 1.28e-2     5 recipe       deci‚Ä¶     3\n#&gt; 6 recipe_decision_‚Ä¶ Prepro‚Ä¶ roc_auc 0.953 1.39e-2     5 recipe       deci‚Ä¶     3"
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Structure",
    "text": "Structure\nIn general ‚Ä¶\n\nMondays will be a lecture,with a mix of slides and discussion.\nWednesdays will be a lab with a introductory ~30 min technical demo, followed by a hands-on lab due the following week.\nGroup work is encouraged, but all assignments should be submitted individually."
  },
  {
    "objectID": "index.html#grades",
    "href": "index.html#grades",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Grades",
    "text": "Grades\n\n6 labs will be worth 150 points each.\nThey will be assigned on Wednesdays and due the following Wednesdays before class.\nA final project will be optional and worth 150 extra credit points. It will build on your personal website built in ESS 523a.\n\nThe total points possible is 1050, with the percentage being taken out of 900 using the traditional 90/80/70/60 scales"
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Lab 1: Data Science Tools",
    "section": "",
    "text": "In this lab you will practice data wrangling and visualization skills using COVID-19 data curated by the New York Times. This data is a large dataset measuring the cases and deaths per US county across the lifespan of COVID from its early beginnings to just past the peak. The data stored in daily cummulative counts, is a great example of data that needs to be wrangled and cleaned before any analysis can be done."
  },
  {
    "objectID": "labs/lab1.html#libraries",
    "href": "labs/lab1.html#libraries",
    "title": "Lab 1: Data Science Tools",
    "section": "Libraries",
    "text": "Libraries\nYou will need a few libraries for this lab. Make sure they are installed and loaded in your Qmd:\n\ntidyverse (data wrangling and visualization)\nflextable (make nice tables)\nzoo (rolling averages)"
  },
  {
    "objectID": "labs/lab1.html#data",
    "href": "labs/lab1.html#data",
    "title": "Lab 1: Data Science Tools",
    "section": "Data",
    "text": "Data\nWe are going to practice some data wrangling skills using a real-world dataset about COVID cases curated and maintained by the New York Times. The data was used in the peak of the pandemic to create reports and data visualizations like this, and are archived on a GitHub repo here. A history of the importance can be found here.\nLets pretend it in Feb 1st, 2022. You are a data scientist for the state of Colorado Department of Public Health (this is actually a task I did in California!). You‚Äôve been tasked with giving a report to Governor Polis each morning about the most current COVID-19 conditions at the county level.\nAs it stands, the Colorado Department of Public Health maintains a watch list of counties that are being monitored for worsening corona virus trends. There are six criteria used to place counties on the watch list:\n\nDoing fewer than 150 tests per 100,000 residents daily (over a 7-day average)\nMore than 100 new cases per 100,000 residents over the past 14 days‚Ä¶\n25 new cases per 100,000 residents and an 8% test positivity rate\n10% or greater increase in COVID-19 hospitalized patients over the past 3 days\nFewer than 20% of ICU beds available\nFewer than 25% ventilators available\n\nOf these 6 conditions, you are in charge of monitoring condition number 2."
  },
  {
    "objectID": "labs/lab1.html#steps",
    "href": "labs/lab1.html#steps",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nStart by reading in the data from the NY-Times URL with read_csv (make sure to attach the tidyverse). The data read from Github is considered our ‚Äúraw data‚Äù. Remember to always leave ‚Äúraw-data-raw‚Äù and to generate meaningful subsets as you go.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(flextable)\ndata &lt;- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\n\n\n\nCreate an object called my.date and set it as ‚Äú2022-02-01‚Äù - ensure this is a date object.\nCreate a object called my.state and set it to ‚ÄúColorado‚Äù.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIn R, as.Date() is a function used to convert character strings, numeric values, or other date-related objects into Date objects. It ensures that dates are stored in the correct format for date-based calculations and manipulations.\n\n\nCode\ntxt &lt;- \"2025-02-15\"\nclass(txt)\n\n\n[1] \"character\"\n\n\nCode\ndate_example &lt;- as.Date(txt)\nclass(date_example)\n\n\n[1] \"Date\"\n\n\n\n\n\n\n\nCode\nmy.date  &lt;- as.Date(\"2022-02-01\")\nmy.state &lt;- \"Colorado\"\n\n\n\nStart by making a subset that limits the data to Colorado (filter), and add a new column (mutate) with the daily new cases using diff/lag by county (group_by). Do the same for new deaths. If lag is new to you, lag is a function that shifts a vector by a specified number of positions. The help file can be found with ?lag.\n\n(Hint: you will need some combination of filter, group_by, arrange, mutate, diff/lag, and ungroup)\n\nUsing your subset, generate (2) tables. The first should show the 5 counties with the most CUMULATIVE cases on you date of interest, and the second should show the 5 counties with the most NEW cases on that same date. Remember to use your my.date object as a proxy for today‚Äôs date:\n\nYour tables should have clear column names and descriptive captions.\n(Hint: Use flextable::flextable() and flextable::set_caption())"
  },
  {
    "objectID": "labs/lab1.html#steps-1",
    "href": "labs/lab1.html#steps-1",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nGiven the above URL, and guidelines on string concatenation, read in the population data and (1) create a five digit FIP variable and only keep columns that contain ‚ÄúNAME‚Äù or ‚Äú2021‚Äù (remember the tidyselect option found with ?dplyr::select). Additionally, remove all state level rows (e.g.¬†COUNTY FIP == ‚Äú000‚Äù)\n\n\nNow, explore the data ‚Ä¶ what attributes does it have, what are the names of the columns? Do any match the COVID data we have? What are the dimensions‚Ä¶ In a few sentences describe the data obtained after modification:\n\n(Hint: names(), dim(), nrow(), str(), glimpse(), skimr,‚Ä¶))"
  },
  {
    "objectID": "labs/lab1.html#steps-2",
    "href": "labs/lab1.html#steps-2",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nFirst, we need to group/summarize our county level data to the state level, filter it to the four states of interest, and calculate the number of daily new cases (diff/lag) and the 7-day rolling mean.\n\n\n\n\n\n\n\nRolling Averages\n\n\n\n\n\nThe rollmean function from the zoo package in R is used to compute the rolling (moving) mean of a numeric vector, matrix, or zoo/ts object.\nrollmean(x, k, fill = NA, align = \"center\", na.pad = FALSE)\n- x: Numeric vector, matrix, or time series.\n- k: Window size (number of observations).\n- fill: Values to pad missing results (default NA).\n- align: Position of the rolling window (‚Äúcenter‚Äù, ‚Äúleft‚Äù, ‚Äúright‚Äù).\n- na.pad: If TRUE, pads missing values with NA.\n\n\nExamples\n\nRolling Mean on a Numeric Vector Since align = \"center\" by default, values at the start and end are dropped.\n\n\n\nCode\nlibrary(zoo)\n\n# Sample data\nx &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n# Rolling mean with a window size of 3\nrollmean(x, k = 3)\n\n\n[1] 2 3 4 5 6 7 8 9\n\n\n\nRolling Mean with Padding Missing values are filled at the start and end.\n\n\n\nCode\nrollmean(x, k = 3, fill = NA)\n\n\n [1] NA  2  3  4  5  6  7  8  9 NA\n\n\n\nAligning Left or Right The rolling mean is calculated with values aligned to the left or right\n\n\n\nCode\nrollmean(x, k = 3, fill = NA, align = \"left\")\n\n\n [1]  2  3  4  5  6  7  8  9 NA NA\n\n\nCode\nrollmean(x, k = 3, fill = NA, align = \"right\")\n\n\n [1] NA NA  2  3  4  5  6  7  8  9\n\n\n\n\n\n\nHint: You will need two group_by calls and the zoo::rollmean function.\n\nUsing the modified data, make a facet plot of the daily new cases and the 7-day rolling mean. Your plot should use compelling geoms, labels, colors, and themes.\n\n\nThe story of raw case counts can be misleading. To understand why, lets explore the cases per capita of each state. To do this, join the state COVID data to the population estimates and calculate the \\(new cases / total population\\). Additionally, calculate the 7-day rolling mean of the new cases per capita counts. This is a tricky task and will take some thought, time, and modification to existing code (most likely)!\n\nHint: You may need to modify the columns you kept in your original population data. Be creative with how you join data (inner vs outer vs full)!\n\nUsing the per capita data, plot the 7-day rolling averages overlying each other (one plot) with compelling labels, colors, and theme.\n\n\nBriefly describe the influence scaling by population had on the analysis? Does it make some states look better? Some worse? How so?\n\n\n‚Ä¶"
  },
  {
    "objectID": "labs/lab1.html#data-preparation",
    "href": "labs/lab1.html#data-preparation",
    "title": "Lab 1: Data Science Tools",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLet‚Äôs start with the raw COVID dataset, and compute county level daily new cases and deaths (lag). Then, join it to the census data in order to use population data in the model.\nWe are aware there was a strong seasonal component to the spread of COVID-19. To account for this, lets add a new column to the data for year (lubridate::year()), month (lubridate::month()), and season (dplyr::case_when()) which will be one of four values: ‚ÄúSpring‚Äù (Mar-May), ‚ÄúSummer‚Äù (Jun-Aug), ‚ÄúFall‚Äù (Sep-Nov), or ‚ÄúWinter‚Äù (Dec - Jan) based on the computed Month.\nNext, lets group the data by state, year, and season and summarize the total population, new cases, and new deaths per grouping.\nGiven the case/death counts are not scaled by population, we expect that each will exhibit a right skew behavior (you can confirm this with density plots, shapiro.test, or histrograms). Given an assumption of linear models is normality in the data, let‚Äôs apply a log transformation to cases, deaths, and population to normalize them.\n\n\n\n\n\n\n\nNote\n\n\n\nWe know there are 0‚Äôs in the data (cases/deaths), so we can add 1 to the data before taking the log. As the log of 0 is undefined, adding 1 ensures that the log of 0 is -Inf.\n\n\nCode\nlog(0)\n\n\n[1] -Inf"
  },
  {
    "objectID": "labs/lab1.html#model-building",
    "href": "labs/lab1.html#model-building",
    "title": "Lab 1: Data Science Tools",
    "section": "Model Building",
    "text": "Model Building\n\nOnce the data has been prepared, build a linear model (lm) to predict the log of cases using the log of deaths the log of population, and the season. Be sure to add an interaction term for population and deaths since they per capita realtionship is significant!\nOnce the model is built, summarize it (summary) and report the R-squared value and the p-value of the model. What does this mean for the value of its application?"
  },
  {
    "objectID": "slides/week-1.html",
    "href": "slides/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to 523C: Environmental Data Science Applications: Water Resources!\nThis first lecture will introduce essential, high-level topics to help you build a strong foundation in R for environmental data science.\nThroughout the lecture, you will be asked to assess your comfort level with various topics via a Google survey.\nThe survey results will help tailor the course focus, ensuring that we reinforce challenging concepts while avoiding unnecessary review of familiar topics."
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Lab 2: Distances and Projections",
    "section": "",
    "text": "In this lab we will explore the properties of sf, sfc, and sfg features & objects; how they are stored; and issues related to distance calculation and coordinate transformation.\nWe will continue to build on our data wrangling and data visualization skills; as well as document preparation via Quarto and GitHub.\n\n\nSet-up\n\nNavigage to your csu-523c repository\nCreate a new Quarto (.qmd) file called lab-02.qmd\nPopulate its YML with a title, author, subtitle, output type and theme. For example:\n\n\n---\ntitle: \"Lab 02: Distances and the Border Zone\"\nsubtitle: 'Ecosystem Science and Sustainability 523c'\nauthor:\n  - name: ...\n    email: ...\nformat: html\n---\n\n\n\n\nLibraries\n\n# spatial data science\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(units)\n\n# Data\nlibrary(USAboundaries)\nlibrary(rnaturalearth)\n\n# Visualization\nlibrary(gghighlight)\nlibrary(ggrepel)\nlibrary(knitr)\n\n\n\n\nBackground\nIn this lab, 4 main skills are covered:\n\nIngesting / building sf objects from R packages and CSVs. (Q1)\nManipulating geometries and coordinate systems (Q2)\nCalculating distances (Q2)\nBuilding maps using ggplot (Q3)\n\nHints and Tricks for this lab are available here\n\n\n\nQuestion 1:\nFor this lab we need three (3) datasets.\n\nSpatial boundaries of continental USA states (1.1)\nBoundaries of Canada, Mexico and the United States (1.2)\nAll USA cites (1.3)\n\n\n1.1 Define a Projection\nFor this lab we want to calculate distances between features, therefore we need a projection that preserves distance at the scale of CONUS. For this, we will use the North America Equidistant Conic:\n\neqdc &lt;- '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\nThis PROJ.4 string defines an Equidistant Conic projection with the following parameters:\n\n+proj=eqdc ‚Üí Equidistant Conic projection\n+lat_0=40 ‚Üí Latitude of the projection‚Äôs center (40¬∞N)\n+lon_0=-96 ‚Üí Central meridian (96¬∞W)\n+lat_1=20 ‚Üí First standard parallel (20¬∞N)\n+lat_2=60 ‚Üí Second standard parallel (60¬∞N)\n+x_0=0 ‚Üí False easting (0 meters)\n+y_0=0 ‚Üí False northing (0 meters)\n+datum=NAD83 ‚Üí Uses the North American Datum 1983 (NAD83)\n+units=m ‚Üí Units are in meters\n+no_defs ‚Üí No additional default parameters from PROJ‚Äôs database\n\nThis projection is commonly used for mapping large areas with an east-west extent, especially in North America, as it balances distortion well between the two standard parallels.\n\n\n1.2 - Get USA state boundaries\nIn R, USA boundaries are stored in the USAboundaries package. In case this package and data are not installed:\n\nremotes::install_github(\"ropensci/USAboundaries\")\nremotes::install_github(\"ropensci/USAboundariesData\")\n\nOnce installed:\n\nUSA state boundaries can be accessed with USAboundaries::us_states(resolution = \"low\"). Given the precision needed for this analysis we are ok with the low resolution.\nMake sure you only have the states in the continental United States (CONUS) (Hint use filter)\nMake sure the data is in a projected coordinate system suitable for distance measurements at the national scale (eqdc).\n\n\n\n\n1.3 - Get country boundaries for Mexico, the United States of America, and Canada\nIn R, country boundaries are stored in the rnaturalearth package. In case this package is not installed:\n\nremotes::install_github(\"ropenscilabs/rnaturalearthdata\")\n\nOnce installed:\n\nWorld boundaries can be accessed with rnaturalearth::countries110.\nMake sure the data is in simple features (sf) format (Hint use the st_as_sf variable).\nMake sure you only have the countries you want (Hint filter on the admin variable)\nMake sure the data is in a projected coordinate system suitable for distance measurements at the national scale (eqdc).\n\n\n\n\n1.4 - Get city locations from the CSV file\nThe process of finding, downloading and accessing data is the first step of every analysis. Here we will go through these steps (minus finding the data).\nFirst go to this site and download the appropriate (free) dataset into the data directory of this project.\nOnce downloaded, read it into your working session using readr::read_csv() and explore the dataset until you are comfortable with the information it contains.\nWhile this data has everything we want, it is not yet spatial. Convert the data.frame to a spatial object using st_as_sf and prescribing the coordinate variables and CRS (Hint what projection are the raw coordinates in?)\nFinally, remove cities in states not wanted and make sure the data is in a projected coordinate system suitable for distance measurements at the national scale:\nCongratulations! You now have three real-world, large datasets ready for analysis.\n\n\n\nQuestion 2:\nHere we will focus on calculating the distance of each USA city to (1) the national border (2) the nearest state border (3) the Mexican border and (4) the Canadian border. You will need to manipulate you existing spatial geometries to do this using either st_union or st_combine depending on the situation. In all cases, since we are after distances to borders, we will need to cast (st_cast) our MULTIPPOLYGON geometries to MULTILINESTRING geometries. To perform these distance calculations we will use st_distance().\n\n2.1 - Distance to USA Border (coastline or national) (km)\nFor 2.2 we are interested in calculating the distance of each USA city to the USA border (coastline or national border). To do this we need all states to act as single unit. Convert the USA state boundaries to a MULTILINESTRING geometry in which the state boundaries are resolved. Please do this starting with the states object and NOT with a filtered country object. In addition to storing this distance data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.2 - Distance to States (km)\nFor 2.1 we are interested in calculating the distance of each city to the nearest state boundary. To do this we need all states to act as single unit. Convert the USA state boundaries to a MULTILINESTRING geometry in which the state boundaries are preserved (not resolved). In addition to storing this distance data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.3 - Distance to Mexico (km)\nFor 2.3 we are interested in calculating the distance of each city to the Mexican border. To do this we need to isolate Mexico from the country objects. In addition to storing this data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.4 - Distance to Canada (km)\nFor 2.4 we are interested in calculating the distance of each city to the Canadian border. To do this we need to isolate Canada from the country objects. In addition to storing this data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n\nQuestion 3:\nIn this section we will focus on visualizing the distance data you calculated above. You will be using ggplot to make your maps, ggrepl to label significant features, and gghighlight to emphasize important criteria.\n\n3.1 Data\nShow the 3 continents, CONUS outline, state boundaries, and 10 largest USA cities (by population) on a single map\n\nUse geom_sf to plot your layers\nUse lty to change the line type and size to change line width\nUse ggrepel::geom_label_repel to label your cities\n\n\n\n3.2 City Distance from the Border\nCreate a map that colors USA cities by their distance from the national border. In addition, re-draw and label the 5 cities that are farthest from the border.\n\n\n3.3 City Distance from Nearest State\nCreate a map that colors USA cities by their distance from the nearest state border. In addition, re-draw and label the 5 cities that are farthest from any border.\n\n\n3.4 Equidistance boundary from Mexico and Canada\nHere we provide a little more challenge. Use gghighlight to identify the cities that are equal distance from the Canadian AND Mexican border \\(\\pm\\) 100 km.\nIn addition, label the five (5) most populous cites in this zone.\nHint: (create a new variable that finds the absolute difference between the distance to Mexico and the distance to Canada)\n\n\n\nQuestion 4:\n\nReal World Application\nRecently, Federal Agencies have claimed basic constitutional rights protected by the Fourth Amendment (protecting Americans from random and arbitrary stops and searches) do not apply fully at our borders (see Portland). For example, federal authorities do not need a warrant or suspicion of wrongdoing to justify conducting what courts have called a ‚Äúroutine search,‚Äù such as searching luggage or a vehicle. Specifically, federal regulations give U.S. Customs and Border Protection (CBP) authority to operate within 100 miles of any U.S. ‚Äúexternal boundary‚Äù. Further information can be found at this ACLU article.\n\n\n4.1 Quantifing Border Zone\n\nHow many cities are in this 100 mile zone? (100 miles ~ 160 kilometers)\nHow many people live in a city within 100 miles of the border?\nWhat percentage of the total population is in this zone?\nDoes it match the ACLU estimate in the link above?\n\nReport this information as a table.\n\n\n4.2 Mapping Border Zone\n\nMake a map highlighting the cites within the 100 mile zone using gghighlight.\nUse a color gradient from ‚Äòorange‚Äô to ‚Äòdarkred‚Äô.\nLabel the 10 most populous cities in the Danger Zone\n\n\n\n4.3 : Instead of labeling the 10 most populous cites, label the most populous city in each state within the Danger Zone.\n\n\n\n\nRubric\n\nQuestion 1 (35)\nQuestion 2 (35)\nQuestion 3 (35)\nQuestion 4 (35)\nWell Structured and appealing Qmd deployed as web page (10)\n\nTotal: 150 points\n\n\nSubmission\nFor this lab you will submit a URL to a webpage deployed with GitHub pages.\nTo do this:\n\nRender your lab document\nStage/commit/push your files\nIf you followed the naming conventions in the ‚ÄúSet Up‚Äù, your lab 2 link will be available at:\n\nhttps://USERNAME.github.io/csu-523c/lab-02.html\nSubmit this URL in the appropriate Canvas dropbox. Also take a moment to update your personal webpage with this link and some bullet points of what you learned. While not graded as part of this lab, it will be your final!"
  },
  {
    "objectID": "slides/week-2.html",
    "href": "slides/week-2.html",
    "title": "week-2",
    "section": "",
    "text": "Projections & Measures\nLecture 10, Lecture 11, Lecture 13 (centroids/buffers forward)\n\n\nPredicates & Tesselations\nLecture 12, 15"
  },
  {
    "objectID": "labs/lab2-hints.html",
    "href": "labs/lab2-hints.html",
    "title": "Lab 2: Distances and Projections",
    "section": "",
    "text": "Question 1:\n\nMaking Spatial Objects & Coordinate Transformation\nSpatial objects (sf) can be built from a vector of X and Y values in addition to a coordinate reference system (CRS). For example:\n\ndf &lt;- data.frame(name = state.name, \n                X = state.center$x, \n                Y = state.center$y)\nhead(df)\n\n        name         X       Y\n1    Alabama  -86.7509 32.5901\n2     Alaska -127.2500 49.2500\n3    Arizona -111.6250 34.2192\n4   Arkansas  -92.2992 34.7336\n5 California -119.7730 36.5341\n6   Colorado -105.5130 38.6777\n\n# Geographic Coordinate System (GCS)\n(df_sf_gcs = st_as_sf(df, \n                      coords = c(\"X\", \"Y\"), \n                      crs = 4269))\n\nSimple feature collection with 50 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -127.25 ymin: 27.8744 xmax: -68.9801 ymax: 49.25\nGeodetic CRS:  NAD83\nFirst 10 features:\n          name                 geometry\n1      Alabama POINT (-86.7509 32.5901)\n2       Alaska    POINT (-127.25 49.25)\n3      Arizona POINT (-111.625 34.2192)\n4     Arkansas POINT (-92.2992 34.7336)\n5   California POINT (-119.773 36.5341)\n6     Colorado POINT (-105.513 38.6777)\n7  Connecticut POINT (-72.3573 41.5928)\n8     Delaware POINT (-74.9841 38.6777)\n9      Florida  POINT (-81.685 27.8744)\n10     Georgia POINT (-83.3736 32.3329)\n\nggplot() + \n  geom_sf(data = df_sf_gcs) + \n  coord_sf(datum = st_crs(df_sf_gcs)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n# Projected Coordinate System (PCS)\n# st_transforms converts from one reference system to another\n(df_sf_pcs = st_transform(df_sf_gcs, 5070))\n\nSimple feature collection with 50 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -2805703 ymin: 640477 xmax: 2079664 ymax: 3291437\nProjected CRS: NAD83 / Conus Albers\nFirst 10 features:\n          name                  geometry\n1      Alabama  POINT (862043.5 1099545)\n2       Alaska  POINT (-2264853 3291437)\n3      Arizona  POINT (-1422260 1356663)\n4     Arkansas  POINT (336061.5 1303543)\n5   California  POINT (-2086972 1760961)\n6     Colorado POINT (-818480.9 1779785)\n7  Connecticut   POINT (1936213 2307450)\n8     Delaware   POINT (1796466 1938236)\n9      Florida    POINT (1409814 640477)\n10     Georgia   POINT (1179012 1107322)\n\nggplot() + \n  geom_sf(data = df_sf_pcs) + \n  coord_sf(datum = st_crs(df_sf_pcs)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2:\n\nst_distance review\n\n# Three most populous cities in the USA\n(big3 = cities |&gt; \n   select(city, population) |&gt; \n   slice_max(population, n = 3))\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -2032604 ymin: 1468468 xmax: 1833394 ymax: 2178657\nProjected CRS: NAD83 / Conus Albers\n# A tibble: 3 √ó 3\n  city        population           geometry\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;POINT [m]&gt;\n1 New York      18832416  (1833394 2178657)\n2 Los Angeles   11885717 (-2032604 1468468)\n3 Chicago        8489066 (684628.5 2122697)\n\n# Fort Collins\n(foco = filter(cities, city == \"Fort Collins\") |&gt; \n    select(city, population))\n\nSimple feature collection with 1 feature and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -760147.5 ymin: 1984621 xmax: -760147.5 ymax: 1984621\nProjected CRS: NAD83 / Conus Albers\n# A tibble: 1 √ó 3\n  city         population            geometry\n  &lt;chr&gt;             &lt;dbl&gt;         &lt;POINT [m]&gt;\n1 Fort Collins     339256 (-760147.5 1984621)\n\n# Distance from foco to population centers\nst_distance(big3, foco)\n\nUnits: [m]\n        [,1]\n[1,] 2600790\n[2,] 1373156\n[3,] 1451359\n\n\nThere are two notable things about this result:\n\nIt has units\nIt is returned as a matrix, even though foco only had one row\n\nThis second point highlights a useful feature of st_distance, namley, its ability to return distance matrices between all combinations of features in x and y.\n\n\nunits review\nWhile units are useful, they are not always the preferred units. By default, the units measurement is defined by the projection. For example:\n\nst_crs(big3)$units\n\n[1] \"m\"\n\n\nUnits can be converted using units::set_units. For example, ‚Äòm‚Äô can be converted to ‚Äòkm‚Äô:\n\nbig3 = mutate(big3, \n              dist_to_foco = st_distance(big3, foco),\n              dist_to_foco = set_units(dist_to_foco, \"km\")) \n\n(big3$dist_to_foco)\n\nUnits: [km]\n         [,1]\n[1,] 2600.790\n[2,] 1373.156\n[3,] 1451.359\n\n\nYou might have noticed the data type of the st_distance objects are an S3 class of units. Sometimes, this class can cause problems when trying to using it with other classes or methods:\n\nbig3$dist_to_foco + 4\n\nError in Ops.units(big3$dist_to_foco, 4): both operands of the expression should be \"units\" objects\n\nggplot(data = big3) + \n  geom_col(aes(x = city, y = dist_to_foco)) + \n  theme_linedraw()\n\nWarning: The `scale_name` argument of `continuous_scale()` is deprecated as of ggplot2\n3.5.0.\n\n\n\n\n\n\n\n\n\nIn these cases, the units class can be dropped with units::drop_units\n\nbig3 = mutate(big3, \n              dist_to_foco = st_distance(big3, foco),\n              dist_to_foco = set_units(dist_to_foco, \"km\"),\n              dist_to_foco = drop_units(dist_to_foco))\n\nbig3$dist_to_foco + 4\n\n         [,1]\n[1,] 2604.790\n[2,] 1377.156\n[3,] 1455.359\n\nggplot(data = big3) + \n  geom_col(aes(x = reorder(city, -dist_to_foco), y = dist_to_foco)) + \n    labs(title = \"Distance to Fort Collins (km)\") + \n  ggthemes::theme_fivethirtyeight() + \n  theme( axis.text.x = element_text(face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\nAs with all functions, these steps can be nested:\n\nbig3 = mutate(big3, \n              dist_to_foco = drop_units(set_units(st_distance(big3, foco), \"km\")))\n\n\n\n\nGeometry review\nThere are a few ways to manipulate existing geometries, here we discuss st_union, st_combine and st_cast\n\nst_combine returns a single, combined geometry, with no resolved boundaries.\nst_union() returns a single geometry with resolved boundaries\nst_cast() casts one geometry type to another\n\n\n(rockies = USAboundaries::us_states() |&gt; \n  filter(name %in% c('Montana', 'Wyoming', 'Colorado', \"New Mexico\")) |&gt; \n  select(name, geometry))\n\nSimple feature collection with 4 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n        name                       geometry\n1    Montana MULTIPOLYGON (((-116.0492 4...\n2   Colorado MULTIPOLYGON (((-109.06 38....\n3    Wyoming MULTIPOLYGON (((-111.0569 4...\n4 New Mexico MULTIPOLYGON (((-109.0492 3...\n\nplot(rockies['name'], key.pos = 1)\n\n\n\n\n\n\n\n# Combine Geometries\n(combined_wc = st_combine(rockies))\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n\n\nMULTIPOLYGON (((-116.0492 49.00091, -115.501 49...\n\nplot(combined_wc, col = \"red\")\n\n\n\n\n\n\n\n# Unioned Geometries\n(unioned_wc = st_union(rockies))\n\nGeometry set for 1 feature \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n\n\nPOLYGON ((-109.0601 38.27549, -109.0418 38.1646...\n\nplot(unioned_wc, col = \"red\")\n\n\n\n\n\n\n\n# Combine Geometries\nline_wc = st_cast(unioned_wc, \"MULTILINESTRING\")\nplot(line_wc, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3:\nIn this section you will extend your growing ggplot skills to handle spatial data using ggrepl to label significant features; gghighlight to emphasize important criteria; and scaled color/fill to create chloropleth represnetations of variables. Below is some example code to provide an example of these tools in action:\n\nGet some data (review)\n\n# Define a state/region classifier and select the southern states\nstate.of.interest &lt;- data.frame(state = state.name, region = state.region) |&gt; \n  filter(region == \"South\") |&gt; \n  pull(state)\n\n# Get USA states in the southern region and transform to EPSG:5070\nstate = USAboundaries::us_states() |&gt; \n  filter(name %in% state.of.interest) |&gt; \n  st_transform(5070)\n\n# Get USA congressional districts in the southern region and transform to EPSG:5070\ndistricts =  USAboundaries::us_congressional() |&gt; \n  filter(state_name %in% state.of.interest) |&gt; \n  st_transform(5070)\n\n# Get the 10 most populous cities in the southern region and transform to EPSG:5070\nsub_cities = cities |&gt; \n  filter(state_name %in% state.of.interest) |&gt; \n  slice_max(population, n = 10) |&gt; \n  st_transform(5070)\n\n\n\nMap\n\nggplot() + \n  # Add districts with a dashed line (lty = 3), \n  # a color gradient from blue to red based on aland, \n  # and a fill aplha of 0.5\n  geom_sf(data = districts, aes(fill = aland), lty = 3, alpha = .5) + \n  scale_fill_gradient(low = 'blue', high = \"red\") +\n  # Highlight (keep blue) only those districts witn a land area &gt; 5e10\n  gghighlight(aland &gt; 5e10) +\n  # Add the state borders with a thicker line and no fill\n  geom_sf(data = state, size = 1, fill = \"NA\") +\n  # Add the cities\n  geom_sf(data = sub_cities, size= 2, color = \"red\") +\n  # Add labels to the cities\n  ggrepel::geom_label_repel(\n    data = sub_cities,\n    aes(label = city, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 3) +\n  labs(fill = \"Area Land\") + \n  ggthemes::theme_map()"
  },
  {
    "objectID": "slides/week-2.html#simple-features",
    "href": "slides/week-2.html#simple-features",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features"
  },
  {
    "objectID": "slides/week-2.html#todays-data",
    "href": "slides/week-2.html#todays-data",
    "title": "Week 2",
    "section": "Todays Data:",
    "text": "Todays Data:\n\nSimple feature collection with 64 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   geoid       name      aland state_nm                       geometry\n1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3..."
  },
  {
    "objectID": "slides/week-2.html#simple-features-1",
    "href": "slides/week-2.html#simple-features-1",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features\n\nSimple feature geometries describe the geometries of features.\nThe main application of simple feature geometries is to describe 2D geometries as points, lines, or polygons.\n‚Äúsimple‚Äù refers to the fact that line or polygon geometries are represented by set of points connected with straight lines.\nSimple features access is a standard (Herring 2011, Herring (2010), ISO (2004)) for describing simple feature geometries via:\n\na class hierarchy\na set of operations\nbinary and text encodings"
  },
  {
    "objectID": "slides/week-2.html#simple-features-access",
    "href": "slides/week-2.html#simple-features-access",
    "title": "Week 2",
    "section": "Simple Features Access",
    "text": "Simple Features Access\n\nSimple features or simple feature access refers to the formal standard (ISO 19125-1:2004) describing how objects in the real world can be represented in computers, with emphasis on the spatial geometry of these objects.\nIt also describes how objects can be stored in and retrieved from databases, and which geometrical operations should/can be defined for them.\nThe standard is widely implemented in spatial databases (such as PostGIS), commercial GIS (e.g., ESRI ArcGIS) and forms the vector data basis for libraries such as GDAL.\nA subset of simple features (e.g.¬†the big 7) forms the GeoJSON specification.\nR has well-supported classes for storing spatial data (sp) and interfacing to the above mentioned environments (rgdal, rgeos), but has so far lacked a complete implementation of simple features, making conversions at times convoluted, inefficient or incomplete.\nsf is seeking to fill this gap and has/will succeed sp"
  },
  {
    "objectID": "slides/week-2.html#so-what-is-a-feature",
    "href": "slides/week-2.html#so-what-is-a-feature",
    "title": "Week 2",
    "section": "So what is a feature?",
    "text": "So what is a feature?\n\nA feature is a thing (object) in the real world, such as a building or a river\nThey often consist of other objects.\n\nA river system can be a feature, a river can be a feature, a river outlet can be a feature.\nA image pixel can be a feature, and the image can be a feature‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#spatial-features",
    "href": "slides/week-2.html#spatial-features",
    "title": "Week 2",
    "section": "Spatial Features",
    "text": "Spatial Features\n\nThe standard says: ‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes. Spatial attributes are geometry valued, and simple features are based on 2D geometry with linear interpolation between vertices.‚Äù - standard.\nSpatial Features have a geometry describing where the feature is located and how it is represented.\nThe geometry of a river can be its watershed, of its mainstem, or the point it drains to (see the OGC HY_Feature standard)\nFeatures can have attributes describing other properties of the feature\n\n\n\nstr(co$geometry)\n#&gt; sfc_MULTIPOLYGON of length 64; first list element: List of 1\n#&gt;  $ :List of 1\n#&gt;   ..$ : num [1:132, 1:2] -105 -105 -105 -105 -105 ...\n#&gt;  - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n\n\nOther properties may include its length, slope, stream order or average flowrate"
  },
  {
    "objectID": "slides/week-2.html#geometry-types",
    "href": "slides/week-2.html#geometry-types",
    "title": "Week 2",
    "section": "Geometry types",
    "text": "Geometry types\nThe following 7 simple feature types are the most common, and are the only ones used for GeoJSON:\n\n\n\n\n\n\n\nSINGLE\nDescription\n\n\n\n\nPOINT\nzero-dimensional geometry containing a single point\n\n\nLINESTRING\nsequence of points connected by straight, non-self intersecting line pieces; one-dimensional geometry\n\n\nPOLYGON\ngeometry with a positive area (two-dimensional); sequence of points form a closed, non-self intersecting ring; the first ring denotes the exterior ring, zero or more subsequent rings denote holes in this exterior ring\n\n\n\n\n\n\n\n\n\n\nMULTI (same typed)\nDescription\n\n\n\n\nMULTIPOINT\nset of points; a MULTIPOINT is simple if no two Points in the MULTIPOINT are equal\n\n\nMULTILINESTRING\nset of linestrings\n\n\nMULTIPOLYGON\nset of polygons\n\n\n\n\n\n\n\n\n\n\nMulti-Typed\nDescription\n\n\n\n\nGEOMETRYCOLLECTION\nset of geometries of any type except GEOMETRYCOLLECTION\n\n\n\n\nThe descriptions above were copied from the PostGIS manual."
  },
  {
    "objectID": "slides/week-2.html#dimensions",
    "href": "slides/week-2.html#dimensions",
    "title": "Week 2",
    "section": "Dimensions",
    "text": "Dimensions\nAll geometries are composed of points\n\nPoints are defined by coordinates in a 2-, 3- or 4-D space.\nIn addition to XY coordinates, there are two optional dimensions:\na Z coordinate, denoting altitude\nan M coordinate (rarely used), denoting some measure\nThe M describes a property of the vertex that is independent of the feature.\nIt sounds attractive to encode a time as M, however these quickly become invalid once the path self-intersects.\nBoth Z and M are found relatively rarely, and software support to do something useful with them is rarer still."
  },
  {
    "objectID": "slides/week-2.html#valid-geometries",
    "href": "slides/week-2.html#valid-geometries",
    "title": "Week 2",
    "section": "Valid geometries",
    "text": "Valid geometries\n\nValid geometries obey the following properties:\n\nLINESTRINGS shall not self-intersect\nPOLYGON rings shall be closed (last point = first point)\nPOLYGON holes (inner rings) shall be inside their exterior ring\nPOLYGON inner rings shall maximally touch the exterior ring in single points, not over a line\nPOLYGON rings shall not repeat their own path\n\nIf any of the above is not the case, the geometry is not valid."
  },
  {
    "objectID": "slides/week-2.html#non-simple-and-non-valid-geometries",
    "href": "slides/week-2.html#non-simple-and-non-valid-geometries",
    "title": "Week 2",
    "section": "Non-simple and non-valid geometries",
    "text": "Non-simple and non-valid geometries\n\nst_is_simple and st_is_valid provide methods to help detect non-simple and non-valid geometries:\nAn example of a non-simple geometries is a self-intersecting lines\nAn example of a non-valid geometry are would be a polygon with slivers or self-intersections.\n\n\n\n\n(x1 &lt;- st_linestring(cbind(c(0,1,0,1),c(0,1,1,0))))\n#&gt; LINESTRING (0 0, 1 1, 0 1, 1 0)\nst_is_simple(x1)\n#&gt; [1] FALSE\n\n\n\n\n\n\n\n\n\n\n\n\n(x2 &lt;- st_polygon(list(cbind(c(0,1,1,1,0,0),c(0,0,1,0.6,1,0)))))\n#&gt; POLYGON ((0 0, 1 0, 1 1, 1 0.6, 0 1, 0 0))\n(x3 &lt;- st_polygon(list(cbind(c(0,1,0,1,0),c(0,1,1,0,0)))))\n#&gt; POLYGON ((0 0, 1 1, 0 1, 1 0, 0 0))\n\nst_is_valid(c(x2,x3))\n#&gt; [1] FALSE"
  },
  {
    "objectID": "slides/week-2.html#empty-geometries",
    "href": "slides/week-2.html#empty-geometries",
    "title": "Week 2",
    "section": "Empty Geometries",
    "text": "Empty Geometries\n\nAn important concept in the feature geometry framework is the empty geometry.\nempty geometries serve similar purposes as NA values in vectors (placeholder)\nEmpty geometries arise naturally from geometrical operations, for instance:\n\n\n\n(e = st_intersection(st_point(c(0,0)), st_point(c(1,1))))\n#&gt; GEOMETRYCOLLECTION EMPTY\n\n\nIt is not entirely clear what the benefit is of having typed empty geometries, but according to the simple feature standard they are type so the sf package abides by that.\nEmpty geometries can be detected by:\n\n\n\n\nst_is_empty(e)\n#&gt; [1] TRUE"
  },
  {
    "objectID": "slides/week-2.html#so",
    "href": "slides/week-2.html#so",
    "title": "Week 2",
    "section": "So:",
    "text": "So:\n\nThere are 17 typed geometries supported by the simple feature standard\nAll geometries are made up of points\npoints can exist in 2,3,4 Dinimsonal space\nLINESTRING and POLYGON geometries have rules that define validity\nGeometries can be empty (but are still typed)"
  },
  {
    "objectID": "slides/week-2.html#wkt-and-wkb",
    "href": "slides/week-2.html#wkt-and-wkb",
    "title": "Week 2",
    "section": "WKT and WKB",
    "text": "WKT and WKB\n\nThe simple feature standard includes two encodings: Well-known text (WKT) & well-known binary (WKB)\nWell Known Text is human-readable:\n\n\n\nx &lt;- st_linestring(matrix(10:1,5))\nst_as_text(x)\n#&gt; [1] \"LINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\"\n\n\nIn this example, the word LINESTRING provides the geometry type which is followed by a parentheses, inside the parentheses are the points that make up the geometry.\nSeparate points are separated by a ‚Äúcomma‚Äù, while the point coordinates are separated by a ‚Äúspace.‚Äù\nCoordinates are usually floating point numbers, and moving large amounts of information as text is slow and imprecise."
  },
  {
    "objectID": "slides/week-2.html#how-simple-features-are-organized-in-r",
    "href": "slides/week-2.html#how-simple-features-are-organized-in-r",
    "title": "Week 2",
    "section": "How simple features are organized in R?",
    "text": "How simple features are organized in R?\n\nSimple Features is a standard that is implemented in R (not limited to R)\nSo far we have discusses simple features the standard, rather then simple features the implementation\nIn R, simple features are implemented using standard data structures (S3 classes, lists, matrix, vector).\nAttributes are stored in data.frames (or tbl_df)\nFeature geometries are stored in a data.frame column.\nSince geometries are not single-valued, they are put in a list-column\nThis means each observation (element) is a list itself!\n\n\nRemember our nested lists?\n\nlist(list(c(1:5)))\n#&gt; [[1]]\n#&gt; [[1]][[1]]\n#&gt; [1] 1 2 3 4 5"
  },
  {
    "objectID": "slides/week-2.html#sf-sfc-sfg",
    "href": "slides/week-2.html#sf-sfc-sfg",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\nThe three classes are used to represent simple feature obejcts are:\nsf: data.frame with feature attributes and geometries\n\nwhich is contains an:\n\nsfc: the list-column with the geometries for each feature\n\n\nwhich is composed of:\n\nsfg, individual simple feature geometries"
  },
  {
    "objectID": "slides/week-2.html#sf-sfc-sfg-1",
    "href": "slides/week-2.html#sf-sfc-sfg-1",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\n\nIn the output we see:\n\nin green a simple feature: a single record (row, consisting of attributes and geometry\nin blue a single simple feature geometry (an object of class sfg)\nin red a simple feature list-column (an object of class sfc, which is a column in the data.frame)\nEven though geometries are native R objects, they are printed as well-known text"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-blue",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-blue",
    "title": "Week 2",
    "section": "sfg: simple feature geometry (blue)",
    "text": "sfg: simple feature geometry (blue)\n\n\nSimple feature geometry (sfg) objects carry the geometry for a single feature\nSimple feature geometries are implemented as R native data, using the following rules\n\na single POINT is a numeric vector\na set of points (e.g.¬†in a LINESTRING or ring of a POLYGON) is a matrix, each row containing a point\nany other set is a list\n\n\nlist of numeric matrices for MULTILINESTRING and POLYGON\nlist of lists of numeric matrices for MULTIPOLYGON\nlist of (typed) geometries for GEOMETRYCOLLECTION"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry",
    "href": "slides/week-2.html#sfg-simple-feature-geometry",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nCreator functions are rarely used in practice, since we typically read existing spatial data. But, they are useful for illustration:\n\n(x &lt;- st_point(c(1,2)))\n#&gt; POINT (1 2)\nstr(x)\n#&gt;  'XY' num [1:2] 1 2\n(x &lt;- st_linestring(matrix(c(1,2,3,4), ncol=2)))\n#&gt; LINESTRING (1 3, 2 4)\nstr(x)\n#&gt;  'XY' num [1:2, 1:2] 1 2 3 4"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-1",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-1",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAll geometry objects have a S3 class indicating their (1) dimension, (2) type, and (3) superclass\n\n(pt = st_point(c(0,1)))\n#&gt; POINT (0 1)\nattributes(pt)\n#&gt; $class\n#&gt; [1] \"XY\"    \"POINT\" \"sfg\"\n\n(pt2 = st_point(c(0,1,4)))\n#&gt; POINT Z (0 1 4)\nattributes(pt2)\n#&gt; $class\n#&gt; [1] \"XYZ\"   \"POINT\" \"sfg\""
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-2",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-2",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\n\n(m1 = rbind(c(8, 1), c(2, 5), c(3, 2)))\n#&gt;      [,1] [,2]\n#&gt; [1,]    8    1\n#&gt; [2,]    2    5\n#&gt; [3,]    3    2\n\n(mp = st_multipoint(m1))\n#&gt; MULTIPOINT ((8 1), (2 5), (3 2))\nattributes(mp)\n#&gt; $dim\n#&gt; [1] 3 2\n#&gt; \n#&gt; $class\n#&gt; [1] \"XY\"         \"MULTIPOINT\" \"sfg\"\n\n(ls = st_linestring(m1))\n#&gt; LINESTRING (8 1, 2 5, 3 2)\nattributes(ls)\n#&gt; $dim\n#&gt; [1] 3 2\n#&gt; \n#&gt; $class\n#&gt; [1] \"XY\"         \"LINESTRING\" \"sfg\""
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-3",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-3",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAlthough these geometries contain the same points (m1), they have entirely different meaning: the point set is a zero-dimensional, the line a one-dimensional geometry:\nHere, dimensions is not the XY vs XYZ, but rather whether the geometry has length (1D) or area (2D) or greater‚Ä¶\n\nst_dimension(mp)\n#&gt; [1] 0\n\nst_length(mp)\n#&gt; [1] 0\n\nst_dimension(ls)\n#&gt; [1] 1\n\nst_length(ls)\n#&gt; [1] 10.37338"
  },
  {
    "objectID": "slides/week-2.html#geometrycollection",
    "href": "slides/week-2.html#geometrycollection",
    "title": "Week 2",
    "section": "GEOMETRYCOLLECTION",
    "text": "GEOMETRYCOLLECTION\n\nSingle features (1 geometry per row) can have a single geometry, that consists of several geometries of different types.\nSuch cases arise rather naturally when looking for intersections. For instance, the intersection of two LINESTRING geometries may be the combination of a LINESTRING and a POINT.\nPutting this intersection into a single feature geometry needs a GEOMETRYCOLLECTION\n\n\n\npt &lt;- st_point(c(1, 0))\nls &lt;- st_linestring(matrix(c(4, 3, 0, 0), ncol = 2))\npoly1 &lt;- st_polygon(list(matrix(c(5.5, 7, 7, 6, 5.5, 0, 0, -0.5, -0.5, 0), ncol = 2)))\npoly2 &lt;- st_polygon(list(matrix(c(6.6, 8, 8, 7, 6.6, 1, 1, 1.5, 1.5, 1), ncol = 2)))\nmultipoly &lt;- st_multipolygon(list(poly1, poly2))\n\nst_sfc(pt, ls, poly1, poly2, multipoly)\n#&gt; Geometry set for 5 features \n#&gt; Geometry type: GEOMETRY\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 1 ymin: -0.5 xmax: 8 ymax: 1.5\n#&gt; CRS:           NA\n#&gt; POINT (1 0)\n#&gt; LINESTRING (4 0, 3 0)\n#&gt; POLYGON ((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0))\n#&gt; POLYGON ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1))\n#&gt; MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\n\n(j &lt;- st_geometrycollection(list(pt, ls, poly1, poly2, multipoly)))\n#&gt; GEOMETRYCOLLECTION (POINT (1 0), LINESTRING (4 0, 3 0), POLYGON ((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), POLYGON ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)), MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1))))"
  },
  {
    "objectID": "slides/week-2.html#sfc-sets-of-geometries",
    "href": "slides/week-2.html#sfc-sets-of-geometries",
    "title": "Week 2",
    "section": "sfc: sets of geometries",
    "text": "sfc: sets of geometries\n\nsf provides a dedicated class for handeling geometry sets, called sfc (simple feature geometry list column).\nWe can create such a list column with constructor function st_sfc:\n\n\n\n(sfc = st_sfc(st_point(c(0,1)), st_point(c(-3,2))))\n#&gt; Geometry set for 2 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -3 ymin: 1 xmax: 0 ymax: 2\n#&gt; CRS:           NA\n#&gt; POINT (0 1)\n#&gt; POINT (-3 2)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n#&gt;      [,1] [,2]\n#&gt; [1,]    0    0\n#&gt; [2,]    1    1\n#&gt; [3,]    1    0\n#&gt; [4,]    0    1"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\n#&gt; LINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc()\n\n\n\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: LINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; LINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\")\n\n\n\n#&gt; Geometry set for 4 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; POINT (0 0)\n#&gt; POINT (1 1)\n#&gt; POINT (1 0)\n#&gt; POINT (0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\n\n\n\nOn the last slide, st_sfc creates a set of one LINESTRING (p), with a size of 4.\nGoing the other way around (from set to feature), we need to combine geometries:\n\n\n\n\n\np\n#&gt; Geometry set for 4 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; POINT (0 0)\n#&gt; POINT (1 1)\n#&gt; POINT (1 0)\n#&gt; POINT (0 1)\n\n\n\nst_combine(p)\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTIPOINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; MULTIPOINT ((0 0), (1 1), (1 0), (0 1))"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n#&gt;      [,1] [,2]\n#&gt; [1,]    0    0\n#&gt; [2,]    1    1\n#&gt; [3,]    1    0\n#&gt; [4,]    0    1"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\n#&gt; LINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_cast(\"POINT\")\n\n\n\n#&gt; POINT (0 0)\n\n\n\nOn the last slide, st_sfc creates a set of one LINESTRING (p), with a size of 4.\nGoing the other way around (from set to feature), we need to combine geometries:\n\n\n\n\n\np\n#&gt; Geometry set for 4 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; POINT (0 0)\n#&gt; POINT (1 1)\n#&gt; POINT (1 0)\n#&gt; POINT (0 1)\n\n\n\nst_combine(p)\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTIPOINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; MULTIPOINT ((0 0), (1 1), (1 0), (0 1))"
  },
  {
    "objectID": "slides/week-2.html#casting-must-be-done-the-level-of-the-feature",
    "href": "slides/week-2.html#casting-must-be-done-the-level-of-the-feature",
    "title": "Week 2",
    "section": "Casting must be done the level of the feature",
    "text": "Casting must be done the level of the feature\nIf we want to go from the 4 feature (p) object to a 1 feature LINESTRING, we must combine before casting ‚Ä¶\n\nst_combine(p) |&gt; \n  st_cast(\"LINESTRING\")\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: LINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; LINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#mixed-geometries",
    "href": "slides/week-2.html#mixed-geometries",
    "title": "Week 2",
    "section": "Mixed geometries",
    "text": "Mixed geometries\nSets of simple features also consist of features with heterogeneous geometries. In this case, the geometry type of the set is GEOMETRY:\n\n\n\n(g = st_sfc(st_point(c(0,0)), \n            st_linestring(rbind(c(0,0), c(1,1)))))\n#&gt; Geometry set for 2 features \n#&gt; Geometry type: GEOMETRY\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; POINT (0 0)\n#&gt; LINESTRING (0 0, 1 1)\n\n\nThese set can be filtered by using st_is\n\ng |&gt; st_is(\"LINESTRING\")\n#&gt; [1] FALSE  TRUE\n\nor, when working with sf objects,\n\n# Note need of %&gt;%\nst_sf(g) %&gt;%\n  filter(st_is(., \"LINESTRING\"))\n#&gt; Simple feature collection with 1 feature and 0 fields\n#&gt; Geometry type: LINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt;                       g\n#&gt; 1 LINESTRING (0 0, 1 1)"
  },
  {
    "objectID": "slides/week-2.html#sf-objects-with-simple-features",
    "href": "slides/week-2.html#sf-objects-with-simple-features",
    "title": "Week 2",
    "section": "sf: objects with simple features",
    "text": "sf: objects with simple features\nSimple features geometries and feature attributes are put together in sf (simple feature) objects.\n\nco\n#&gt; Simple feature collection with 64 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    geoid       name      aland state_nm                       geometry\n#&gt; 1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n#&gt; 2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n#&gt; 3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n#&gt; 4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n#&gt; 5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n#&gt; 6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n#&gt; 7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n#&gt; 8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n#&gt; 9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n#&gt; 10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3...\n\nThis sf object is of class\n\nclass(co)\n#&gt; [1] \"sf\"         \"data.frame\"\n\nmeaning it extends data.frame, but with a single list-column with geometries, which is held in the column named:\n\nattr(co, \"sf_column\")\n#&gt; [1] \"geometry\""
  },
  {
    "objectID": "slides/week-2.html#sfc-simple-feature-geometry-list-column",
    "href": "slides/week-2.html#sfc-simple-feature-geometry-list-column",
    "title": "Week 2",
    "section": "sfc: simple feature geometry list-column",
    "text": "sfc: simple feature geometry list-column\nThe column in the sf data.frame that contains the geometries is a list, of class sfc.\nWe can retrieve the geometry list-column as we would any data.frame column (e.g.¬†co$geometry), or more generally with st_geometry:\n\n(co_geom &lt;- st_geometry(co))\n#&gt; Geometry set for 64 features \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 5 geometries:\n#&gt; MULTIPOLYGON (((-105.0532 39.79106, -104.976 39...\n#&gt; MULTIPOLYGON (((-105.4855 37.5779, -105.4859 37...\n#&gt; MULTIPOLYGON (((-103.7065 39.73989, -103.7239 3...\n#&gt; MULTIPOLYGON (((-107.1287 37.42294, -107.2803 3...\n#&gt; MULTIPOLYGON (((-102.0416 37.64428, -102.0558 3...\n\nGeometries are printed in abbreviated form, but we can view a complete geometry by selecting it:\n\nco_geom[[1]]\n#&gt; MULTIPOLYGON (((-105.0532 39.79106, -104.976 39.79104, -104.9731 39.79242, -104.9716 39.79829, -104.9687 39.7984, -104.9689 39.79104, -104.9602 39.79102, -104.9554 39.79463, -104.9405 39.7946, -104.9405 39.791, -104.927 39.79105, -104.927 39.78378, -104.9034 39.78381, -104.9036 39.79839, -104.8845 39.79832, -104.8844 39.81282, -104.8661 39.81285, -104.866 39.79839, -104.8291 39.79806, -104.7909 39.79825, -104.7909 39.8418, -104.7623 39.84179, -104.7623 39.84539, -104.731 39.84519, -104.7304 39.89613, -104.7033 39.89595, -104.7032 39.90693, -104.6921 39.90685, -104.6921 39.91418, -104.6796 39.91402, -104.6797 39.90701, -104.6309 39.90664, -104.6309 39.89929, -104.5996 39.89904, -104.5998 39.88131, -104.6052 39.88135, -104.6053 39.87311, -104.6192 39.87322, -104.6198 39.82242, -104.6554 39.82261, -104.6554 39.813, -104.6662 39.81307, -104.6661 39.82279, -104.7625 39.82344, -104.7626 39.79843, -104.7344 39.79844, -104.7346 39.76918, -104.7646 39.76919, -104.7646 39.77157, -104.7722 39.7715, -104.7722 39.77641, -104.7816 39.77648, -104.7816 39.7728, -104.8282 39.77278, -104.8282 39.76916, -104.833 39.76918, -104.8376 39.76717, -104.8564 39.76858, -104.8563 39.75813, -104.8482 39.75642, -104.8469 39.75469, -104.8799 39.75473, -104.88 39.74744, -104.8847 39.74747, -104.8846 39.74016, -104.8217 39.74029, -104.7256 39.74027, -104.6783 39.74, -104.6603 39.74048, -104.6528 39.73978, -104.6304 39.7395, -104.6246 39.74008, -104.5589 39.73933, -104.5074 39.73825, -104.3919 39.73804, -104.3401 39.73825, -104.265 39.73888, -104.2095 39.73902, -104.1151 39.73977, -104.0407 39.73998, -103.9776 39.74027, -103.9655 39.74052, -103.9075 39.74065, -103.8661 39.74024, -103.8002 39.7402, -103.794 39.74005, -103.7239 39.73978, -103.7065 39.73989, -103.7066 39.76555, -103.7063 39.82855, -103.7063 39.889, -103.7061 39.90854, -103.7062 39.95888, -103.7057 39.98511, -103.7057 40.00137, -103.8677 40.0012, -103.9546 40.00113, -104.0371 40.00113, -104.1503 40.00086, -104.1693 40.00078, -104.2674 40.00092, -104.3015 40.00077, -104.4523 40.00062, -104.6019 40.00053, -104.6406 40.00057, -104.7885 40.00041, -104.9048 40.00032, -104.9614 40.00034, -104.9809 40.00032, -104.9877 39.98648, -104.9878 39.97575, -104.9944 39.9758, -104.9971 39.97215, -104.9881 39.97218, -104.9881 39.96847, -104.9972 39.96853, -104.9974 39.98121, -105.0158 39.98119, -105.0156 39.95519, -105.0171 39.95281, -105.0122 39.95045, -105.0063 39.95044, -105.0063 39.9468, -104.9972 39.94677, -104.9971 39.94324, -105.0157 39.94313, -105.0155 39.9214, -105.0344 39.9213, -105.0343 39.91418, -105.0529 39.91422, -105.0532 39.86362, -105.0532 39.79106)))"
  },
  {
    "objectID": "slides/week-2.html#reading-and-writing",
    "href": "slides/week-2.html#reading-and-writing",
    "title": "Week 2",
    "section": "Reading and writing",
    "text": "Reading and writing\nAs we‚Äôve seen above, reading spatial data from an external file can be done via sf - reading data requires the ‚Äúparser function‚Äù and the file path\n\n#&gt; Reading layer `co' from data source \n#&gt;   `/Users/mikejohnson/github/csu-ess-523c/slides/data/co.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 64 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n\nwe can suppress the output by adding argument quiet=TRUE or by using the otherwise nearly identical but more quiet\n\nco &lt;- read_sf(\"data/co.shp\")\n\nWriting takes place in the same fashion, using st_write:\n\nst_write(co, \"data/co.shp\")\n\nor its quiet alternative that silently overwrites existing files by default,\n\nwrite_sf(co, \"co.shp\") # silently overwrites"
  },
  {
    "objectID": "slides/week-2.html#from-tables-e.g.-csv",
    "href": "slides/week-2.html#from-tables-e.g.-csv",
    "title": "Week 2",
    "section": "From Tables (e.g.¬†CSV)",
    "text": "From Tables (e.g.¬†CSV)\nSpatial data can also be created from CSV and other flat files once it is in R:\n\n(cities = readr::read_csv(\"../labs/data/uscities.csv\") |&gt; \n  select(city, state_name, county_name, population, lat, lng) )\n#&gt; # A tibble: 31,254 √ó 6\n#&gt;    city         state_name           county_name         population   lat    lng\n#&gt;    &lt;chr&gt;        &lt;chr&gt;                &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt;  1 New York     New York             Queens                18832416  40.7  -73.9\n#&gt;  2 Los Angeles  California           Los Angeles           11885717  34.1 -118. \n#&gt;  3 Chicago      Illinois             Cook                   8489066  41.8  -87.7\n#&gt;  4 Miami        Florida              Miami-Dade             6113982  25.8  -80.2\n#&gt;  5 Houston      Texas                Harris                 6046392  29.8  -95.4\n#&gt;  6 Dallas       Texas                Dallas                 5843632  32.8  -96.8\n#&gt;  7 Philadelphia Pennsylvania         Philadelphia           5696588  40.0  -75.1\n#&gt;  8 Atlanta      Georgia              Fulton                 5211164  33.8  -84.4\n#&gt;  9 Washington   District of Columbia District of Columb‚Ä¶    5146120  38.9  -77.0\n#&gt; 10 Boston       Massachusetts        Suffolk                4355184  42.3  -71.1\n#&gt; # ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2.html#data-manipulation",
    "href": "slides/week-2.html#data-manipulation",
    "title": "Week 2",
    "section": "Data Manipulation",
    "text": "Data Manipulation\n\nSince sf objects are data.frames, our dplyr verbs work!\nLets find the most populous city in each Colorado county‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr",
    "href": "slides/week-2.html#sf-and-dplyr",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf\n\n\n\n#&gt; Simple feature collection with 31254 features and 4 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -176.6295 ymin: 17.9559 xmax: 174.111 ymax: 71.2727\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 31,254 √ó 5\n#&gt;    city         state_name      county_name population            geometry\n#&gt;  * &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n#&gt;  1 New York     New York        Queens        18832416  (-73.9249 40.6943)\n#&gt;  2 Los Angeles  California      Los Angeles   11885717 (-118.4068 34.1141)\n#&gt;  3 Chicago      Illinois        Cook           8489066  (-87.6866 41.8375)\n#&gt;  4 Miami        Florida         Miami-Dade     6113982   (-80.2101 25.784)\n#&gt;  5 Houston      Texas           Harris         6046392   (-95.3885 29.786)\n#&gt;  6 Dallas       Texas           Dallas         5843632  (-96.7667 32.7935)\n#&gt;  7 Philadelphia Pennsylvania    Philadelph‚Ä¶    5696588  (-75.1339 40.0077)\n#&gt;  8 Atlanta      Georgia         Fulton         5211164   (-84.422 33.7628)\n#&gt;  9 Washington   District of Co‚Ä¶ District o‚Ä¶    5146120  (-77.0163 38.9047)\n#&gt; 10 Boston       Massachusetts   Suffolk        4355184  (-71.0852 42.3188)\n#&gt; # ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-1",
    "href": "slides/week-2.html#sf-and-dplyr-1",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\")\n\n\n\n#&gt; Simple feature collection with 477 features and 4 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 477 √ó 5\n#&gt;    city             state_name county_name population            geometry\n#&gt;  * &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n#&gt;  1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n#&gt;  2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n#&gt;  3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n#&gt;  4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n#&gt;  5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n#&gt;  6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n#&gt;  7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n#&gt;  8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n#&gt;  9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n#&gt; 10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n#&gt; # ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-2",
    "href": "slides/week-2.html#sf-and-dplyr-2",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name)\n\n\n\n#&gt; Simple feature collection with 477 features and 4 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 477 √ó 5\n#&gt; # Groups:   county_name [64]\n#&gt;    city             state_name county_name population            geometry\n#&gt;    &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n#&gt;  1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n#&gt;  2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n#&gt;  3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n#&gt;  4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n#&gt;  5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n#&gt;  6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n#&gt;  7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n#&gt;  8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n#&gt;  9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n#&gt; 10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n#&gt; # ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-3",
    "href": "slides/week-2.html#sf-and-dplyr-3",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1)\n\n\n\n#&gt; Simple feature collection with 64 features and 4 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -108.9071 ymin: 37.1751 xmax: -102.2627 ymax: 40.9849\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 64 √ó 5\n#&gt; # Groups:   county_name [64]\n#&gt;    city           state_name county_name population            geometry\n#&gt;    &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n#&gt;  1 Thornton       Colorado   Adams           142878 (-104.9438 39.9197)\n#&gt;  2 Alamosa        Colorado   Alamosa           9847  (-105.877 37.4752)\n#&gt;  3 Aurora         Colorado   Arapahoe        390201 (-104.7237 39.7083)\n#&gt;  4 Pagosa Springs Colorado   Archuleta         1718 (-107.0307 37.2675)\n#&gt;  5 Springfield    Colorado   Baca              1482  (-102.6189 37.405)\n#&gt;  6 Las Animas     Colorado   Bent              2480 (-103.2236 38.0695)\n#&gt;  7 Boulder        Colorado   Boulder         120121 (-105.2524 40.0248)\n#&gt;  8 Broomfield     Colorado   Broomfield       75110 (-105.0526 39.9542)\n#&gt;  9 Salida         Colorado   Chaffee           5786 (-105.9979 38.5298)\n#&gt; 10 Cheyenne Wells Colorado   Cheyenne           949 (-102.3521 38.8192)\n#&gt; # ‚Ñπ 54 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-4",
    "href": "slides/week-2.html#sf-and-dplyr-4",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1) -&gt;\n  co_cities"
  },
  {
    "objectID": "slides/week-2.html#plotting",
    "href": "slides/week-2.html#plotting",
    "title": "Week 2",
    "section": "Plotting",
    "text": "Plotting\n\nWe‚Äôve already seen that ggplot() is a powerful visualization tool:\nThe 5 steps we described for building a ggplot are:\n\ncanvas\nlayers (geoms)\nlabels\nfacets\nthemes\n\nspatial work in R is becoming so common that ggplot() comes with a sf geom (geom_sf)"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot",
    "href": "slides/week-2.html#sf-an-ggplot",
    "title": "Week 2",
    "section": "sf an ggplot",
    "text": "sf an ggplot\n\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-1",
    "href": "slides/week-2.html#sf-an-ggplot-1",
    "title": "Week 2",
    "section": "sf an ggplot",
    "text": "sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10))"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-2",
    "href": "slides/week-2.html#sf-an-ggplot-2",
    "title": "Week 2",
    "section": "sf an ggplot",
    "text": "sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\")"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-3",
    "href": "slides/week-2.html#sf-an-ggplot-3",
    "title": "Week 2",
    "section": "sf an ggplot",
    "text": "sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-4",
    "href": "slides/week-2.html#sf-an-ggplot-4",
    "title": "Week 2",
    "section": "sf an ggplot",
    "text": "sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw() +\n  labs(title = \"Colorado Counties: Land Area\",\n       size = \"Population \\n(100,000)\",\n       fill = \"Acres \\n(billions)\")"
  },
  {
    "objectID": "labs/lab3.html",
    "href": "labs/lab3.html",
    "title": "Lab 3: Tesselations, Point-in-Polygon",
    "section": "",
    "text": "Background\nIn this lab we will an explore the impacts of tessellated surfaces and the modifiable areal unit problem (MAUP) using the National Dam Inventory maintained by the United States Army Corps of Engineers. Doing this will require repetitive tasks that we will write as functions and careful consideration of feature aggregation/simplification, spatial joins, and data visualization. The end goal is to visualize the distribution of dams and there purposes across the country.\nDISCLAIMER: This lab will be crunching a TON of data, in some cases 562,590,604 values for a single process! Therefore, I encourage you to run your code chuck-by-chunk rather then regularly knitting. Your final knit may take a couple of minutes to process. I know this is painful but be proud that, all said, your report will be analyzing billions of meaningful data and geometric relations.\n\nThis labs covers 4 main skills:\n\nTessellating Surfaces to discritized space\nGeometry Simplification: to expedite expensive intersections\nWriting functions to expedite repetitious reporting and mapping tasks\nPoint-in-polygon counts to aggregate point data\n\n\nLibraries\n\n\n\n\nQuestion 1:\nHere we will prepare five tessellated surfaces from CONUS and write a function to plot them in a descriptive way.\n\nStep 1.1\nFirst, we need a spatial file of CONUS counties. For future area calculations we want these in an equal area projection (EPSG:5070).\nTo achieve this:\n\nget an sf object of US counties (AOI::aoi_get(state = \"conus\", county = \"all\"))\ntransform the data to EPSG:5070\n\n\n\nStep 1.2\nFor triangle based tessellations we need point locations to serve as our ‚Äúanchors‚Äù.\nTo achieve this:\n\ngenerate county centroids using st_centroid\nSince, we can only tessellate over a feature we need to combine or union the resulting 3,108 POINT features into a single MULTIPOINT feature\nSince these are point objects, the difference between union/combine is mute\n\n\n\nStep 1.3\nTessellations/Coverage‚Äôs describe the extent of a region with geometric shapes, called tiles, with no overlaps or gaps.\nTiles can range in size, shape, area and have different methods for being created.\nSome methods generate triangular tiles across a set of defined points (e.g.¬†voroni and delauny triangulation)\nOthers generate equal area tiles over a known extent (st_make_grid)\nFor this lab, we will create surfaces of CONUS using using 4 methods, 2 based on an extent and 2 based on point anchors:\nTessellations :\n\nst_voroni: creates voroni tessellation\nst_traingulate: triangulates set of points (not constrained)\n\nCoverage‚Äôs:\n\nst_make_grid: Creates a square grid covering the geometry of an sf or sfc object\nst_make_grid(square = FALSE): Create a hexagonal grid covering the geometry of an sf or sfc object\nThe side of coverage tiles can be defined by a cell resolution or a specified number of cell in the X and Y direction\n\n\nFor this step:\n\nMake a voroni tessellation over your county centroids (MULTIPOINT)\nMake a triangulated tessellation over your county centroids (MULTIPOINT)\nMake a gridded coverage with n = 70, over your counties object\nMake a hexagonal coverage with n = 70, over your counties object\n\nIn addition to creating these 4 coverage‚Äôs we need to add an ID to each tile.\nTo do this:\n\nadd a new column to each tessellation that spans from 1:n().\nRemember that ALL tessellation methods return an sfc GEOMETRYCOLLECTION, and to add attribute information - like our ID - you will have to coerce the sfc list into an sf object (st_sf or st_as_sf)\n\nLast, we want to ensure that our surfaces are topologically valid/simple.\n\nTo ensure this, we can pass our surfaces through st_cast.\nRemember that casting an object explicitly (e.g.¬†st_cast(x, \"POINT\")) changes a geometry\nIf no output type is specified (e.g.¬†st_cast(x)) then the cast attempts to simplify the geometry.\nIf you don‚Äôt do this you might get unexpected ‚ÄúTopologyException‚Äù errors.\n\n\n\nStep 1.4\nIf you plot the above tessellations you‚Äôll see the triangulated surfaces produce regions far beyond the boundaries of CONUS.\nWe need to cut these boundaries to CONUS border.\nTo do this, we will call on st_intersection, but will first need a geometry of CONUS to serve as our differencing feature. We can get this by unioning our existing county boundaries.\n\n\nStep 1.5\nWith a single feature boundary, we must carefully consider the complexity of the geometry. Remember, the more points our geometry contains, the more computations needed for spatial predicates our differencing. For a task like ours, we do not need a finely resolved coastal boarder.\nTo achieve this:\n\nSimplify your unioned border using the Visvalingam algorithm provided by rmapshaper::ms_simplify.\nChoose what percentage of vertices to retain using the keep argument and work to find the highest number that provides a shape you are comfortable with for the analysis:\n\n\nOnce you are happy with your simplification, use the mapview::npts function to report the number of points in your original object, and the number of points in your simplified object.\nHow many points were you able to remove? What are the consequences of doing this computationally?\n\n\nFinally, use your simplified object to crop the two triangulated tessellations with st_intersection:\n\n\n\nStep 1.6\nThe last step is to plot your tessellations. We don‚Äôt want to write out 5 ggplots (or mindlessly copy and paste üòÑ)\nInstead, lets make a function that takes an sf object as arg1 and a character string as arg2 and returns a ggplot object showing arg1 titled with arg2.\n\nThe form of a function is:\n\nname = function(arg1, arg2) {\n  \n  ... code goes here ...\n  \n}\n\n\nFor this function:\n\nThe name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string that will title the plot\nIn your function, the code should follow our standard ggplot practice where your data is arg1, and your title is arg2\nThe function should also enforce the following:\n\na white fill\na navy border\na size of 0.2\n`theme_void``\na caption that reports the number of features in arg1\n\nYou will need to paste character stings and variables together.\n\n\n\n\n\nStep 1.7\nUse your new function to plot each of your tessellated surfaces and the original county data (5 plots in total):\n\n\n\nQuestion 2:\nIn this question, we will write out a function to summarize our tessellated surfaces. Most of this should have been done in your daily assignments.\n\nStep 2.1\nFirst, we need a function that takes a sf object and a character string and returns a data.frame.\nFor this function:\n\nThe function name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string describing the object\nIn your function, calculate the area of arg1; convert the units to km2; and then drop the units\nNext, create a data.frame containing the following:\n\ntext from arg2\nthe number of features in arg1\nthe mean area of the features in arg1 (km2)\nthe standard deviation of the features in arg1\nthe total area (km2) of arg1\n\nReturn this data.frame\n\n\n\nStep 2.2\nUse your new function to summarize each of your tessellations and the original counties.\n\n\nStep 2.3\nMultiple data.frame objects can bound row-wise with bind_rows into a single data.frame\nFor example, if your function is called sum_tess, the following would bind your summaries of the triangulation and voroni object.\n\n\nStep 2.4\nOnce your 5 summaries are bound (2 tessellations, 2 coverage‚Äôs, and the raw counties) print the data.frame as a nice table using knitr/kableExtra.\n\n\nStep 2.5\nComment on the traits of each tessellation. Be specific about how these traits might impact the results of a point-in-polygon analysis in the contexts of the modifiable areal unit problem and with respect computational requirements.\n\n\n\n\nQuestion 3:\nThe data we are going to analysis in this lab is from US Army Corp of Engineers National Dam Inventory (NID). This dataset documents ~91,000 dams in the United States and a variety of attribute information including design specifications, risk level, age, and purpose.\nFor the remainder of this lab we will analysis the distributions of these dams (Q3) and their purpose (Q4) through using a point-in-polygon analysis.\n\nStep 3.1\nIn the tradition of this class - and true to data science/GIS work - you need to find, download, and manage raw data. While the raw NID data is no longer easy to get with the transition of the USACE services to ESRI Features Services, I staged the data in the resources directory of this class. To get it, navigate to that location and download the raw file into you lab data directory.\n\nReturn to your RStudio Project and read the data in using the readr::read_csv\n\nAfter reading the data in, be sure to remove rows that don‚Äôt have location values (!is.na())\nConvert the data.frame to a sf object by defining the coordinates and CRS\nTransform the data to a CONUS AEA (EPSG:5070) projection - matching your tessellation\nFilter to include only those within your CONUS boundary\n\n\n\ndams = readr::read_csv('../labs/data/NID2019_U.csv') \n\nusa &lt;- AOI::aoi_get(state = \"conus\") %&gt;% \n  st_union() %&gt;% \n  st_transform(5070)\n\ndams2 = dams %&gt;% \n  filter(!is.na(LATITUDE) ) %&gt;%\n  st_as_sf(coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4236) %&gt;% \n  st_transform(5070) %&gt;% \n  st_filter(usa)\n\n\n\nStep 3.2\nFollowing the in-class examples develop an efficient point-in-polygon function that takes:\n\npoints as arg1,\npolygons as arg2,\nThe name of the id column as arg3\n\nThe function should make use of spatial and non-spatial joins, sf coercion and dplyr::count. The returned object should be input sf object with a column - n - counting the number of points in each tile.\n\n\nStep 3.3\nApply your point-in-polygon function to each of your five tessellated surfaces where:\n\nYour points are the dams\nYour polygons are the respective tessellation\nThe id column is the name of the id columns you defined.\n\n\n\nStep 3.4\nLets continue the trend of automating our repetitive tasks through function creation. This time make a new function that extends your previous plotting function.\nFor this function:\n\nThe name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string that will title the plot\nThe function should also enforce the following:\n\nthe fill aesthetic is driven by the count column n\nthe col is NA\nthe fill is scaled to a continuous viridis color ramp\ntheme_void\na caption that reports the number of dams in arg1 (e.g.¬†sum(n))\n\nYou will need to paste character stings and variables together.\n\n\n\n\n\nStep 3.5\nApply your plotting function to each of the 5 tessellated surfaces with Point-in-Polygon counts:\n\n\nStep 3.6\nComment on the influence of the tessellated surface in the visualization of point counts. How does this related to the MAUP problem. Moving forward you will only use one tessellation, which will you chose and why?\nWhile there is not ‚Äúright‚Äù answer, justify your selection here.\n\n\n\nQuestion 4\nThe NID provides a comprehensive data dictionary here. In it we find that dam purposes are designated by a character code.\nThese are shown below for convenience (built using knitr on a data.frame called nid_classifier):\n\n\n\nNID 2019: Dam Purposes\n\n\nabbr\npurpose\n\n\n\n\nI\nIrrigation\n\n\nH\nHydroelectric\n\n\nC\nFlood Control\n\n\nN\nNavigation\n\n\nS\nWater Supply\n\n\nR\nRecreation\n\n\nP\nFire Protection\n\n\nF\nFish and Wildlife\n\n\nD\nDebris Control\n\n\nT\nTailings\n\n\nG\nGrade Stabilization\n\n\nO\nOther\n\n\n\n\n\n\n\n\nIn the data dictionary, we see a dam can have multiple purposes.\nIn these cases, the purpose codes are concatenated in order of decreasing importance. For example, SCR would indicate the primary purposes are Water Supply, then Flood Control, then Recreation.\nA standard summary indicates there are over 400 unique combinations of dam purposes:\n\n\nunique(dams2$PURPOSES) %&gt;% length()\n\n[1] 494\n\n\n\nBy storing dam codes as a concatenated string, there is no easy way to identify how many dams serve any one purpose‚Ä¶ for example where are the hydro electric dams?\n\n\nTo overcome this data structure limitation, we can identify how many dams serve each purpose by splitting the PURPOSES values (strsplit) and tabulating the unlisted results as a data.frame. Effectively this is double/triple/quadruple counting dams bases on how many purposes they serve:\n\n\nJoining with `by = join_by(abbr)`\n\n\nThe result of this would indicate:\n\n\n\n\n\n\n\n\n\n\nStep 4.1\n\nYour task is to create point-in-polygon counts for at least 4 of the above dam purposes:\nYou will use grepl to filter the complete dataset to those with your chosen purpose\nRemember that grepl returns a boolean if a given pattern is matched in a string\ngrepl is vectorized so can be used in dplyr::filter\n\n\nFor example:\n\n# Find flood control dams in the first 5 records:\ndams2$PURPOSES[1:5]\n\n[1] \"FR\" \"R\"  \"C\"  \"FR\" \"R\" \n\ngrepl(\"F\", dams2$PURPOSES[1:5])\n\n[1]  TRUE FALSE FALSE  TRUE FALSE\n\n\n\nFor your analysis, choose at least four of the above codes, and describe why you chose them. Then for each of them, create a subset of dams that serve that purpose using dplyr::filter and grepl\nFinally, use your point-in-polygon function to count each subset across your elected tessellation\n\n\nStep 4.2\n\nNow use your plotting function from Q3 to map these counts.\nBut! you will use gghighlight to only color those tiles where the count (n) is greater then the (mean + 1 standard deviation) of the set\nSince your plotting function returns a ggplot object already, the gghighlight call can be added ‚Äú+‚Äù directly to the function.\nThe result of this exploration is to highlight the areas of the country with the most\n\n\n\nStep 4.3\nComment of geographic distribution of dams you found. Does it make sense? How might the tessellation you chose impact your findings? How does the distribution of dams coincide with other geographic factors such as river systems, climate, ect?\n\n\n\nQuestion 5:\nYou have also been asked to identify the largest, at risk, flood control dams in the country\nYou must also map the Mississippi River System - This data is available here - Download the shapefile and unzip it into your data directory. - Use read_sf to import this data and filter it to only include the Mississippi SYSTEM\nTo achieve this:\nCreate an interactive map using leaflet to show the largest (NID_STORAGE); high-hazard (HAZARD == ‚ÄúH‚Äù) dam in each state\n\nThe markers should be drawn as opaque, circle markers, filled red with no border, and a radius set equal to the (NID_Storage / 1,500,000)\nThe map tiles should be selected from any of the tile providers\nA popup table should be added using leafem::popup and should only include the dam name, storage, purposes, and year completed.\nThe Mississippi system should be added at a Polyline feature.\n\n\n\n\nRubric\n\nQuestion 1: Tessellations (30)\nQuestion 2: Tessellation Comparison (30)\nQuestion 3: PIP (30)\nQuestion 4: Conditional PIP (30)\nQuestion 5: Dam Age (20)\nWell Structured and appealing Qmd deployed as web page (10)\n\nTotal: 150\n\n\nSubmission\nYou will submit a URL to your web page deployed with GitHub pages.\nTo do this:\n\nRender your lab document\nStage/commit/push your files\nIf you followed the naming conventions in the ‚ÄúSet Up‚Äù of lab 1, your lab 3 link will be available at:\n\nhttps://USERNAME.github.io/csu-523c/lab-03.html\nSubmit this URL in the appropriate Canvas dropbox. Also take a moment to update your personal webpage with this link and some bullet points of what you learned. While not graded as part of this lab, it will be extra credit!"
  },
  {
    "objectID": "slides/week-2-1.html#simple-features",
    "href": "slides/week-2-1.html#simple-features",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features"
  },
  {
    "objectID": "slides/week-2-1.html#todays-data",
    "href": "slides/week-2-1.html#todays-data",
    "title": "Week 2",
    "section": "Todays Data:",
    "text": "Todays Data:\n\nSimple feature collection with 64 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   geoid       name      aland state_nm                       geometry\n1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3..."
  },
  {
    "objectID": "slides/week-2-1.html#simple-features-1",
    "href": "slides/week-2-1.html#simple-features-1",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features\n\nSimple feature geometries describe the geometries of features.\nThe main application of simple feature geometries is to describe 2D geometries as points, lines, or polygons.\n‚Äúsimple‚Äù refers to the fact that line or polygon geometries are represented by set of points connected with straight lines.\nSimple features access is a standard (Herring 2011, Herring (2010), ISO (2004)) for describing simple feature geometries via:\n\na class hierarchy\na set of operations\nbinary and text encodings"
  },
  {
    "objectID": "slides/week-2-1.html#simple-features-access",
    "href": "slides/week-2-1.html#simple-features-access",
    "title": "Week 2",
    "section": "Simple Features Access",
    "text": "Simple Features Access\n\nSimple features or simple feature access refers to the formal standard (ISO 19125-1:2004) describing how objects in the real world can be represented in computers, with emphasis on the spatial geometry of these objects.\nIt also describes how objects can be stored in and retrieved from databases, and which geometrical operations should/can be defined for them.\nThe standard is widely implemented in spatial databases (such as PostGIS), commercial GIS (e.g., ESRI ArcGIS) and forms the vector data basis for libraries such as GDAL.\nA subset of simple features (e.g.¬†the big 7) forms the GeoJSON specification.\nR has well-supported classes for storing spatial data (sp) and interfacing to the above mentioned environments (rgdal, rgeos), but has so far lacked a complete implementation of simple features, making conversions at times convoluted, inefficient or incomplete.\nsf is seeking to fill this gap and has/will succeed sp"
  },
  {
    "objectID": "slides/week-2-1.html#so-what-is-a-feature",
    "href": "slides/week-2-1.html#so-what-is-a-feature",
    "title": "Week 2",
    "section": "So what is a feature?",
    "text": "So what is a feature?\n\nA feature is a thing (object) in the real world, such as a building or a river\nThey often consist of other objects.\n\nA river system can be a feature, a river can be a feature, a river outlet can be a feature.\nA image pixel can be a feature, and the image can be a feature‚Ä¶"
  },
  {
    "objectID": "slides/week-2-1.html#spatial-features",
    "href": "slides/week-2-1.html#spatial-features",
    "title": "Week 2",
    "section": "Spatial Features",
    "text": "Spatial Features\n\nThe standard says: ‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes. Spatial attributes are geometry valued, and simple features are based on 2D geometry with linear interpolation between vertices.‚Äù - standard.\nSpatial Features have a geometry describing where the feature is located and how it is represented.\n\n\nstr(co$geometry)\nsfc_MULTIPOLYGON of length 64; first list element: List of 1\n $ :List of 1\n  ..$ : num [1:132, 1:2] -105 -105 -105 -105 -105 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n\n\nThe geometry of a river can be its watershed, of its mainstem, or the point it drains to (see the OGC HY_Feature standard)\nFeatures can have attributes describing other properties of the feature\nOther properties may include its length, slope, stream order or average flowrate"
  },
  {
    "objectID": "slides/week-2-1.html#geometry-types",
    "href": "slides/week-2-1.html#geometry-types",
    "title": "Week 2",
    "section": "Geometry types",
    "text": "Geometry types\nThe following 7 simple feature types are the most common, and are the only ones used for GeoJSON:\n\n\n\n\n\n\n\nSINGLE\nDescription\n\n\n\n\nPOINT\nzero-dimensional geometry containing a single point\n\n\nLINESTRING\nsequence of points connected by straight, non-self intersecting line pieces; one-dimensional geometry\n\n\nPOLYGON\ngeometry with a positive area (two-dimensional); sequence of points form a closed, non-self intersecting ring; the first ring denotes the exterior ring, zero or more subsequent rings denote holes in this exterior ring\n\n\n\n\n\n\n\n\n\n\nMULTI (same typed)\nDescription\n\n\n\n\nMULTIPOINT\nset of points; a MULTIPOINT is simple if no two Points in the MULTIPOINT are equal\n\n\nMULTILINESTRING\nset of linestrings\n\n\nMULTIPOLYGON\nset of polygons\n\n\n\n\n\n\n\n\n\n\nMulti-Typed\nDescription\n\n\n\n\nGEOMETRYCOLLECTION\nset of geometries of any type except GEOMETRYCOLLECTION\n\n\n\n\nThe descriptions above were copied from the PostGIS manual."
  },
  {
    "objectID": "slides/week-2-1.html#dimensions",
    "href": "slides/week-2-1.html#dimensions",
    "title": "Week 2",
    "section": "Dimensions",
    "text": "Dimensions\nAll geometries are composed of points\n\nPoints are defined by coordinates in a 2-, 3- or 4-D space.\nIn addition to XY coordinates, there are two optional dimensions:\na Z coordinate, denoting altitude\nan M coordinate (rarely used), denoting some measure\nThe M describes a property of the vertex that is independent of the feature.\nIt sounds attractive to encode a time as M, however these quickly become invalid once the path self-intersects.\nBoth Z and M are found relatively rarely, and software support to do something useful with them is rarer still."
  },
  {
    "objectID": "slides/week-2-1.html#valid-geometries",
    "href": "slides/week-2-1.html#valid-geometries",
    "title": "Week 2",
    "section": "Valid geometries",
    "text": "Valid geometries\nValid geometries obey the following properties:\n\nLINESTRINGS shall not self-intersect\nPOLYGON rings shall be closed (last point = first point)\nPOLYGON holes (inner rings) shall be inside their exterior ring\nPOLYGON inner rings shall maximally touch the exterior ring in single points, not over a line\nPOLYGON rings shall not repeat their own path\n\nIf any of the above is not the case, the geometry is not valid."
  },
  {
    "objectID": "slides/week-2-1.html#non-simple-and-non-valid-geometries",
    "href": "slides/week-2-1.html#non-simple-and-non-valid-geometries",
    "title": "Week 2",
    "section": "Non-simple and non-valid geometries",
    "text": "Non-simple and non-valid geometries\nst_is_simple and st_is_valid provide methods to help detect non-simple and non-valid geometries:\n\nAn example of a non-simple geometries is a self-intersecting lines;\n\n\n(x1 &lt;- st_linestring(cbind(c(0,1,0,1),c(0,1,1,0))))\nLINESTRING (0 0, 1 1, 0 1, 1 0)\nst_is_simple(x1)\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\n\nAn example of a non-valid geometry are would be a polygon with slivers or self-intersections.\n\n\n(x2 &lt;- st_polygon(list(cbind(c(0,1,1,1,0,0),c(0,0,1,0.6,1,0)))))\nPOLYGON ((0 0, 1 0, 1 1, 1 0.6, 0 1, 0 0))\n(x3 &lt;- st_polygon(list(cbind(c(0,1,0,1,0),c(0,1,1,0,0)))))\nPOLYGON ((0 0, 1 1, 0 1, 1 0, 0 0))\n\nst_is_valid(c(x2,x3))\n[1] FALSE"
  },
  {
    "objectID": "slides/week-2-1.html#empty-geometries",
    "href": "slides/week-2-1.html#empty-geometries",
    "title": "Week 2",
    "section": "Empty Geometries",
    "text": "Empty Geometries\n\nAn important concept in the feature geometry framework is the empty geometry.\nempty geometries serve similar purposes as NA values in vectors (placeholder)\nEmpty geometries arise naturally from geometrical operations, for instance:\n\n\n(e = st_intersection(st_point(c(0,0)), st_point(c(1,1))))\nGEOMETRYCOLLECTION EMPTY\n\n\nIt is not entirely clear what the benefit is of having typed empty geometries, but according to the simple feature standard they are type so the sf package abides by that.\nEmpty geometries can be detected by:\n\n\nst_is_empty(e)\n[1] TRUE"
  },
  {
    "objectID": "slides/week-2-1.html#so",
    "href": "slides/week-2-1.html#so",
    "title": "Week 2",
    "section": "So:",
    "text": "So:\n\nThere are 17 typed geometries supported by the simple feature standard\nAll geometries are made up of points\npoints can exist in 2,3,4 Dinimsonal space\nLINESTRING and POLYGON geometries have rules that define validity\nGeometries can be empty (but are still typed)"
  },
  {
    "objectID": "slides/week-2-1.html#wkt-and-wkb",
    "href": "slides/week-2-1.html#wkt-and-wkb",
    "title": "Week 2",
    "section": "WKT and WKB",
    "text": "WKT and WKB\nThe simple feature standard includes two encodings:\nWell-known text (WKT) & well-known binary (WKB)\nWell Known Text is human-readable:\n\nx &lt;- st_linestring(matrix(10:1,5))\nst_as_text(x)\n[1] \"LINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\"\n\nIn this example,\nThe word LINESTRING provides the geometry type which is followed by a parentheses, inside the parentheses are the points that make up the geometry.\nSeparate points are separated by a ‚Äúcomma‚Äù, while the point coordinates are separated by a ‚Äúspace.‚Äù\nCoordinates are usually floating point numbers, and moving large amounts of information as text is slow and imprecise.\nFor that reason, we use well-known binary (WKB) encoding\n\nx\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\nst_as_binary(x)\n [1] 01 02 00 00 00 05 00 00 00 00 00 00 00 00 00 24 40 00 00 00 00 00 00 14 40\n[26] 00 00 00 00 00 00 22 40 00 00 00 00 00 00 10 40 00 00 00 00 00 00 20 40 00\n[51] 00 00 00 00 00 08 40 00 00 00 00 00 00 1c 40 00 00 00 00 00 00 00 40 00 00\n[76] 00 00 00 00 18 40 00 00 00 00 00 00 f0 3f\n\n\nBinary conversion is used to communicate geometries to external libraries (GDAL, GEOS, liblwgeom) and spatial databases because it is fast and lossless.\nWKT and WKB can both be transformed back into R native objects by\n\n\nst_as_sfc(\"LINESTRING(10 5, 9 4, 8 3, 7 2, 6 1)\")[[1]]\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\nst_as_sfc(structure(list(st_as_binary(x)), class = \"WKB\"))[[1]]\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\n\nConversion between R native objects and WKB is done by package sf in compiled (C++/Rcpp) code, making this a reusable and fast route for I/O of simple feature geometries in R."
  },
  {
    "objectID": "slides/week-2-1.html#how-simple-features-are-organized-in-r",
    "href": "slides/week-2-1.html#how-simple-features-are-organized-in-r",
    "title": "Week 2",
    "section": "How simple features are organized in R?",
    "text": "How simple features are organized in R?\n\nSimple Features is a standard that is implemented in R (not limited to R)\nSo far we have discusses simple features the standard, rather then simple features the implementation\nIn R, simple features are implemented using standard data structures (S3 classes, lists, matrix, vector).\nAttributes are stored in data.frames (or tbl_df)\nFeature geometries are stored in a data.frame column.\nSince geometries are not single-valued, they are put in a list-column\nThis means each observation (element) is a list itself!\n\nRemember our nested lists?\n\nlist(list(c(1:5)))\n[[1]]\n[[1]][[1]]\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "slides/week-2-1.html#sf-sfc-sfg",
    "href": "slides/week-2-1.html#sf-sfc-sfg",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\nThe three classes are used to represent simple feature obejcts are:\n\nsf: data.frame with feature attributes and geometries\n\nwhich is composed of\n\nsfc: the list-column with the geometries for each feature\n\nwhich is composed of\n\nsfg, individual simple feature geometries"
  },
  {
    "objectID": "slides/week-2-1.html#sf-sfc-sfg-1",
    "href": "slides/week-2-1.html#sf-sfc-sfg-1",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\n\nIn the output we see:\n\nin green a simple feature: a single record (row, consisting of attributes and geometry\nin blue a single simple feature geometry (an object of class sfg)\nin red a simple feature list-column (an object of class sfc, which is a column in the data.frame)\n\nEven though geometries are native R objects, they are printed as well-known text"
  },
  {
    "objectID": "slides/week-2-1.html#sfg-simple-feature-geometry-blue",
    "href": "slides/week-2-1.html#sfg-simple-feature-geometry-blue",
    "title": "Week 2",
    "section": "sfg: simple feature geometry (blue)",
    "text": "sfg: simple feature geometry (blue)\n\n\nSimple feature geometry (sfg) objects carry the geometry for a single feature\nSimple feature geometries are implemented as R native data, using the following rules\n\na single POINT is a numeric vector\na set of points (e.g.¬†in a LINESTRING or ring of a POLYGON) is a matrix, each row containing a point\nany other set is a list\n\n\nlist of numeric matrices for MULTILINESTRING and POLYGON\nlist of lists of numeric matrices for MULTIPOLYGON\nlist of (typed) geometries for GEOMETRYCOLLECTION"
  },
  {
    "objectID": "slides/week-2-1.html#sfg-simple-feature-geometry",
    "href": "slides/week-2-1.html#sfg-simple-feature-geometry",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nCreator functions are rarely used in practice, since we typically read existing spatial data. But, they are useful for illustration:\n\n(x &lt;- st_point(c(1,2)))\nPOINT (1 2)\nstr(x)\n 'XY' num [1:2] 1 2\n(x &lt;- st_linestring(matrix(c(1,2,3,4), ncol=2)))\nLINESTRING (1 3, 2 4)\nstr(x)\n 'XY' num [1:2, 1:2] 1 2 3 4"
  },
  {
    "objectID": "slides/week-2-1.html#sfg-simple-feature-geometry-1",
    "href": "slides/week-2-1.html#sfg-simple-feature-geometry-1",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAll geometry objects have a S3 class indicating their (1) dimension, (2) type, and (3) superclass\n\n(pt = st_point(c(0,1)))\nPOINT (0 1)\nattributes(pt)\n$class\n[1] \"XY\"    \"POINT\" \"sfg\"  \n\n(pt2 = st_point(c(0,1,4)))\nPOINT Z (0 1 4)\nattributes(pt2)\n$class\n[1] \"XYZ\"   \"POINT\" \"sfg\""
  },
  {
    "objectID": "slides/week-2-1.html#sfg-simple-feature-geometry-2",
    "href": "slides/week-2-1.html#sfg-simple-feature-geometry-2",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\n\n\n\n(m1 = rbind(c(8, 1), c(2, 5), c(3, 2)))\n     [,1] [,2]\n[1,]    8    1\n[2,]    2    5\n[3,]    3    2\n\n(mp = st_multipoint(m1))\nMULTIPOINT ((8 1), (2 5), (3 2))\nattributes(mp)\n$dim\n[1] 3 2\n\n$class\n[1] \"XY\"         \"MULTIPOINT\" \"sfg\"       \n\n\n\n(ls = st_linestring(m1))\nLINESTRING (8 1, 2 5, 3 2)\nattributes(ls)\n$dim\n[1] 3 2\n\n$class\n[1] \"XY\"         \"LINESTRING\" \"sfg\""
  },
  {
    "objectID": "slides/week-2-1.html#sfg-simple-feature-geometry-3",
    "href": "slides/week-2-1.html#sfg-simple-feature-geometry-3",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAlthough these geometries contain the same points (m1), they have entirely different meaning: the point set is a zero-dimensional, the line a one-dimensional geometry:\nHere, dimensions is no the XY vs XYZ, but rather whether the geometry has length (1D) or area (2D) or greater‚Ä¶\n\nst_dimension(mp)\n[1] 0\nst_length(mp)\n[1] 0\nst_dimension(ls)\n[1] 1\nst_length(ls)\n[1] 10.37338"
  },
  {
    "objectID": "slides/week-2-1.html#geometrycollection",
    "href": "slides/week-2-1.html#geometrycollection",
    "title": "Week 2",
    "section": "GEOMETRYCOLLECTION",
    "text": "GEOMETRYCOLLECTION\n\nSingle features can have a geometry that consists of several geometries of different types.\nSuch cases arise rather naturally when looking for intersections. For instance, the intersection of two LINESTRING geometries may be the combination of a LINESTRING and a POINT.\nPutting this intersection into a single feature geometry needs a GEOMETRYCOLLECTION\n\n\npt &lt;- st_point(c(1, 0))\nls &lt;- st_linestring(matrix(c(4, 3, 0, 0), ncol = 2))\npoly1 &lt;- st_polygon(list(matrix(c(5.5, 7, 7, 6, 5.5, 0, 0, -0.5, -0.5, 0), ncol = 2)))\npoly2 &lt;- st_polygon(list(matrix(c(6.6, 8, 8, 7, 6.6, 1, 1, 1.5, 1.5, 1), ncol = 2)))\nmultipoly &lt;- st_multipolygon(list(poly1, poly2))\n\n(j &lt;- st_geometrycollection(list(pt, ls, poly1, poly2, multipoly)))\nGEOMETRYCOLLECTION (POINT (1 0), LINESTRING (4 0, 3 0), POLYGON ((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), POLYGON ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)), MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1))))\n\n\nIn case we end up with GEOMETRYCOLLECTION objects, the next question is often what to do with them. One thing we can do is extract elements from them:\n\n\nst_collection_extract(j, \"POLYGON\")\nGeometry set for 3 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 5.5 ymin: -0.5 xmax: 8 ymax: 1.5\nCRS:           NA\nMULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\nMULTIPOLYGON (((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)))\nMULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\n\nst_collection_extract(j, \"POINT\")\nPOINT (1 0)\n\nst_collection_extract(j, \"LINESTRING\")\nLINESTRING (4 0, 3 0)"
  },
  {
    "objectID": "slides/week-2-1.html#sfc-sets-of-geometries",
    "href": "slides/week-2-1.html#sfc-sets-of-geometries",
    "title": "Week 2",
    "section": "sfc: sets of geometries",
    "text": "sfc: sets of geometries\n\nsf provides a dedicated class for handeling geometry sets, called sfc (simple feature geometry list column).\nWe can create such a list column with constructor function st_sfc:\n\n\n(sfc = st_sfc(st_point(c(0,1)), st_point(c(-3,2))))\nGeometry set for 2 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -3 ymin: 1 xmax: 0 ymax: 2\nCRS:           NA\nPOINT (0 1)\nPOINT (-3 2)\n\nThe default report from the print method for sfc gives\n\nthe number of features geometries\nthe feature geometry type (here: POINT)\nthe feature geometry dimension (here: XY)\nthe bounding box for the set\nthe coordinate reference system for the set (epsg and proj4string)\nthe first few geometries, as (abbreviated) WKT\n\nThe class of the geometry list-column is a combination of a specific class, and a superclass.\n\nclass(sfc)\n[1] \"sfc_POINT\" \"sfc\"      \n\nIn addition to a class, the sfc object has further attributes (remember S3 class!)\n\nattributes(sfc) |&gt; names()\n[1] \"class\"     \"precision\" \"bbox\"      \"crs\"       \"n_empty\"  \n\nwhich are used to record for the whole set:\n\na precision value\nthe bounding box enclosing all geometries (for x and y)\na coordinate reference system\nthe number of empty geometries contained in the set\n\nThis means that all these properties are defined for the set (sfc), and not for geometries (sfg) individually.\nsfc objects are lists with each entry being an sfg object:\n\np[[2]]\nPOINT (1 1)\n\nand we will use these lists as list columns in data.frame or tibble objects to represent simple features with geometries in a list column."
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    1    1\n[3,]    1    0\n[4,]    0    1"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc()\n\n\n\nGeometry set for 1 feature \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\")\n\n\n\nGeometry set for 4 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nPOINT (1 1)\nPOINT (1 0)\nPOINT (0 1)"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    1    1\n[3,]    1    0\n[4,]    0    1"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "href": "slides/week-2-1.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_cast(\"POINT\")\n\n\n\nPOINT (0 0)\n\n\n\nOn the last slide, st_sfc creates a set of one LINESTRING (p), with a size of 4.\nGoing the other way around (from set to feature), we need to combine geometries:\n\n\n\n\np\nGeometry set for 4 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nPOINT (1 1)\nPOINT (1 0)\nPOINT (0 1)\n\n\n\nst_combine(p)\nGeometry set for 1 feature \nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nMULTIPOINT ((0 0), (1 1), (1 0), (0 1))"
  },
  {
    "objectID": "slides/week-2-1.html#casting-must-be-done-the-level-of-the-feature",
    "href": "slides/week-2-1.html#casting-must-be-done-the-level-of-the-feature",
    "title": "Week 2",
    "section": "Casting must be done the level of the feature",
    "text": "Casting must be done the level of the feature\nIf we want to go from the 4 feature (p) object to a 1 feature LINESTRING, we must combine before casting ‚Ä¶\n\nst_combine(p) |&gt; \n  st_cast(\"LINESTRING\")\nGeometry set for 1 feature \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2-1.html#mixed-geometries",
    "href": "slides/week-2-1.html#mixed-geometries",
    "title": "Week 2",
    "section": "Mixed geometries",
    "text": "Mixed geometries\nSets of simple features also consist of features with heterogeneous geometries. In this case, the geometry type of the set is GEOMETRY:\n\n\n\n(g = st_sfc(st_point(c(0,0)), \n            st_linestring(rbind(c(0,0), c(1,1)))))\nGeometry set for 2 features \nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nLINESTRING (0 0, 1 1)\n\n\nThese set can be filtered by using st_is\n\ng |&gt; st_is(\"LINESTRING\")\n[1] FALSE  TRUE\n\nor, when working with sf objects,\n\n# Note need of %&gt;%\nst_sf(g) %&gt;%\n  filter(st_is(., \"LINESTRING\"))\nSimple feature collection with 1 feature and 0 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\n                      g\n1 LINESTRING (0 0, 1 1)"
  },
  {
    "objectID": "slides/week-2-1.html#sf-objects-with-simple-features",
    "href": "slides/week-2-1.html#sf-objects-with-simple-features",
    "title": "Week 2",
    "section": "sf: objects with simple features",
    "text": "sf: objects with simple features\nSimple features geometries and feature attributes are put together in sf (simple feature) objects.\n\nco\nSimple feature collection with 64 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   geoid       name      aland state_nm                       geometry\n1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3...\n\nThis sf object is of class\n\nclass(co)\n[1] \"sf\"         \"data.frame\"\n\nmeaning it extends data.frame, but with a single list-column with geometries, which is held in the column named:\n\nattr(co, \"sf_column\")\n[1] \"geometry\""
  },
  {
    "objectID": "slides/week-2-1.html#sfc-simple-feature-geometry-list-column",
    "href": "slides/week-2-1.html#sfc-simple-feature-geometry-list-column",
    "title": "Week 2",
    "section": "sfc: simple feature geometry list-column",
    "text": "sfc: simple feature geometry list-column\nThe column in the sf data.frame that contains the geometries is a list, of class sfc.\nWe can retrieve the geometry list-column as we would any data.frame column (e.g.¬†ca$geometry), or more generally with st_geometry:\n\n(co_geom &lt;- st_geometry(co))\nGeometry set for 64 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\nMULTIPOLYGON (((-105.0532 39.79106, -104.976 39...\nMULTIPOLYGON (((-105.4855 37.5779, -105.4859 37...\nMULTIPOLYGON (((-103.7065 39.73989, -103.7239 3...\nMULTIPOLYGON (((-107.1287 37.42294, -107.2803 3...\nMULTIPOLYGON (((-102.0416 37.64428, -102.0558 3...\n\nGeometries are printed in abbreviated form, but we can view a complete geometry by selecting it:\n\nco_geom[[1]]\nMULTIPOLYGON (((-105.0532 39.79106, -104.976 39.79104, -104.9731 39.79242, -104.9716 39.79829, -104.9687 39.7984, -104.9689 39.79104, -104.9602 39.79102, -104.9554 39.79463, -104.9405 39.7946, -104.9405 39.791, -104.927 39.79105, -104.927 39.78378, -104.9034 39.78381, -104.9036 39.79839, -104.8845 39.79832, -104.8844 39.81282, -104.8661 39.81285, -104.866 39.79839, -104.8291 39.79806, -104.7909 39.79825, -104.7909 39.8418, -104.7623 39.84179, -104.7623 39.84539, -104.731 39.84519, -104.7304 39.89613, -104.7033 39.89595, -104.7032 39.90693, -104.6921 39.90685, -104.6921 39.91418, -104.6796 39.91402, -104.6797 39.90701, -104.6309 39.90664, -104.6309 39.89929, -104.5996 39.89904, -104.5998 39.88131, -104.6052 39.88135, -104.6053 39.87311, -104.6192 39.87322, -104.6198 39.82242, -104.6554 39.82261, -104.6554 39.813, -104.6662 39.81307, -104.6661 39.82279, -104.7625 39.82344, -104.7626 39.79843, -104.7344 39.79844, -104.7346 39.76918, -104.7646 39.76919, -104.7646 39.77157, -104.7722 39.7715, -104.7722 39.77641, -104.7816 39.77648, -104.7816 39.7728, -104.8282 39.77278, -104.8282 39.76916, -104.833 39.76918, -104.8376 39.76717, -104.8564 39.76858, -104.8563 39.75813, -104.8482 39.75642, -104.8469 39.75469, -104.8799 39.75473, -104.88 39.74744, -104.8847 39.74747, -104.8846 39.74016, -104.8217 39.74029, -104.7256 39.74027, -104.6783 39.74, -104.6603 39.74048, -104.6528 39.73978, -104.6304 39.7395, -104.6246 39.74008, -104.5589 39.73933, -104.5074 39.73825, -104.3919 39.73804, -104.3401 39.73825, -104.265 39.73888, -104.2095 39.73902, -104.1151 39.73977, -104.0407 39.73998, -103.9776 39.74027, -103.9655 39.74052, -103.9075 39.74065, -103.8661 39.74024, -103.8002 39.7402, -103.794 39.74005, -103.7239 39.73978, -103.7065 39.73989, -103.7066 39.76555, -103.7063 39.82855, -103.7063 39.889, -103.7061 39.90854, -103.7062 39.95888, -103.7057 39.98511, -103.7057 40.00137, -103.8677 40.0012, -103.9546 40.00113, -104.0371 40.00113, -104.1503 40.00086, -104.1693 40.00078, -104.2674 40.00092, -104.3015 40.00077, -104.4523 40.00062, -104.6019 40.00053, -104.6406 40.00057, -104.7885 40.00041, -104.9048 40.00032, -104.9614 40.00034, -104.9809 40.00032, -104.9877 39.98648, -104.9878 39.97575, -104.9944 39.9758, -104.9971 39.97215, -104.9881 39.97218, -104.9881 39.96847, -104.9972 39.96853, -104.9974 39.98121, -105.0158 39.98119, -105.0156 39.95519, -105.0171 39.95281, -105.0122 39.95045, -105.0063 39.95044, -105.0063 39.9468, -104.9972 39.94677, -104.9971 39.94324, -105.0157 39.94313, -105.0155 39.9214, -105.0344 39.9213, -105.0343 39.91418, -105.0529 39.91422, -105.0532 39.86362, -105.0532 39.79106)))"
  },
  {
    "objectID": "slides/week-2-1.html#reading-and-writing",
    "href": "slides/week-2-1.html#reading-and-writing",
    "title": "Week 2",
    "section": "Reading and writing",
    "text": "Reading and writing\nAs we‚Äôve seen above, reading spatial data from an external file can be done via sf - reading data requires the ‚Äúparser function‚Äù and the file path\n\nco &lt;- st_read(\"data/co.shp\")\n\nwe can suppress the output by adding argument quiet=TRUE or by using the otherwise nearly identical but more quiet\n\nca &lt;- read_sf(\"data/co.shp\")\n\nWriting takes place in the same fashion, using st_write:\n\nst_write(co, \"data/co.shp\")\n\nor its quiet alternative that silently overwrites existing files by default,\n\nwrite_sf(co, \"co.shp\") # silently overwrites"
  },
  {
    "objectID": "slides/week-2-1.html#from-tables-e.g.-csv",
    "href": "slides/week-2-1.html#from-tables-e.g.-csv",
    "title": "Week 2",
    "section": "From Tables (e.g.¬†CSV)",
    "text": "From Tables (e.g.¬†CSV)\nSpatial data can also be created from CSV and other flat files once it is in R:\n\n(cities = readr::read_csv(\"../labs/data/uscities.csv\") |&gt; \n  select(city, state_name, county_name, population, lat, lng) )\n# A tibble: 31,254 √ó 6\n   city         state_name           county_name         population   lat    lng\n   &lt;chr&gt;        &lt;chr&gt;                &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 New York     New York             Queens                18832416  40.7  -73.9\n 2 Los Angeles  California           Los Angeles           11885717  34.1 -118. \n 3 Chicago      Illinois             Cook                   8489066  41.8  -87.7\n 4 Miami        Florida              Miami-Dade             6113982  25.8  -80.2\n 5 Houston      Texas                Harris                 6046392  29.8  -95.4\n 6 Dallas       Texas                Dallas                 5843632  32.8  -96.8\n 7 Philadelphia Pennsylvania         Philadelphia           5696588  40.0  -75.1\n 8 Atlanta      Georgia              Fulton                 5211164  33.8  -84.4\n 9 Washington   District of Columbia District of Columb‚Ä¶    5146120  38.9  -77.0\n10 Boston       Massachusetts        Suffolk                4355184  42.3  -71.1\n# ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2-1.html#data-manipulation",
    "href": "slides/week-2-1.html#data-manipulation",
    "title": "Week 2",
    "section": "Data Manipulation",
    "text": "Data Manipulation\nSince sf objects are data.frames, our dplyr verbs work!\nLets find the most populous city in each California county‚Ä¶"
  },
  {
    "objectID": "slides/week-2-1.html#sf-and-dplyr",
    "href": "slides/week-2-1.html#sf-and-dplyr",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf\n\n\n\nSimple feature collection with 31254 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -176.6295 ymin: 17.9559 xmax: 174.111 ymax: 71.2727\nGeodetic CRS:  WGS 84\n# A tibble: 31,254 √ó 5\n   city         state_name      county_name population            geometry\n * &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 New York     New York        Queens        18832416  (-73.9249 40.6943)\n 2 Los Angeles  California      Los Angeles   11885717 (-118.4068 34.1141)\n 3 Chicago      Illinois        Cook           8489066  (-87.6866 41.8375)\n 4 Miami        Florida         Miami-Dade     6113982   (-80.2101 25.784)\n 5 Houston      Texas           Harris         6046392   (-95.3885 29.786)\n 6 Dallas       Texas           Dallas         5843632  (-96.7667 32.7935)\n 7 Philadelphia Pennsylvania    Philadelph‚Ä¶    5696588  (-75.1339 40.0077)\n 8 Atlanta      Georgia         Fulton         5211164   (-84.422 33.7628)\n 9 Washington   District of Co‚Ä¶ District o‚Ä¶    5146120  (-77.0163 38.9047)\n10 Boston       Massachusetts   Suffolk        4355184  (-71.0852 42.3188)\n# ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2-1.html#sf-and-dplyr-1",
    "href": "slides/week-2-1.html#sf-and-dplyr-1",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\")\n\n\n\nSimple feature collection with 477 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 477 √ó 5\n   city             state_name county_name population            geometry\n * &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n 2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n 3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n 5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n 6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n 7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n 8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n 9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n# ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2-1.html#sf-and-dplyr-2",
    "href": "slides/week-2-1.html#sf-and-dplyr-2",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name)\n\n\n\nSimple feature collection with 477 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 477 √ó 5\n# Groups:   county_name [64]\n   city             state_name county_name population            geometry\n   &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n 2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n 3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n 5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n 6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n 7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n 8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n 9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n# ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2-1.html#sf-and-dplyr-3",
    "href": "slides/week-2-1.html#sf-and-dplyr-3",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1)\n\n\n\nSimple feature collection with 64 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -108.9071 ymin: 37.1751 xmax: -102.2627 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 64 √ó 5\n# Groups:   county_name [64]\n   city           state_name county_name population            geometry\n   &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Thornton       Colorado   Adams           142878 (-104.9438 39.9197)\n 2 Alamosa        Colorado   Alamosa           9847  (-105.877 37.4752)\n 3 Aurora         Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Pagosa Springs Colorado   Archuleta         1718 (-107.0307 37.2675)\n 5 Springfield    Colorado   Baca              1482  (-102.6189 37.405)\n 6 Las Animas     Colorado   Bent              2480 (-103.2236 38.0695)\n 7 Boulder        Colorado   Boulder         120121 (-105.2524 40.0248)\n 8 Broomfield     Colorado   Broomfield       75110 (-105.0526 39.9542)\n 9 Salida         Colorado   Chaffee           5786 (-105.9979 38.5298)\n10 Cheyenne Wells Colorado   Cheyenne           949 (-102.3521 38.8192)\n# ‚Ñπ 54 more rows"
  },
  {
    "objectID": "slides/week-2-1.html#sf-and-dplyr-4",
    "href": "slides/week-2-1.html#sf-and-dplyr-4",
    "title": "Week 2",
    "section": "sf and dplyr",
    "text": "sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1) -&gt;\n  co_cities"
  },
  {
    "objectID": "slides/week-2-1.html#plotting",
    "href": "slides/week-2-1.html#plotting",
    "title": "Week 2",
    "section": "Plotting",
    "text": "Plotting\nWe‚Äôve already seen that ggplot() is a powerful visualization tool:\n‚Äì\nThe 5 steps we described for building a ggplot are: 1. canvas 2. layers (geoms) 3. labels 4. facets 5. themes\n‚Äì\nspatial work in R is becoming so common that ggplot() comes with a sf geom (geom_sf)"
  },
  {
    "objectID": "slides/week-2-1.html#sf-an-ggplot",
    "href": "slides/week-2-1.html#sf-an-ggplot",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-2-1.html#sf-an-ggplot-1",
    "href": "slides/week-2-1.html#sf-an-ggplot-1",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10))"
  },
  {
    "objectID": "slides/week-2-1.html#sf-an-ggplot-2",
    "href": "slides/week-2-1.html#sf-an-ggplot-2",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\")"
  },
  {
    "objectID": "slides/week-2-1.html#sf-an-ggplot-3",
    "href": "slides/week-2-1.html#sf-an-ggplot-3",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-2-1.html#sf-an-ggplot-4",
    "href": "slides/week-2-1.html#sf-an-ggplot-4",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw() +\n  labs(title = \"California Counties: Land Area\",\n       size = \"Population \\n(100,000)\",\n       fill = \"Acres \\n(billions)\")"
  },
  {
    "objectID": "slides/week2-2.html#feature-resoloved-and-combined",
    "href": "slides/week2-2.html#feature-resoloved-and-combined",
    "title": "Week 2-2",
    "section": "1 feature: resoloved and combined:",
    "text": "1 feature: resoloved and combined:\n\n\n\nst_cast / st_union work on sfg, sfc, and sf objects:\n\n\nus_c_ml = st_combine(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")\n   \nus_u_ml = st_union(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")"
  },
  {
    "objectID": "slides/week2-2.html#determine-the-3-closest-states",
    "href": "slides/week2-2.html#determine-the-3-closest-states",
    "title": "Week 2-2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus\n\n\n\n#&gt; Simple feature collection with 49 features and 12 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    statefp  statens    affgeoid geoid stusps       name lsad        aland\n#&gt; 1       06 01779778 0400000US06    06     CA California   00 403671196038\n#&gt; 2       55 01779806 0400000US55    55     WI  Wisconsin   00 140292246684\n#&gt; 3       16 01779783 0400000US16    16     ID      Idaho   00 214049923496\n#&gt; 4       27 00662849 0400000US27    27     MN  Minnesota   00 206232157570\n#&gt; 5       19 01779785 0400000US19    19     IA       Iowa   00 144659688848\n#&gt; 6       29 01779791 0400000US29    29     MO   Missouri   00 178052563675\n#&gt; 7       24 01714934 0400000US24    24     MD   Maryland   00  25151895765\n#&gt; 8       41 01155107 0400000US41    41     OR     Oregon   00 248628426864\n#&gt; 9       26 01779789 0400000US26    26     MI   Michigan   00 146614604273\n#&gt; 10      30 00767982 0400000US30    30     MT    Montana   00 376973673895\n#&gt;          awater state_name state_abbr jurisdiction_type\n#&gt; 1   20294133830 California         CA             state\n#&gt; 2   29343721650  Wisconsin         WI             state\n#&gt; 3    2391577745      Idaho         ID             state\n#&gt; 4   18949864226  Minnesota         MN             state\n#&gt; 5    1085996889       Iowa         IA             state\n#&gt; 6    2487215790   Missouri         MO             state\n#&gt; 7    6979171386   Maryland         MD             state\n#&gt; 8    6170953359     Oregon         OR             state\n#&gt; 9  103872203398   Michigan         MI             state\n#&gt; 10   3866689601    Montana         MT             state\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-118.594 33...\n#&gt; 2  MULTIPOLYGON (((-86.93428 4...\n#&gt; 3  MULTIPOLYGON (((-117.243 44...\n#&gt; 4  MULTIPOLYGON (((-97.22904 4...\n#&gt; 5  MULTIPOLYGON (((-96.62187 4...\n#&gt; 6  MULTIPOLYGON (((-95.76564 4...\n#&gt; 7  MULTIPOLYGON (((-76.04621 3...\n#&gt; 8  MULTIPOLYGON (((-124.5524 4...\n#&gt; 9  MULTIPOLYGON (((-84.61622 4...\n#&gt; 10 MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#determine-the-3-closest-states-1",
    "href": "slides/week2-2.html#determine-the-3-closest-states-1",
    "title": "Week 2-2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry\n#&gt; 1  California MULTIPOLYGON (((-118.594 33...\n#&gt; 2   Wisconsin MULTIPOLYGON (((-86.93428 4...\n#&gt; 3       Idaho MULTIPOLYGON (((-117.243 44...\n#&gt; 4   Minnesota MULTIPOLYGON (((-97.22904 4...\n#&gt; 5        Iowa MULTIPOLYGON (((-96.62187 4...\n#&gt; 6    Missouri MULTIPOLYGON (((-95.76564 4...\n#&gt; 7    Maryland MULTIPOLYGON (((-76.04621 3...\n#&gt; 8      Oregon MULTIPOLYGON (((-124.5524 4...\n#&gt; 9    Michigan MULTIPOLYGON (((-84.61622 4...\n#&gt; 10    Montana MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#determine-the-3-closest-states-2",
    "href": "slides/week2-2.html#determine-the-3-closest-states-2",
    "title": "Week 2-2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\n#&gt; Simple feature collection with 49 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry          dist\n#&gt; 1  California MULTIPOLYGON (((-118.594 33... 1000950.5 [m]\n#&gt; 2   Wisconsin MULTIPOLYGON (((-86.93428 4... 1146522.6 [m]\n#&gt; 3       Idaho MULTIPOLYGON (((-117.243 44...  567809.5 [m]\n#&gt; 4   Minnesota MULTIPOLYGON (((-97.22904 4...  823100.9 [m]\n#&gt; 5        Iowa MULTIPOLYGON (((-96.62187 4...  773889.8 [m]\n#&gt; 6    Missouri MULTIPOLYGON (((-95.76564 4...  789142.1 [m]\n#&gt; 7    Maryland MULTIPOLYGON (((-76.04621 3... 2174383.4 [m]\n#&gt; 8      Oregon MULTIPOLYGON (((-124.5524 4... 1041819.1 [m]\n#&gt; 9    Michigan MULTIPOLYGON (((-84.61622 4... 1401455.7 [m]\n#&gt; 10    Montana MULTIPOLYGON (((-116.0492 4...  585011.2 [m]"
  },
  {
    "objectID": "slides/week2-2.html#determine-the-3-closest-states-3",
    "href": "slides/week2-2.html#determine-the-3-closest-states-3",
    "title": "Week 2-2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado      0.0 [m] MULTIPOLYGON (((-109.06 38....\n#&gt; 2    Wyoming 139988.4 [m] MULTIPOLYGON (((-111.0569 4...\n#&gt; 3   Nebraska 161243.2 [m] MULTIPOLYGON (((-104.0531 4..."
  },
  {
    "objectID": "slides/week2-2.html#determine-the-3-closest-states-4",
    "href": "slides/week2-2.html#determine-the-3-closest-states-4",
    "title": "Week 2-2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3) -&gt;\n  near3\n\n\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado      0.0 [m] MULTIPOLYGON (((-109.06 38....\n#&gt; 2    Wyoming 139988.4 [m] MULTIPOLYGON (((-111.0569 4...\n#&gt; 3   Nebraska 161243.2 [m] MULTIPOLYGON (((-104.0531 4...\n\n\nThat‚Äôs close, but the distance to Colorado is 0, that‚Äôs not a state border."
  },
  {
    "objectID": "slides/week2-2.html#geometry-selection",
    "href": "slides/week2-2.html#geometry-selection",
    "title": "Week 2-2",
    "section": "Geometry Selection",
    "text": "Geometry Selection\n\nPolygon (therefore MULTIPOLGYGONS) describe areas!\nThe distance to a point in a polygon to that polygon is 0."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus\n\n\n\n#&gt; Simple feature collection with 49 features and 12 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    statefp  statens    affgeoid geoid stusps       name lsad        aland\n#&gt; 1       06 01779778 0400000US06    06     CA California   00 403671196038\n#&gt; 2       55 01779806 0400000US55    55     WI  Wisconsin   00 140292246684\n#&gt; 3       16 01779783 0400000US16    16     ID      Idaho   00 214049923496\n#&gt; 4       27 00662849 0400000US27    27     MN  Minnesota   00 206232157570\n#&gt; 5       19 01779785 0400000US19    19     IA       Iowa   00 144659688848\n#&gt; 6       29 01779791 0400000US29    29     MO   Missouri   00 178052563675\n#&gt; 7       24 01714934 0400000US24    24     MD   Maryland   00  25151895765\n#&gt; 8       41 01155107 0400000US41    41     OR     Oregon   00 248628426864\n#&gt; 9       26 01779789 0400000US26    26     MI   Michigan   00 146614604273\n#&gt; 10      30 00767982 0400000US30    30     MT    Montana   00 376973673895\n#&gt;          awater state_name state_abbr jurisdiction_type\n#&gt; 1   20294133830 California         CA             state\n#&gt; 2   29343721650  Wisconsin         WI             state\n#&gt; 3    2391577745      Idaho         ID             state\n#&gt; 4   18949864226  Minnesota         MN             state\n#&gt; 5    1085996889       Iowa         IA             state\n#&gt; 6    2487215790   Missouri         MO             state\n#&gt; 7    6979171386   Maryland         MD             state\n#&gt; 8    6170953359     Oregon         OR             state\n#&gt; 9  103872203398   Michigan         MI             state\n#&gt; 10   3866689601    Montana         MT             state\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-118.594 33...\n#&gt; 2  MULTIPOLYGON (((-86.93428 4...\n#&gt; 3  MULTIPOLYGON (((-117.243 44...\n#&gt; 4  MULTIPOLYGON (((-97.22904 4...\n#&gt; 5  MULTIPOLYGON (((-96.62187 4...\n#&gt; 6  MULTIPOLYGON (((-95.76564 4...\n#&gt; 7  MULTIPOLYGON (((-76.04621 3...\n#&gt; 8  MULTIPOLYGON (((-124.5524 4...\n#&gt; 9  MULTIPOLYGON (((-84.61622 4...\n#&gt; 10 MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-1",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-1",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry\n#&gt; 1  California MULTIPOLYGON (((-118.594 33...\n#&gt; 2   Wisconsin MULTIPOLYGON (((-86.93428 4...\n#&gt; 3       Idaho MULTIPOLYGON (((-117.243 44...\n#&gt; 4   Minnesota MULTIPOLYGON (((-97.22904 4...\n#&gt; 5        Iowa MULTIPOLYGON (((-96.62187 4...\n#&gt; 6    Missouri MULTIPOLYGON (((-95.76564 4...\n#&gt; 7    Maryland MULTIPOLYGON (((-76.04621 3...\n#&gt; 8      Oregon MULTIPOLYGON (((-124.5524 4...\n#&gt; 9    Michigan MULTIPOLYGON (((-84.61622 4...\n#&gt; 10    Montana MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-2",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-2",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\")\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry\n#&gt; 1  California MULTILINESTRING ((-118.594 ...\n#&gt; 2   Wisconsin MULTILINESTRING ((-86.93428...\n#&gt; 3       Idaho MULTILINESTRING ((-117.243 ...\n#&gt; 4   Minnesota MULTILINESTRING ((-97.22904...\n#&gt; 5        Iowa MULTILINESTRING ((-96.62187...\n#&gt; 6    Missouri MULTILINESTRING ((-95.76564...\n#&gt; 7    Maryland MULTILINESTRING ((-76.04621...\n#&gt; 8      Oregon MULTILINESTRING ((-124.5524...\n#&gt; 9    Michigan MULTILINESTRING ((-84.61622...\n#&gt; 10    Montana MULTILINESTRING ((-116.0492..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-3",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-3",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\n#&gt; Simple feature collection with 49 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry          dist\n#&gt; 1  California MULTILINESTRING ((-118.594 ... 1000950.5 [m]\n#&gt; 2   Wisconsin MULTILINESTRING ((-86.93428... 1146522.6 [m]\n#&gt; 3       Idaho MULTILINESTRING ((-117.243 ...  567809.5 [m]\n#&gt; 4   Minnesota MULTILINESTRING ((-97.22904...  823100.9 [m]\n#&gt; 5        Iowa MULTILINESTRING ((-96.62187...  773889.8 [m]\n#&gt; 6    Missouri MULTILINESTRING ((-95.76564...  789142.1 [m]\n#&gt; 7    Maryland MULTILINESTRING ((-76.04621... 2174383.4 [m]\n#&gt; 8      Oregon MULTILINESTRING ((-124.5524... 1041819.1 [m]\n#&gt; 9    Michigan MULTILINESTRING ((-84.61622... 1401455.7 [m]\n#&gt; 10    Montana MULTILINESTRING ((-116.0492...  585011.2 [m]"
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-4",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-4",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n#&gt; 2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-5",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-represnetation-5",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear represnetation:",
    "text": "To determine distance to border we need a linear represnetation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3) -&gt;\n  near3\n\n\n\n\n\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n#&gt; 2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531...\n\n\nGood. However, we were only interested in the distance to the closest border not to ALL boarders. Therefore we calculated 48 (49 - 1) more distances then needed!\nWhile this is not to complex for 1 &lt;-&gt; 49 features imagine we had 28,000+ (like) your lab!\nThat would result in 1,344,000 more calculations then needed ‚Ä¶"
  },
  {
    "objectID": "slides/week2-2.html#coordinate-systems-1",
    "href": "slides/week2-2.html#coordinate-systems-1",
    "title": "Week 2-2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nCoordinate Reference Systems (CRS) defines how spatial features relate to the surface of the Earth.\nCRSs are either geographic or projected‚Ä¶\nCRSs are measurement units for coordinates:"
  },
  {
    "objectID": "slides/week2-2.html#geographic-coordinate-systms-gcs",
    "href": "slides/week2-2.html#geographic-coordinate-systms-gcs",
    "title": "Week 2-2",
    "section": "Geographic Coordinate Systms (GCS)",
    "text": "Geographic Coordinate Systms (GCS)\nA GCS identifies locations on the curved surface of the earth.\nLocations are measured in angular units from the center of the earth relative to the plane defined by the equator and the plane defined by the prime meridian.\nThe vertical angle describes the latitude and the horizontal angle the longitude\nIn most coordinate systems, the North-South and East-West directions are encoded as +/-.\nNorth and East are positive (+) and South and West are negative (-) sign.\nA GCS is defined by 3 components:\n\nan ellipsoid\na geoid\na datum"
  },
  {
    "objectID": "slides/week2-2.html#sphere-and-ellipsoid",
    "href": "slides/week2-2.html#sphere-and-ellipsoid",
    "title": "Week 2-2",
    "section": "Sphere and Ellipsoid",
    "text": "Sphere and Ellipsoid\n\nAssuming that the earth is a perfect sphere simplifies calculations and works for small-scale maps (maps that show a large area of the earth).\nBut ‚Ä¶ the earth is not a sphere do to its rotation inducing a centripetal force along the equator.\nThis results in an equatorial axis that is roughly 21 km longer than the polar axis.\nTo account for this, the earth is modeled as an ellipsoid (slighty squished sphere) defined by two radii:\n\nthe semi-major axis (along the equatorial radius)\nthe semi-minor axis (along the polar radius)"
  },
  {
    "objectID": "slides/week2-2.html#datum",
    "href": "slides/week2-2.html#datum",
    "title": "Week 2-2",
    "section": "Datum",
    "text": "Datum\n\nSo how are we to reconcile our need to work with a (simple) mathematical model of the earth‚Äôs shape with the undulating nature of the geoid?\nWe align the geoid with the ellipsoid to map the the earths departures from the smooth assumption\nThe alignment can be local where the ellipsoid surface is closely fit to the geoid at a particular location on the earth‚Äôs surface\n\nor\n\ngeocentric where the ellipsoid is aligned with the center of the earth.\nThe alignment of the smooth ellipsoid to the geoid model defines a datum."
  },
  {
    "objectID": "slides/week2-2.html#local-datums",
    "href": "slides/week2-2.html#local-datums",
    "title": "Week 2-2",
    "section": "Local Datums",
    "text": "Local Datums\n\nThere are many local datums to choose from\nThe choice of datum is largely driven by the location\nWhen working in the USA, a the North American Datum of 1927 (or NAD27 for short) is standard\n\nNAD27 is not well suited for other parts of the world.\n\n\nExamples of common local datums are shown in the following table:"
  },
  {
    "objectID": "slides/week2-2.html#projected-coordinate-systems",
    "href": "slides/week2-2.html#projected-coordinate-systems",
    "title": "Week 2-2",
    "section": "Projected Coordinate Systems",
    "text": "Projected Coordinate Systems\n\nThe surface of the earth is curved but maps (and to data GIS) is flat.\nA projected coordinate system (PCS) is a reference system for identifying locations and measuring features on a flat (2D) surfaces. I\nProjected coordinate systems have an origin, an x axis, a y axis, and a linear unit of measure.\nGoing from a GCS to a PCS requires mathematical transformations.\nThere are three main groups of projection types:\n\nconic\ncylindrical\nplanar"
  },
  {
    "objectID": "slides/week2-2.html#projection-types",
    "href": "slides/week2-2.html#projection-types",
    "title": "Week 2-2",
    "section": "Projection Types:",
    "text": "Projection Types:\n\n\nIn all cases, distortion is minimized at the line/point of tangency (denoted by black line/point)\nDistortions are minimized along the tangency lines and increase with the distance from those lines."
  },
  {
    "objectID": "slides/week2-2.html#plannar",
    "href": "slides/week2-2.html#plannar",
    "title": "Week 2-2",
    "section": "Plannar",
    "text": "Plannar\n\nA planar projection projects data onto a flat surface touching the globe at a point or along 1 line of tangency.\nTypically used to map polar regions."
  },
  {
    "objectID": "slides/week2-2.html#cylindrical",
    "href": "slides/week2-2.html#cylindrical",
    "title": "Week 2-2",
    "section": "Cylindrical",
    "text": "Cylindrical\n\nA cylindrical projection maps the surface onto a cylinder.\nThis projection could also be created by touching the Earth‚Äôs surface along 1 or 2 lines of tangency\nMost often when mapping the entire world."
  },
  {
    "objectID": "slides/week2-2.html#conic",
    "href": "slides/week2-2.html#conic",
    "title": "Week 2-2",
    "section": "Conic",
    "text": "Conic\nIn a conic projection, the Earth‚Äôs surface is projected onto a cone along 1 or 2 lines of tangency\nTherefore, it is the best suited for maps of mid-latitude areas."
  },
  {
    "objectID": "slides/week2-2.html#spatial-properties",
    "href": "slides/week2-2.html#spatial-properties",
    "title": "Week 2-2",
    "section": "Spatial Properties",
    "text": "Spatial Properties\n\nAll projections distort real-world geographic features.\nThink about trying to unpeel an orange while preserving the skin\n\nThe four spatial properties that are subject to distortion are: shape, area, distance and direction\n\nA map that preserves shape is called conformal;\none that preserves area is called equal-area;\none that preserves distance is called equidistant\none that preserves direction is called azimuthal\nEach map projection can preserve only one or two of the four spatial properties.\nOften, projections are named after the spatial properties they preserve.\nWhen working with small-scale (large area) maps and when multiple spatial properties are needed, it is best to break the analyses across projections to minimize errors associated with spatial distortion."
  },
  {
    "objectID": "slides/week2-2.html#setting-crsspcss",
    "href": "slides/week2-2.html#setting-crsspcss",
    "title": "Week 2-2",
    "section": "Setting CRSs/PCSs",
    "text": "Setting CRSs/PCSs\n\nWe saw that sfc objects have two attributes to store a CRS: epsg and proj4string\n\n\nst_geometry(conus)\n#&gt; Geometry set for 49 features \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 5 geometries:\n\n\nThis implies that all geometries in a geometry list-column (sfc) must have the same CRS.\nproj4string is a generic, string-based description of a CRS, understood by PROJ\nIt defines projection types and parameter values for particular projections,\nAs a result it can cover an infinite amount of different projections.\nepsg is the integer ID for a known CRS that can be resolved into a proj4string.\n\nThis is somewhat equivalent to the idea that a 6-digit FIP code can be resolved to a state/county pair\n\nSome proj4string values can resolved back into their corresponding epsg ID, but this does not always work.\nThe importance of having epsg values stored with data besides proj4string values is that the epsg refers to particular, well-known CRS, whose parameters may change (improve) over time\nfixing only the proj4string may remove the possibility to benefit from such improvements, and limit some of the provenance of datasets (but may help reproducibility)"
  },
  {
    "objectID": "slides/week2-2.html#proj4-coordinate-syntax",
    "href": "slides/week2-2.html#proj4-coordinate-syntax",
    "title": "Week 2-2",
    "section": "PROJ4 coordinate syntax",
    "text": "PROJ4 coordinate syntax\nThe PROJ4 syntax contains a list of parameters, each prefixed with the + character.\nA list of some PROJ4 parameters follows and the full list can be found here:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\n+a\nSemi-major radius of the ellipsoid axis\n\n\n+b\nSemi-minor radius of the ellipsoid axis\n\n\n+datum\nDatum name\n\n\n+ellps\nEllipsoid name\n\n\n+lat_0\nLatitude of origin\n\n\n+lat_1\nLatitude of first standard parallel\n\n\n+lat_2\nLatitude of second standard parallel\n\n\n+lat_ts\nLatitude of true scale\n\n\n+lon_0\nCentral meridian\n\n\n+over\nAllow longitude output outside -180 to 180 range, disables wrapping\n\n\n+proj\nProjection name\n\n\n+south\nDenotes southern hemisphere UTM zone\n\n\n+units\nmeters, US survey feet, etc.\n\n\n+x_0\nFalse easting\n\n\n+y_0\nFalse northing\n\n\n+zone\nUTM zone"
  },
  {
    "objectID": "slides/week2-2.html#transform-and-retrive",
    "href": "slides/week2-2.html#transform-and-retrive",
    "title": "Week 2-2",
    "section": "Transform and retrive",
    "text": "Transform and retrive\n\n\n\nst_crs(conus)$epsg\n#&gt; [1] 4326\nst_crs(conus)$proj4string\n#&gt; [1] \"+proj=longlat +datum=WGS84 +no_defs\"\nst_crs(conus)$datum\n#&gt; [1] \"WGS84\"\n\n\n\nconus5070 &lt;- st_transform(conus, 5070)\n\nst_crs(conus5070)$epsg\n#&gt; [1] 5070\nst_crs(conus5070)$proj4string\n#&gt; [1] \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\"\nst_crs(conus5070)$datum\n#&gt; [1] \"NAD83\""
  },
  {
    "objectID": "slides/week2-2.html#revisit-denver",
    "href": "slides/week2-2.html#revisit-denver",
    "title": "Week 2-2",
    "section": "Revisit Denver",
    "text": "Revisit Denver\n\necho -104.9903 39.7392 | proj +proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\n#&gt; -723281.88   6827.29\n\n\nred = false origin : blue = Denver"
  },
  {
    "objectID": "slides/week2-2.html#geodesic-geometries",
    "href": "slides/week2-2.html#geodesic-geometries",
    "title": "Week 2-2",
    "section": "Geodesic geometries",
    "text": "Geodesic geometries\n\nPCSs introduce errors in their geometric measurements because the distance between two points on an ellipsoid is difficult to replicate on a projected coordinate system unless these points are close to one another.\nIn most cases, such errors other sources of error in the feature representation outweigh measurement errors made in a PCS making them tolorable.\n\nHowever, if the domain of analysis is large (i.e.¬†the North American continent), then the measurement errors associated with a projected coordinate system may no longer be acceptable.\nA way to circumvent projected coordinate system limitations is to adopt a geodesic solution."
  },
  {
    "objectID": "slides/week2-2.html#geodesic-measurments",
    "href": "slides/week2-2.html#geodesic-measurments",
    "title": "Week 2-2",
    "section": "Geodesic Measurments",
    "text": "Geodesic Measurments\n\nA geodesic distance is the shortest distance between two points on an ellipsoid\nA geodesic area measurement is one that is measured on an ellipsoid.\nSuch measurements are independent of the underlying projected coordinate system.\nWhy does this matter?\nCompare the distances measured between Santa Barbara and Amsterdam. The blue line represents the shortest distance between the two points on a planar coordinate system. The red line as measured on a ellipsoid."
  },
  {
    "objectID": "slides/week2-2.html#distance-example",
    "href": "slides/week2-2.html#distance-example",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-1",
    "href": "slides/week2-2.html#distance-example-1",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-2",
    "href": "slides/week2-2.html#distance-example-2",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-3",
    "href": "slides/week2-2.html#distance-example-3",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-4",
    "href": "slides/week2-2.html#distance-example-4",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-5",
    "href": "slides/week2-2.html#distance-example-5",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-6",
    "href": "slides/week2-2.html#distance-example-6",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 3823549\n#&gt; 2 3823549       0"
  },
  {
    "objectID": "slides/week2-2.html#distance-example-7",
    "href": "slides/week2-2.html#distance-example-7",
    "title": "Week 2-2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 3823549\n#&gt; 2 3823549       0"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus",
    "href": "slides/week2-2.html#area-example-conus",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus-1",
    "href": "slides/week2-2.html#area-example-conus-1",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus-2",
    "href": "slides/week2-2.html#area-example-conus-2",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df)"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus-3",
    "href": "slides/week2-2.html#area-example-conus-3",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) ))"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus-4",
    "href": "slides/week2-2.html#area-example-conus-4",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week2-2.html#area-example-conus-5",
    "href": "slides/week2-2.html#area-example-conus-5",
    "title": "Week 2-2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw() +\n  labs(x = \"SRS\", y = \"m2\")"
  },
  {
    "objectID": "slides/week2-2.html#units-in-sf",
    "href": "slides/week2-2.html#units-in-sf",
    "title": "Week 2-2",
    "section": "Units in sf",
    "text": "Units in sf\n\nThe CRS in sf encodes the units of measurement relating to spatial features\nWhere possible geometric operations such as st_distance(), st_length() and st_area() report results with a units attribute appropriate for the CRS:\nThis can be both handy and very confusing for those new to it. Consider the following:\n\n\n(l = sum(st_length(conus)))\n#&gt; 94980149 [m]\n(a = sum(st_area(conus)))\n#&gt; 7.83761e+12 [m^2]"
  },
  {
    "objectID": "slides/week2-2.html#units-are-a-class",
    "href": "slides/week2-2.html#units-are-a-class",
    "title": "Week 2-2",
    "section": "Units are a class",
    "text": "Units are a class\n\nunits are an S3 data object with attribute information and ‚Äúrules of engagement‚Äù\n\n\nclass(st_length(conus)) \n#&gt; [1] \"units\"\nattributes(st_length(conus)) |&gt; unlist()\n#&gt; units.numerator           class \n#&gt;             \"m\"         \"units\"\n\nst_length(conus) + 100\n#&gt; Error in Ops.units(st_length(conus), 100): both operands of the expression should be \"units\" objects\n\nconus |&gt; \n  mutate(area = st_area(.)) |&gt; \n  ggplot(aes(x = name, y = area)) + \n  geom_col()\n#&gt; Error in `stopifnot()`:\n#&gt; ‚Ñπ In argument: `area = st_area(.)`.\n#&gt; Caused by error:\n#&gt; ! object '.' not found"
  },
  {
    "objectID": "slides/week2-2.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "href": "slides/week2-2.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "title": "Week 2-2",
    "section": "Unit values can be stripped of their attributes if need be:",
    "text": "Unit values can be stripped of their attributes if need be:\n\n# Via drop_units\n(units::drop_units(sum(st_length(conus))))\n#&gt; [1] 94980149\n\n# Via casting\n(as.numeric(sum(st_length(conus))))\n#&gt; [1] 94980149"
  },
  {
    "objectID": "slides/week2-2.html#picking-up-again",
    "href": "slides/week2-2.html#picking-up-again",
    "title": "Week 2-2",
    "section": "Picking up again ‚Ä¶",
    "text": "Picking up again ‚Ä¶\nYesterday, we discussed the simple feature standard\n\nGeometries (type, dimension, and structure)\n\n- Empty, Valid, Simple\n\nEncoding (WKT & WKB)\nA set of operations\n\nAnd the implementation of the simple features standard in R\n\nsfg: a single feature geometry\nsfc: a set of geometries (sfg) stored as a list\nsf: a sfc list joined with a data.frame (attributes)\n\nThis R implementation is ideal/special because it achieves the simple feature abstract goal of:\n\n‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes‚Ä¶‚Äù - standard.\n\nThe shapefile/GIS traditional GIS view does not do this and seperates geometry (shp), from projection (prj), from data (dbf) and relates them through an shx file"
  },
  {
    "objectID": "slides/week2-2.html#section",
    "href": "slides/week2-2.html#section",
    "title": "Week 2-2",
    "section": "",
    "text": "Thanks to satellite and computational capabilities our estimates of these radii are be quite precise\n\nThe semi-major axis is 6,378,137 m\nThe semi-minor axis is 6,356,752 m\n\nDifferences in distance along the surfaces of an ellipsoid vs.¬†a perfect sphere are small but measurable (the difference can be as high as 20 km)"
  },
  {
    "objectID": "slides/week2-2.html#integration-with-tidyverse",
    "href": "slides/week2-2.html#integration-with-tidyverse",
    "title": "Week 2-2",
    "section": "Integration with tidyverse",
    "text": "Integration with tidyverse\n\nWe saw how the dplyr verbs still work on an sf object since sf extends the data.frame class\nHow geom_sf support mapping (‚Äúspatial plotting‚Äù) in ggplot\nHow to read spatial data into R via GDAL drivers:\n\nspatial files (read_sf)\nflat files via st_as_sf\n\nIntegration with a few GEOS geometry operations like:\n\nst_combine()\nst_union()"
  },
  {
    "objectID": "slides/week2-2.html#yesterday",
    "href": "slides/week2-2.html#yesterday",
    "title": "Week 2-2",
    "section": "Yesterday ‚Ä¶",
    "text": "Yesterday ‚Ä¶\n\n\n\nconus &lt;-  USAboundaries::us_states() |&gt;\n  filter(!state_name %in% c(\"Puerto Rico\", \n                            \"Alaska\", \n                            \"Hawaii\"))\n\nlength(st_geometry(conus))\n#&gt; [1] 49"
  },
  {
    "objectID": "slides/week2-2.html#so-what",
    "href": "slides/week2-2.html#so-what",
    "title": "Week 2-2",
    "section": "So what?",
    "text": "So what?\nLets imagine we want to know the distance from Denver to the nearest state border:\nTo do this, we need to:\n\n1: define Denver as a geometry in a CRS\n2: determine the correct geometry types / representation\n3: calculate the distance between (1) and (2)"
  },
  {
    "objectID": "slides/week2-2.html#make-denver-in-the-crs-of-our-states",
    "href": "slides/week2-2.html#make-denver-in-the-crs-of-our-states",
    "title": "Week 2-2",
    "section": "1. Make ‚ÄúDenver‚Äù in the CRS of our states",
    "text": "1. Make ‚ÄúDenver‚Äù in the CRS of our states\n\ndenver = data.frame(y = 39.7392, x = -104.9903, name = \"Denver\")\n(denver_sf = st_as_sf(denver, coords = c(\"x\", \"y\"), crs = 4326))\n#&gt; Simple feature collection with 1 feature and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -104.9903 ymin: 39.7392 xmax: -104.9903 ymax: 39.7392\n#&gt; Geodetic CRS:  WGS 84\n#&gt;     name                  geometry\n#&gt; 1 Denver POINT (-104.9903 39.7392)"
  },
  {
    "objectID": "slides/week2-2.html#revisting-the-idea-of-the-feature-level",
    "href": "slides/week2-2.html#revisting-the-idea-of-the-feature-level",
    "title": "Week 2-2",
    "section": "Revisting the idea of the feature level:",
    "text": "Revisting the idea of the feature level:\nA ‚Äúfeature‚Äù can ‚Äúbe part of the whole‚Äù or the whole\n\nA island (POLYGON), or a set of islands acting as 1 unit (MULTIPOLYGON)\nA city (POINT), or a set of cities meeting a condition (MULTIPOINT)\nA road (LINESTRING), or a route (MULTILINESTRING)\nSince we want the distance to the nearest border, regardless of the state. Our feature is the set of borders with preserved boundaries.\nIn other words, a 1 feature MULTILINESTRING\n\n\nst_distance(denver_sf, st_cast(st_combine(conus), \"MULTILINESTRING\"))\n#&gt; Units: [m]\n#&gt;          [,1]\n#&gt; [1,] 139988.4\n\nThe same principle would apply if the question was ‚Äúdistance to national border‚Äù"
  },
  {
    "objectID": "slides/week2-2.html#the-stickness-of-sfc-column",
    "href": "slides/week2-2.html#the-stickness-of-sfc-column",
    "title": "Week 2-2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nA simple features object (sf) is the connection of a sfc list-column and data.frame of attributes\n\n\n\nThis binding is unique compared to other column bindings built with things like\n\ndplyr::bind_cols()\ncbind()\ndo.call(cbind, list())"
  },
  {
    "objectID": "slides/week2-2.html#the-stickness-of-sfc-column-1",
    "href": "slides/week2-2.html#the-stickness-of-sfc-column-1",
    "title": "Week 2-2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nGeometry columns are ‚Äústicky‚Äù meaning they persist through data manipulation:\n\n\nUSAboundaries::us_states() |&gt; \n  select(name) |&gt; \n  slice(1:2)\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.4096 ymin: 32.53416 xmax: -86.80587 ymax: 47.05468\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry\n#&gt; 1 California MULTIPOLYGON (((-118.594 33...\n#&gt; 2  Wisconsin MULTIPOLYGON (((-86.93428 4...\n\nDropping the geometry column requires dropping the geometry via sf:\n\nUSAboundaries::us_states() |&gt; \n  st_drop_geometry() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n#&gt;         name\n#&gt; 1 California\n#&gt; 2  Wisconsin\n\nOr cohersing the sf object to a data.frame:\n\nUSAboundaries::us_states() |&gt; \n  as.data.frame() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n#&gt;         name\n#&gt; 1 California\n#&gt; 2  Wisconsin"
  },
  {
    "objectID": "slides/week2-2.html#section-1",
    "href": "slides/week2-2.html#section-1",
    "title": "Week 2-2",
    "section": "",
    "text": "Local datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1927\nNAD27\nContinental US\nThis is an old datum but still prevalent\n\n\nEuropean Datum of 1950\nED50\nWestern Europe\nDeveloped after World War II and still quite popular\n\n\nWorld Geodetic System 1972\nWGS72\nGlobal\nDeveloped by the Department of Defense."
  },
  {
    "objectID": "slides/week2-2.html#coordinate-systems",
    "href": "slides/week2-2.html#coordinate-systems",
    "title": "Week 2-2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nWhat makes a feature geometry spatial is the reference system‚Ä¶"
  },
  {
    "objectID": "slides/week2-2.html#sf-tools",
    "href": "slides/week2-2.html#sf-tools",
    "title": "Week 2-2",
    "section": "sf tools",
    "text": "sf tools\nIn sf we have three tools for exploring, define, and changing CRS systems:\n\nst_crs : Retrieve coordinate reference system from sf or sfc object\nst_set_crs : Set or replace coordinate reference system from object\nst_transform : Transform or convert coordinates of simple feature\nAgain, ‚Äúst‚Äù (like PostGIS) denotes it is an operation that can work on a ‚Äù s patial t ype ‚Äù"
  },
  {
    "objectID": "slides/week2-2.html#section-2",
    "href": "slides/week2-2.html#section-2",
    "title": "Week 2-2",
    "section": "",
    "text": "Geocentric datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1983\nNAD83\nContinental US\nThis is one of the most popular modern datums for the contiguous US.\n\n\nEuropean Terrestrial Reference System 1989\nETRS89\nWestern Europe\nThis is the most popular modern datum for much of Europe.\n\n\nWorld Geodetic System 1984\nWGS84\nGlobal\nDeveloped by the Department of Defense.\n\n\n\n\n\n\n\n\n\nNote\n\n\nNAD 27 is based on Clarke Ellipsoid of 1866 which is calculated by manual surveying. NAD83 is based on the Geodetic Reference System (GRS) of 1980."
  },
  {
    "objectID": "slides/week2-2.html#geoid",
    "href": "slides/week2-2.html#geoid",
    "title": "Week 2-2",
    "section": "Geoid",
    "text": "Geoid\n\nThe ellipsoid gives us the earths form as a perfectly smooth object\nBut ‚Ä¶ the earth is not perfectly smooth\nDeviations from the perfect sphere are measurable and can influence measurements.\nA geoid is a mathematical model fore representing these deviations\n\nWe are not talking about mountains and ocean trenches but the earth‚Äôs gravitational potential which is tied to the flow of the earth‚Äôs hot and fluid core.\nTherefore the geoid is constantly changing, albeit a large temporal scale.\n\nThe measurement and representation of the earth‚Äôs shape is at the heart of geodesy\n\n\nNASA‚Äôs geoid models"
  },
  {
    "objectID": "slides/week2-2.html#section-3",
    "href": "slides/week2-2.html#section-3",
    "title": "Week 2-2",
    "section": "",
    "text": "WGS84\nEPSG: 4326\nPROJ4: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\n- projection name: longlat\n- Latitude of origin: WGS84\n- Longitude of origin: WGS84\n\nWGS84\nEPSG: 5070\n\"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\"\n- projection name: aea (Albers Equal Area)\n- Latitude of origin: 23\n- Longitude of origin: -96\n- Latitude of first standard parallel: 29.5\n- Latitude of second standard parallel: 45.5\n- False Easting: 0\n- False Northing: 0\n- Datum: NAD83\n- Units: m"
  },
  {
    "objectID": "slides/week2-2.html#geocentric-datum",
    "href": "slides/week2-2.html#geocentric-datum",
    "title": "Week 2-2",
    "section": "Geocentric Datum",
    "text": "Geocentric Datum\n\nMany modern datums use a geocentric alignment\n\nWorld Geodetic Survey for 1984 (WGS84)\nNorth American Datums of 1983 (NAD83)\n\nMost popular geocentric datums use the WGS84 ellipsoid or the GRS80 ellipsoid which share nearly identical semi-major and semi-minor axes"
  },
  {
    "objectID": "slides/week2-2.html#section-4",
    "href": "slides/week2-2.html#section-4",
    "title": "Week 2-2",
    "section": "",
    "text": "the geodesic distance looks weird given its curved appearance on the projected map.\nthis curvature is a byproduct of the current reference system‚Äôs increasing distance distortion as one moves towards the pole!\nWe can display the geodesic and planar distance on a 3D globe (or a projection that mimics the view of the 3D earth)."
  },
  {
    "objectID": "slides/week2-2.html#building-a-gcs",
    "href": "slides/week2-2.html#building-a-gcs",
    "title": "Week 2-2",
    "section": "Building a GCS",
    "text": "Building a GCS\n\nSo, a GCS is defined by the ellipsoid model and its alignment to the geoid defining the datum.\nSmooth Sphere - Mathmatical Geoid (in angular units)"
  },
  {
    "objectID": "slides/week2-2.html",
    "href": "slides/week2-2.html",
    "title": "Week 2-2",
    "section": "",
    "text": "Yesterday, we discussed the simple feature standard\n\nGeometries (type, dimension, and structure)\n\n- Empty, Valid, Simple\n\nEncoding (WKT & WKB)\nA set of operations\n\nAnd the implementation of the simple features standard in R\n\nsfg: a single feature geometry\nsfc: a set of geometries (sfg) stored as a list\nsf: a sfc list joined with a data.frame (attributes)\n\nThis R implementation is ideal/special because it achieves the simple feature abstract goal of:\n\n‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes‚Ä¶‚Äù - standard.\n\nThe shapefile/GIS traditional GIS view does not do this and seperates geometry (shp), from projection (prj), from data (dbf) and relates them through an shx file"
  },
  {
    "objectID": "slides/week2-2.html#distances",
    "href": "slides/week2-2.html#distances",
    "title": "Week 2-2",
    "section": "Distances",
    "text": "Distances\n?st_distance"
  },
  {
    "objectID": "slides/week2-2.html#section-6",
    "href": "slides/week2-2.html#section-6",
    "title": "Week 2-2",
    "section": "",
    "text": "We can set units if we do manipulations as well using the units package\n\nunits::set_units(l, \"km\")\n#&gt; 94980.15 [km]\nunits::set_units(l, \"mile\")\n#&gt; 59017.93 [mile]\n\nunits::set_units(a, \"ha\")\n#&gt; 783760974 [ha]\nunits::set_units(a, \"km2\")\n#&gt; 7837610 [km^2]\nunits::set_units(a, \"in2\")\n#&gt; 1.214832e+16 [in^2]"
  },
  {
    "objectID": "slides/week-2-1.html#section",
    "href": "slides/week-2-1.html#section",
    "title": "Week 2",
    "section": "",
    "text": "The remaining geometries 10 are rarer, but increasingly find implementations:\n\n\n\n\n\n\n\ntype\ndescription\n\n\n\n\nCIRCULARSTRING\nThe CIRCULARSTRING is the basic curve type, similar to a LINESTRING in the linear world. A single segment requires three points, the start and end points (first and third) and any other point on the arc. The exception to this is for a closed circle, where the start and end points are the same. In this case the second point MUST be the center of the arc, i.e., the opposite side of the circle. To chain arcs together, the last point of the previous arc becomes the first point of the next arc, just like in LINESTRING. This means that a valid circular string must have an odd number of points greater than 1.\n\n\nCOMPOUNDCURVE\nA compound curve is a single, continuous curve that has both curved (circular) segments and linear segments. That means that in addition to having well-formed components, the end point of every component (except the last) must be coincident with the start point of the following component.\n\n\nCURVEPOLYGON\nExample compound curve in a curve polygon: CURVEPOLYGON(COMPOUNDCURVE(CIRCULARSTRING(0 0,2 0, 2 1, 2 3, 4 3),(4 3, 4 5, 1 4, 0 0)), CIRCULARSTRING(1.7 1, 1.4 0.4, 1.6 0.4, 1.6 0.5, 1.7 1) )\n\n\nMULTICURVE\nA MultiCurve is a 1-dimensional GeometryCollection whose elements are Curves, it can include linear strings, circular strings or compound strings.\n\n\nMULTISURFACE\nA MultiSurface is a 2-dimensional GeometryCollection whose elements are Surfaces, all using coordinates from the same coordinate reference system.\n\n\nCURVE\nA Curve is a 1-dimensional geometric object usually stored as a sequence of Points, with the subtype of Curve specifying the form of the interpolation between Points\n\n\nSURFACE\nA Surface is a 2-dimensional geometric object\n\n\nPOLYHEDRALSURFACE\nA PolyhedralSurface is a contiguous collection of polygons, which share common boundary segments\n\n\nTIN\nA TIN (triangulated irregular network) is a PolyhedralSurface consisting only of Triangle patches.\n\n\nTRIANGLE\nA Triangle is a polygon with 3 distinct, non-collinear vertices and no interior boundary"
  },
  {
    "objectID": "slides/week2-2.html#section-5",
    "href": "slides/week2-2.html#section-5",
    "title": "Week 2-2",
    "section": "",
    "text": "So if a geodesic measurement is more precise than a planar measurement, why not perform all spatial operations using geodesic geometry?\nThe downside is in its computational requirements.\nIt‚Äôs far more efficient to compute area/distance on a plane than it is on a spheroid.\nThis is because geodesic calculations have no simple algebraic solutions and involve approximations that may require iteration! (think optimization or nonlinear solutions)\nSo this may be a computationally taxing approach if processing 1,000(s) or 1,000,000(s) of line segments."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus\n\n\n\n#&gt; Simple feature collection with 49 features and 12 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    statefp  statens    affgeoid geoid stusps       name lsad        aland\n#&gt; 1       06 01779778 0400000US06    06     CA California   00 403671196038\n#&gt; 2       55 01779806 0400000US55    55     WI  Wisconsin   00 140292246684\n#&gt; 3       16 01779783 0400000US16    16     ID      Idaho   00 214049923496\n#&gt; 4       27 00662849 0400000US27    27     MN  Minnesota   00 206232157570\n#&gt; 5       19 01779785 0400000US19    19     IA       Iowa   00 144659688848\n#&gt; 6       29 01779791 0400000US29    29     MO   Missouri   00 178052563675\n#&gt; 7       24 01714934 0400000US24    24     MD   Maryland   00  25151895765\n#&gt; 8       41 01155107 0400000US41    41     OR     Oregon   00 248628426864\n#&gt; 9       26 01779789 0400000US26    26     MI   Michigan   00 146614604273\n#&gt; 10      30 00767982 0400000US30    30     MT    Montana   00 376973673895\n#&gt;          awater state_name state_abbr jurisdiction_type\n#&gt; 1   20294133830 California         CA             state\n#&gt; 2   29343721650  Wisconsin         WI             state\n#&gt; 3    2391577745      Idaho         ID             state\n#&gt; 4   18949864226  Minnesota         MN             state\n#&gt; 5    1085996889       Iowa         IA             state\n#&gt; 6    2487215790   Missouri         MO             state\n#&gt; 7    6979171386   Maryland         MD             state\n#&gt; 8    6170953359     Oregon         OR             state\n#&gt; 9  103872203398   Michigan         MI             state\n#&gt; 10   3866689601    Montana         MT             state\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-118.594 33...\n#&gt; 2  MULTIPOLYGON (((-86.93428 4...\n#&gt; 3  MULTIPOLYGON (((-117.243 44...\n#&gt; 4  MULTIPOLYGON (((-97.22904 4...\n#&gt; 5  MULTIPOLYGON (((-96.62187 4...\n#&gt; 6  MULTIPOLYGON (((-95.76564 4...\n#&gt; 7  MULTIPOLYGON (((-76.04621 3...\n#&gt; 8  MULTIPOLYGON (((-124.5524 4...\n#&gt; 9  MULTIPOLYGON (((-84.61622 4...\n#&gt; 10 MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry\n#&gt; 1  California MULTIPOLYGON (((-118.594 33...\n#&gt; 2   Wisconsin MULTIPOLYGON (((-86.93428 4...\n#&gt; 3       Idaho MULTIPOLYGON (((-117.243 44...\n#&gt; 4   Minnesota MULTIPOLYGON (((-97.22904 4...\n#&gt; 5        Iowa MULTIPOLYGON (((-96.62187 4...\n#&gt; 6    Missouri MULTIPOLYGON (((-95.76564 4...\n#&gt; 7    Maryland MULTIPOLYGON (((-76.04621 3...\n#&gt; 8      Oregon MULTIPOLYGON (((-124.5524 4...\n#&gt; 9    Michigan MULTIPOLYGON (((-84.61622 4...\n#&gt; 10    Montana MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\")\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry\n#&gt; 1  California MULTILINESTRING ((-118.594 ...\n#&gt; 2   Wisconsin MULTILINESTRING ((-86.93428...\n#&gt; 3       Idaho MULTILINESTRING ((-117.243 ...\n#&gt; 4   Minnesota MULTILINESTRING ((-97.22904...\n#&gt; 5        Iowa MULTILINESTRING ((-96.62187...\n#&gt; 6    Missouri MULTILINESTRING ((-95.76564...\n#&gt; 7    Maryland MULTILINESTRING ((-76.04621...\n#&gt; 8      Oregon MULTILINESTRING ((-124.5524...\n#&gt; 9    Michigan MULTILINESTRING ((-84.61622...\n#&gt; 10    Montana MULTILINESTRING ((-116.0492..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\n#&gt; Simple feature collection with 49 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_name                       geometry          dist\n#&gt; 1  California MULTILINESTRING ((-118.594 ... 1000950.5 [m]\n#&gt; 2   Wisconsin MULTILINESTRING ((-86.93428... 1146522.6 [m]\n#&gt; 3       Idaho MULTILINESTRING ((-117.243 ...  567809.5 [m]\n#&gt; 4   Minnesota MULTILINESTRING ((-97.22904...  823100.9 [m]\n#&gt; 5        Iowa MULTILINESTRING ((-96.62187...  773889.8 [m]\n#&gt; 6    Missouri MULTILINESTRING ((-95.76564...  789142.1 [m]\n#&gt; 7    Maryland MULTILINESTRING ((-76.04621... 2174383.4 [m]\n#&gt; 8      Oregon MULTILINESTRING ((-124.5524... 1041819.1 [m]\n#&gt; 9    Michigan MULTILINESTRING ((-84.61622... 1401455.7 [m]\n#&gt; 10    Montana MULTILINESTRING ((-116.0492...  585011.2 [m]"
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n#&gt; 2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531..."
  },
  {
    "objectID": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "href": "slides/week2-2.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "title": "Week 2-2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3) -&gt;\n  near3\n\n\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n#&gt; 2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531...\n\n\nGood. However, we were only interested in the distance to the closest border not to ALL boarders. Therefore we calculated 48 (49 - 1) more distances then needed!\nWhile this is not to complex for 1 &lt;-&gt; 49 features imagine we had 28,000+ (like) your lab!\nThat would result in 1,344,000 more calculations then needed ‚Ä¶"
  },
  {
    "objectID": "slides/week2-2.html#gedesic-area-and-length-measurements",
    "href": "slides/week2-2.html#gedesic-area-and-length-measurements",
    "title": "Week 2-2",
    "section": "Gedesic Area and Length Measurements",
    "text": "Gedesic Area and Length Measurements\n\nNot all algorthimns are equal (in terms of speed or accuracy)\nSome more efficient algorithms that minimize computation time may reduce precision in the process.\nSome of ArcMap‚Äôs functions offer the option to compute geodesic distances and areas however ArcMap does not clearly indicate how its geodesic calculations are implemented (cite\nR is well documented, and is efficient!"
  },
  {
    "objectID": "slides/week2-2.html#native-sf-binds-to-libwgeom",
    "href": "slides/week2-2.html#native-sf-binds-to-libwgeom",
    "title": "Week 2-2",
    "section": "native sf binds to libwgeom",
    "text": "native sf binds to libwgeom"
  },
  {
    "objectID": "slides/week-2-1.html#so-far",
    "href": "slides/week-2-1.html#so-far",
    "title": "Week 2",
    "section": "So far ‚Ä¶",
    "text": "So far ‚Ä¶\nWe‚Äôve discussed the simple feature standard\n\nGeometries (type, dimension, and structure)\n\n- Empty, Valid, Simple\n\nEncoding (WKT & WKB)\nA set of operations\n\nAnd the implementation of the simple features standard in R\n\nsfg: a single feature geometry\nsfc: a set of geometries (sfg) stored as a list\nsf: a sfc list joined with a data.frame (attributes)\n\nThis R implementation is ideal/special because it achieves the simple feature abstract goal of:\n\n‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes‚Ä¶‚Äù - standard.\n\nThe shapefile/GIS traditional GIS view does not do this and seperates geometry (shp), from projection (prj), from data (dbf) and relates them through an shx file"
  },
  {
    "objectID": "slides/week-2-1.html#integration-with-tidyverse",
    "href": "slides/week-2-1.html#integration-with-tidyverse",
    "title": "Week 2",
    "section": "Integration with tidyverse",
    "text": "Integration with tidyverse\n\nWe saw how the dplyr verbs still work on an sf object since sf extends the data.frame class\nHow geom_sf support mapping (‚Äúspatial plotting‚Äù) in ggplot\nHow to read spatial data into R via GDAL drivers:\n\nspatial files (read_sf)\nflat files via st_as_sf\n\nIntegration with a few GEOS geometry operations like:\n\nst_combine()\nst_union()"
  },
  {
    "objectID": "slides/week-2-1.html#taki",
    "href": "slides/week-2-1.html#taki",
    "title": "Week 2",
    "section": "Taki ‚Ä¶",
    "text": "Taki ‚Ä¶\n\n\n\nconus &lt;-  USAboundaries::us_states() |&gt;\n  filter(!state_name %in% c(\"Puerto Rico\", \n                            \"Alaska\", \n                            \"Hawaii\"))\n\nlength(st_geometry(conus))\n[1] 49"
  },
  {
    "objectID": "slides/week-2-1.html#feature-resoloved-and-combined",
    "href": "slides/week-2-1.html#feature-resoloved-and-combined",
    "title": "Week 2",
    "section": "1 feature: resoloved and combined:",
    "text": "1 feature: resoloved and combined:\n\n\n\nst_cast / st_union work on sfg, sfc, and sf objects:\n\n\nus_c_ml = st_combine(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")\n   \nus_u_ml = st_union(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")"
  },
  {
    "objectID": "slides/week-2-1.html#so-what",
    "href": "slides/week-2-1.html#so-what",
    "title": "Week 2",
    "section": "So what?",
    "text": "So what?\nLets imagine we want to know the distance from Denver to the nearest state border:\nTo do this, we need to:\n\n1: define Denver as a geometry in a CRS\n2: determine the correct geometry types / representation\n3: calculate the distance between (1) and (2)"
  },
  {
    "objectID": "slides/week-2-1.html#make-denver-in-the-crs-of-our-states",
    "href": "slides/week-2-1.html#make-denver-in-the-crs-of-our-states",
    "title": "Week 2",
    "section": "1. Make ‚ÄúDenver‚Äù in the CRS of our states",
    "text": "1. Make ‚ÄúDenver‚Äù in the CRS of our states\n\ndenver = data.frame(y = 39.7392, x = -104.9903, name = \"Denver\")\n(denver_sf = st_as_sf(denver, coords = c(\"x\", \"y\"), crs = 4326))\nSimple feature collection with 1 feature and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -104.9903 ymin: 39.7392 xmax: -104.9903 ymax: 39.7392\nGeodetic CRS:  WGS 84\n    name                  geometry\n1 Denver POINT (-104.9903 39.7392)"
  },
  {
    "objectID": "slides/week-2-1.html#determine-the-3-closest-states",
    "href": "slides/week-2-1.html#determine-the-3-closest-states",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus\n\n\n\nSimple feature collection with 49 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   statefp  statens    affgeoid geoid stusps       name lsad        aland\n1       06 01779778 0400000US06    06     CA California   00 403671196038\n2       55 01779806 0400000US55    55     WI  Wisconsin   00 140292246684\n3       16 01779783 0400000US16    16     ID      Idaho   00 214049923496\n4       27 00662849 0400000US27    27     MN  Minnesota   00 206232157570\n5       19 01779785 0400000US19    19     IA       Iowa   00 144659688848\n6       29 01779791 0400000US29    29     MO   Missouri   00 178052563675\n7       24 01714934 0400000US24    24     MD   Maryland   00  25151895765\n8       41 01155107 0400000US41    41     OR     Oregon   00 248628426864\n9       26 01779789 0400000US26    26     MI   Michigan   00 146614604273\n10      30 00767982 0400000US30    30     MT    Montana   00 376973673895\n         awater state_name state_abbr jurisdiction_type\n1   20294133830 California         CA             state\n2   29343721650  Wisconsin         WI             state\n3    2391577745      Idaho         ID             state\n4   18949864226  Minnesota         MN             state\n5    1085996889       Iowa         IA             state\n6    2487215790   Missouri         MO             state\n7    6979171386   Maryland         MD             state\n8    6170953359     Oregon         OR             state\n9  103872203398   Michigan         MI             state\n10   3866689601    Montana         MT             state\n                         geometry\n1  MULTIPOLYGON (((-118.594 33...\n2  MULTIPOLYGON (((-86.93428 4...\n3  MULTIPOLYGON (((-117.243 44...\n4  MULTIPOLYGON (((-97.22904 4...\n5  MULTIPOLYGON (((-96.62187 4...\n6  MULTIPOLYGON (((-95.76564 4...\n7  MULTIPOLYGON (((-76.04621 3...\n8  MULTIPOLYGON (((-124.5524 4...\n9  MULTIPOLYGON (((-84.61622 4...\n10 MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week-2-1.html#determine-the-3-closest-states-1",
    "href": "slides/week-2-1.html#determine-the-3-closest-states-1",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\nSimple feature collection with 49 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   state_name                       geometry\n1  California MULTIPOLYGON (((-118.594 33...\n2   Wisconsin MULTIPOLYGON (((-86.93428 4...\n3       Idaho MULTIPOLYGON (((-117.243 44...\n4   Minnesota MULTIPOLYGON (((-97.22904 4...\n5        Iowa MULTIPOLYGON (((-96.62187 4...\n6    Missouri MULTIPOLYGON (((-95.76564 4...\n7    Maryland MULTIPOLYGON (((-76.04621 3...\n8      Oregon MULTIPOLYGON (((-124.5524 4...\n9    Michigan MULTIPOLYGON (((-84.61622 4...\n10    Montana MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week-2-1.html#determine-the-3-closest-states-2",
    "href": "slides/week-2-1.html#determine-the-3-closest-states-2",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\nSimple feature collection with 49 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   state_name                       geometry          dist\n1  California MULTIPOLYGON (((-118.594 33... 1000950.5 [m]\n2   Wisconsin MULTIPOLYGON (((-86.93428 4... 1146522.6 [m]\n3       Idaho MULTIPOLYGON (((-117.243 44...  567809.5 [m]\n4   Minnesota MULTIPOLYGON (((-97.22904 4...  823100.9 [m]\n5        Iowa MULTIPOLYGON (((-96.62187 4...  773889.8 [m]\n6    Missouri MULTIPOLYGON (((-95.76564 4...  789142.1 [m]\n7    Maryland MULTIPOLYGON (((-76.04621 3... 2174383.4 [m]\n8      Oregon MULTIPOLYGON (((-124.5524 4... 1041819.1 [m]\n9    Michigan MULTIPOLYGON (((-84.61622 4... 1401455.7 [m]\n10    Montana MULTIPOLYGON (((-116.0492 4...  585011.2 [m]"
  },
  {
    "objectID": "slides/week-2-1.html#determine-the-3-closest-states-3",
    "href": "slides/week-2-1.html#determine-the-3-closest-states-3",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\nGeodetic CRS:  WGS 84\n  state_name         dist                       geometry\n1   Colorado      0.0 [m] MULTIPOLYGON (((-109.06 38....\n2    Wyoming 139988.4 [m] MULTIPOLYGON (((-111.0569 4...\n3   Nebraska 161243.2 [m] MULTIPOLYGON (((-104.0531 4...\n\n\n\nThat‚Äôs close, but the distance to Colorado is 0, that‚Äôs not a state border."
  },
  {
    "objectID": "slides/week-2-1.html#geometry-selection",
    "href": "slides/week-2-1.html#geometry-selection",
    "title": "Week 2",
    "section": "Geometry Selection",
    "text": "Geometry Selection\n\nPolygon (therefore MULTIPOLGYGONS) describe areas!\nThe distance to a point in a polygon to that polygon is 0."
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus\n\n\n\nSimple feature collection with 49 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   statefp  statens    affgeoid geoid stusps       name lsad        aland\n1       06 01779778 0400000US06    06     CA California   00 403671196038\n2       55 01779806 0400000US55    55     WI  Wisconsin   00 140292246684\n3       16 01779783 0400000US16    16     ID      Idaho   00 214049923496\n4       27 00662849 0400000US27    27     MN  Minnesota   00 206232157570\n5       19 01779785 0400000US19    19     IA       Iowa   00 144659688848\n6       29 01779791 0400000US29    29     MO   Missouri   00 178052563675\n7       24 01714934 0400000US24    24     MD   Maryland   00  25151895765\n8       41 01155107 0400000US41    41     OR     Oregon   00 248628426864\n9       26 01779789 0400000US26    26     MI   Michigan   00 146614604273\n10      30 00767982 0400000US30    30     MT    Montana   00 376973673895\n         awater state_name state_abbr jurisdiction_type\n1   20294133830 California         CA             state\n2   29343721650  Wisconsin         WI             state\n3    2391577745      Idaho         ID             state\n4   18949864226  Minnesota         MN             state\n5    1085996889       Iowa         IA             state\n6    2487215790   Missouri         MO             state\n7    6979171386   Maryland         MD             state\n8    6170953359     Oregon         OR             state\n9  103872203398   Michigan         MI             state\n10   3866689601    Montana         MT             state\n                         geometry\n1  MULTIPOLYGON (((-118.594 33...\n2  MULTIPOLYGON (((-86.93428 4...\n3  MULTIPOLYGON (((-117.243 44...\n4  MULTIPOLYGON (((-97.22904 4...\n5  MULTIPOLYGON (((-96.62187 4...\n6  MULTIPOLYGON (((-95.76564 4...\n7  MULTIPOLYGON (((-76.04621 3...\n8  MULTIPOLYGON (((-124.5524 4...\n9  MULTIPOLYGON (((-84.61622 4...\n10 MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\nSimple feature collection with 49 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   state_name                       geometry\n1  California MULTIPOLYGON (((-118.594 33...\n2   Wisconsin MULTIPOLYGON (((-86.93428 4...\n3       Idaho MULTIPOLYGON (((-117.243 44...\n4   Minnesota MULTIPOLYGON (((-97.22904 4...\n5        Iowa MULTIPOLYGON (((-96.62187 4...\n6    Missouri MULTIPOLYGON (((-95.76564 4...\n7    Maryland MULTIPOLYGON (((-76.04621 3...\n8      Oregon MULTIPOLYGON (((-124.5524 4...\n9    Michigan MULTIPOLYGON (((-84.61622 4...\n10    Montana MULTIPOLYGON (((-116.0492 4..."
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\")\n\n\n\nSimple feature collection with 49 features and 1 field\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   state_name                       geometry\n1  California MULTILINESTRING ((-118.594 ...\n2   Wisconsin MULTILINESTRING ((-86.93428...\n3       Idaho MULTILINESTRING ((-117.243 ...\n4   Minnesota MULTILINESTRING ((-97.22904...\n5        Iowa MULTILINESTRING ((-96.62187...\n6    Missouri MULTILINESTRING ((-95.76564...\n7    Maryland MULTILINESTRING ((-76.04621...\n8      Oregon MULTILINESTRING ((-124.5524...\n9    Michigan MULTILINESTRING ((-84.61622...\n10    Montana MULTILINESTRING ((-116.0492..."
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\nSimple feature collection with 49 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   state_name                       geometry          dist\n1  California MULTILINESTRING ((-118.594 ... 1000950.5 [m]\n2   Wisconsin MULTILINESTRING ((-86.93428... 1146522.6 [m]\n3       Idaho MULTILINESTRING ((-117.243 ...  567809.5 [m]\n4   Minnesota MULTILINESTRING ((-97.22904...  823100.9 [m]\n5        Iowa MULTILINESTRING ((-96.62187...  773889.8 [m]\n6    Missouri MULTILINESTRING ((-95.76564...  789142.1 [m]\n7    Maryland MULTILINESTRING ((-76.04621... 2174383.4 [m]\n8      Oregon MULTILINESTRING ((-124.5524... 1041819.1 [m]\n9    Michigan MULTILINESTRING ((-84.61622... 1401455.7 [m]\n10    Montana MULTILINESTRING ((-116.0492...  585011.2 [m]"
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\nGeodetic CRS:  WGS 84\n  state_name         dist                       geometry\n1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531..."
  },
  {
    "objectID": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "href": "slides/week-2-1.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3) -&gt;\n  near3\n\n\n\n\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\nGeodetic CRS:  WGS 84\n  state_name         dist                       geometry\n1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531...\n\n\nGood. However, we were only interested in the distance to the closest border not to ALL boarders. Therefore we calculated 48 (49 - 1) more distances then needed!\nWhile this is not to complex for 1 &lt;-&gt; 49 features imagine we had 28,000+ (like) your lab!\nThat would result in 1,344,000 more calculations then needed ‚Ä¶"
  },
  {
    "objectID": "slides/week-2-1.html#revisting-the-idea-of-the-feature-level",
    "href": "slides/week-2-1.html#revisting-the-idea-of-the-feature-level",
    "title": "Week 2",
    "section": "Revisting the idea of the feature level:",
    "text": "Revisting the idea of the feature level:\nA ‚Äúfeature‚Äù can ‚Äúbe part of the whole‚Äù or the whole\n\nA island (POLYGON), or a set of islands acting as 1 unit (MULTIPOLYGON)\nA city (POINT), or a set of cities meeting a condition (MULTIPOINT)\nA road (LINESTRING), or a route (MULTILINESTRING)\nSince we want the distance to the nearest border, regardless of the state. Our feature is the set of borders with preserved boundaries.\nIn other words, a 1 feature MULTILINESTRING\n\n\nst_distance(denver_sf, st_cast(st_combine(conus), \"MULTILINESTRING\"))\nUnits: [m]\n         [,1]\n[1,] 139988.4\n\nThe same principle would apply if the question was ‚Äúdistance to national border‚Äù"
  },
  {
    "objectID": "slides/week-2-1.html#the-stickness-of-sfc-column",
    "href": "slides/week-2-1.html#the-stickness-of-sfc-column",
    "title": "Week 2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nA simple features object (sf) is the connection of a sfc list-column and data.frame of attributes\n\n\n\nThis binding is unique compared to other column bindings built with things like\n\ndplyr::bind_cols()\ncbind()\ndo.call(cbind, list())"
  },
  {
    "objectID": "slides/week-2-1.html#the-stickness-of-sfc-column-1",
    "href": "slides/week-2-1.html#the-stickness-of-sfc-column-1",
    "title": "Week 2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nGeometry columns are ‚Äústicky‚Äù meaning they persist through data manipulation:\n\n\nUSAboundaries::us_states() |&gt; \n  select(name) |&gt; \n  slice(1:2)\nSimple feature collection with 2 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.4096 ymin: 32.53416 xmax: -86.80587 ymax: 47.05468\nGeodetic CRS:  WGS 84\n        name                       geometry\n1 California MULTIPOLYGON (((-118.594 33...\n2  Wisconsin MULTIPOLYGON (((-86.93428 4...\n\nDropping the geometry column requires dropping the geometry via sf:\n\nUSAboundaries::us_states() |&gt; \n  st_drop_geometry() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n        name\n1 California\n2  Wisconsin\n\nOr cohersing the sf object to a data.frame:\n\nUSAboundaries::us_states() |&gt; \n  as.data.frame() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n        name\n1 California\n2  Wisconsin"
  },
  {
    "objectID": "slides/week-2-1.html#coordinate-systems",
    "href": "slides/week-2-1.html#coordinate-systems",
    "title": "Week 2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nWhat makes a feature geometry spatial is the reference system‚Ä¶"
  },
  {
    "objectID": "slides/week-2-1.html#coordinate-systems-1",
    "href": "slides/week-2-1.html#coordinate-systems-1",
    "title": "Week 2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nCoordinate Reference Systems (CRS) defines how spatial features relate to the surface of the Earth.\nCRSs are either geographic or projected‚Ä¶\nCRSs are measurement units for coordinates:"
  },
  {
    "objectID": "slides/week-2-1.html#sf-tools",
    "href": "slides/week-2-1.html#sf-tools",
    "title": "Week 2",
    "section": "sf tools",
    "text": "sf tools\nIn sf we have three tools for exploring, define, and changing CRS systems:\n\nst_crs : Retrieve coordinate reference system from sf or sfc object\nst_set_crs : Set or replace coordinate reference system from object\nst_transform : Transform or convert coordinates of simple feature\nAgain, ‚Äúst‚Äù (like PostGIS) denotes it is an operation that can work on a ‚Äù s patial t ype ‚Äù"
  },
  {
    "objectID": "slides/week-2-1.html#geographic-coordinate-systms-gcs",
    "href": "slides/week-2-1.html#geographic-coordinate-systms-gcs",
    "title": "Week 2",
    "section": "Geographic Coordinate Systms (GCS)",
    "text": "Geographic Coordinate Systms (GCS)\nA GCS identifies locations on the curved surface of the earth.\nLocations are measured in angular units from the center of the earth relative to the plane defined by the equator and the plane defined by the prime meridian.\nThe vertical angle describes the latitude and the horizontal angle the longitude\nIn most coordinate systems, the North-South and East-West directions are encoded as +/-.\nNorth and East are positive (+) and South and West are negative (-) sign.\nA GCS is defined by 3 components:\n\nan ellipsoid\na geoid\na datum"
  },
  {
    "objectID": "slides/week-2-1.html#sphere-and-ellipsoid",
    "href": "slides/week-2-1.html#sphere-and-ellipsoid",
    "title": "Week 2",
    "section": "Sphere and Ellipsoid",
    "text": "Sphere and Ellipsoid\n\nAssuming that the earth is a perfect sphere simplifies calculations and works for small-scale maps (maps that show a large area of the earth).\nBut ‚Ä¶ the earth is not a sphere do to its rotation inducing a centripetal force along the equator.\nThis results in an equatorial axis that is roughly 21 km longer than the polar axis.\nTo account for this, the earth is modeled as an ellipsoid (slighty squished sphere) defined by two radii:\n\nthe semi-major axis (along the equatorial radius)\nthe semi-minor axis (along the polar radius)"
  },
  {
    "objectID": "slides/week-2-1.html#section-1",
    "href": "slides/week-2-1.html#section-1",
    "title": "Week 2",
    "section": "",
    "text": "Thanks to satellite and computational capabilities our estimates of these radii are be quite precise\n\nThe semi-major axis is 6,378,137 m\nThe semi-minor axis is 6,356,752 m\n\nDifferences in distance along the surfaces of an ellipsoid vs.¬†a perfect sphere are small but measurable (the difference can be as high as 20 km)"
  },
  {
    "objectID": "slides/week-2-1.html#geoid",
    "href": "slides/week-2-1.html#geoid",
    "title": "Week 2",
    "section": "Geoid",
    "text": "Geoid\n\nThe ellipsoid gives us the earths form as a perfectly smooth object\nBut ‚Ä¶ the earth is not perfectly smooth\nDeviations from the perfect sphere are measurable and can influence measurements.\nA geoid is a mathematical model fore representing these deviations\n\nWe are not talking about mountains and ocean trenches but the earth‚Äôs gravitational potential which is tied to the flow of the earth‚Äôs hot and fluid core.\nTherefore the geoid is constantly changing, albeit a large temporal scale.\n\nThe measurement and representation of the earth‚Äôs shape is at the heart of geodesy\n\n\nNASA‚Äôs geoid models"
  },
  {
    "objectID": "slides/week-2-1.html#datum",
    "href": "slides/week-2-1.html#datum",
    "title": "Week 2",
    "section": "Datum",
    "text": "Datum\n\nSo how are we to reconcile our need to work with a (simple) mathematical model of the earth‚Äôs shape with the undulating nature of the geoid?\nWe align the geoid with the ellipsoid to map the the earths departures from the smooth assumption\nThe alignment can be local where the ellipsoid surface is closely fit to the geoid at a particular location on the earth‚Äôs surface\n\nor\n\ngeocentric where the ellipsoid is aligned with the center of the earth.\nThe alignment of the smooth ellipsoid to the geoid model defines a datum."
  },
  {
    "objectID": "slides/week-2-1.html#local-datums",
    "href": "slides/week-2-1.html#local-datums",
    "title": "Week 2",
    "section": "Local Datums",
    "text": "Local Datums\n\nThere are many local datums to choose from\nThe choice of datum is largely driven by the location\nWhen working in the USA, a the North American Datum of 1927 (or NAD27 for short) is standard\n\nNAD27 is not well suited for other parts of the world.\n\n\nExamples of common local datums are shown in the following table:"
  },
  {
    "objectID": "slides/week-2-1.html#section-2",
    "href": "slides/week-2-1.html#section-2",
    "title": "Week 2",
    "section": "",
    "text": "Local datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1927\nNAD27\nContinental US\nThis is an old datum but still prevalent\n\n\nEuropean Datum of 1950\nED50\nWestern Europe\nDeveloped after World War II and still quite popular\n\n\nWorld Geodetic System 1972\nWGS72\nGlobal\nDeveloped by the Department of Defense."
  },
  {
    "objectID": "slides/week-2-1.html#geocentric-datum",
    "href": "slides/week-2-1.html#geocentric-datum",
    "title": "Week 2",
    "section": "Geocentric Datum",
    "text": "Geocentric Datum\n\nMany modern datums use a geocentric alignment\n\nWorld Geodetic Survey for 1984 (WGS84)\nNorth American Datums of 1983 (NAD83)\n\nMost popular geocentric datums use the WGS84 ellipsoid or the GRS80 ellipsoid which share nearly identical semi-major and semi-minor axes"
  },
  {
    "objectID": "slides/week-2-1.html#section-3",
    "href": "slides/week-2-1.html#section-3",
    "title": "Week 2",
    "section": "",
    "text": "Geocentric datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1983\nNAD83\nContinental US\nThis is one of the most popular modern datums for the contiguous US.\n\n\nEuropean Terrestrial Reference System 1989\nETRS89\nWestern Europe\nThis is the most popular modern datum for much of Europe.\n\n\nWorld Geodetic System 1984\nWGS84\nGlobal\nDeveloped by the Department of Defense.\n\n\n\n\n\n\n\n\n\nNote\n\n\nNAD 27 is based on Clarke Ellipsoid of 1866 which is calculated by manual surveying. NAD83 is based on the Geodetic Reference System (GRS) of 1980."
  },
  {
    "objectID": "slides/week-2-1.html#building-a-gcs",
    "href": "slides/week-2-1.html#building-a-gcs",
    "title": "Week 2",
    "section": "Building a GCS",
    "text": "Building a GCS\n\nSo, a GCS is defined by the ellipsoid model and its alignment to the geoid defining the datum.\nSmooth Sphere - Mathmatical Geoid (in angular units)"
  },
  {
    "objectID": "slides/week-2-1.html#projected-coordinate-systems",
    "href": "slides/week-2-1.html#projected-coordinate-systems",
    "title": "Week 2",
    "section": "Projected Coordinate Systems",
    "text": "Projected Coordinate Systems\n\nThe surface of the earth is curved but maps (and to data GIS) is flat.\nA projected coordinate system (PCS) is a reference system for identifying locations and measuring features on a flat (2D) surfaces. I\nProjected coordinate systems have an origin, an x axis, a y axis, and a linear unit of measure.\nGoing from a GCS to a PCS requires mathematical transformations.\nThere are three main groups of projection types:\n\nconic\ncylindrical\nplanar"
  },
  {
    "objectID": "slides/week-2-1.html#projection-types",
    "href": "slides/week-2-1.html#projection-types",
    "title": "Week 2",
    "section": "Projection Types:",
    "text": "Projection Types:\n\n\nIn all cases, distortion is minimized at the line/point of tangency (denoted by black line/point)\nDistortions are minimized along the tangency lines and increase with the distance from those lines."
  },
  {
    "objectID": "slides/week-2-1.html#plannar",
    "href": "slides/week-2-1.html#plannar",
    "title": "Week 2",
    "section": "Plannar",
    "text": "Plannar\n\nA planar projection projects data onto a flat surface touching the globe at a point or along 1 line of tangency.\nTypically used to map polar regions."
  },
  {
    "objectID": "slides/week-2-1.html#cylindrical",
    "href": "slides/week-2-1.html#cylindrical",
    "title": "Week 2",
    "section": "Cylindrical",
    "text": "Cylindrical\n\nA cylindrical projection maps the surface onto a cylinder.\nThis projection could also be created by touching the Earth‚Äôs surface along 1 or 2 lines of tangency\nMost often when mapping the entire world."
  },
  {
    "objectID": "slides/week-2-1.html#conic",
    "href": "slides/week-2-1.html#conic",
    "title": "Week 2",
    "section": "Conic",
    "text": "Conic\nIn a conic projection, the Earth‚Äôs surface is projected onto a cone along 1 or 2 lines of tangency\nTherefore, it is the best suited for maps of mid-latitude areas."
  },
  {
    "objectID": "slides/week-2-1.html#spatial-properties",
    "href": "slides/week-2-1.html#spatial-properties",
    "title": "Week 2",
    "section": "Spatial Properties",
    "text": "Spatial Properties\n\nAll projections distort real-world geographic features.\nThink about trying to unpeel an orange while preserving the skin\n\nThe four spatial properties that are subject to distortion are: shape, area, distance and direction\n\nA map that preserves shape is called conformal;\none that preserves area is called equal-area;\none that preserves distance is called equidistant\none that preserves direction is called azimuthal\nEach map projection can preserve only one or two of the four spatial properties.\nOften, projections are named after the spatial properties they preserve.\nWhen working with small-scale (large area) maps and when multiple spatial properties are needed, it is best to break the analyses across projections to minimize errors associated with spatial distortion."
  },
  {
    "objectID": "slides/week-2-1.html#setting-crsspcss",
    "href": "slides/week-2-1.html#setting-crsspcss",
    "title": "Week 2",
    "section": "Setting CRSs/PCSs",
    "text": "Setting CRSs/PCSs\n\nWe saw that sfc objects have two attributes to store a CRS: epsg and proj4string\n\n\nst_geometry(conus)\nGeometry set for 49 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\nMULTIPOLYGON (((-118.594 33.4672, -118.4848 33....\nMULTIPOLYGON (((-86.93428 45.42115, -86.83575 4...\nMULTIPOLYGON (((-117.243 44.39097, -117.2151 44...\nMULTIPOLYGON (((-97.22904 49.00069, -96.93096 4...\nMULTIPOLYGON (((-96.62187 42.77925, -96.57794 4...\n\n\nThis implies that all geometries in a geometry list-column (sfc) must have the same CRS.\nproj4string is a generic, string-based description of a CRS, understood by PROJ\nIt defines projection types and parameter values for particular projections,\nAs a result it can cover an infinite amount of different projections.\nepsg is the integer ID for a known CRS that can be resolved into a proj4string.\n\nThis is somewhat equivalent to the idea that a 6-digit FIP code can be resolved to a state/county pair\n\nSome proj4string values can resolved back into their corresponding epsg ID, but this does not always work.\nThe importance of having epsg values stored with data besides proj4string values is that the epsg refers to particular, well-known CRS, whose parameters may change (improve) over time\nfixing only the proj4string may remove the possibility to benefit from such improvements, and limit some of the provenance of datasets (but may help reproducibility)"
  },
  {
    "objectID": "slides/week-2-1.html#proj4-coordinate-syntax",
    "href": "slides/week-2-1.html#proj4-coordinate-syntax",
    "title": "Week 2",
    "section": "PROJ4 coordinate syntax",
    "text": "PROJ4 coordinate syntax\nThe PROJ4 syntax contains a list of parameters, each prefixed with the + character.\nA list of some PROJ4 parameters follows and the full list can be found here:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\n+a\nSemi-major radius of the ellipsoid axis\n\n\n+b\nSemi-minor radius of the ellipsoid axis\n\n\n+datum\nDatum name\n\n\n+ellps\nEllipsoid name\n\n\n+lat_0\nLatitude of origin\n\n\n+lat_1\nLatitude of first standard parallel\n\n\n+lat_2\nLatitude of second standard parallel\n\n\n+lat_ts\nLatitude of true scale\n\n\n+lon_0\nCentral meridian\n\n\n+over\nAllow longitude output outside -180 to 180 range, disables wrapping\n\n\n+proj\nProjection name\n\n\n+south\nDenotes southern hemisphere UTM zone\n\n\n+units\nmeters, US survey feet, etc.\n\n\n+x_0\nFalse easting\n\n\n+y_0\nFalse northing\n\n\n+zone\nUTM zone"
  },
  {
    "objectID": "slides/week-2-1.html#section-4",
    "href": "slides/week-2-1.html#section-4",
    "title": "Week 2",
    "section": "",
    "text": "WGS84\nEPSG: 4326\nPROJ4: +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\n- projection name: longlat\n- Latitude of origin: WGS84\n- Longitude of origin: WGS84\n\nWGS84\nEPSG: 5070\n\"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\"\n- projection name: aea (Albers Equal Area)\n- Latitude of origin: 23\n- Longitude of origin: -96\n- Latitude of first standard parallel: 29.5\n- Latitude of second standard parallel: 45.5\n- False Easting: 0\n- False Northing: 0\n- Datum: NAD83\n- Units: m"
  },
  {
    "objectID": "slides/week-2-1.html#transform-and-retrive",
    "href": "slides/week-2-1.html#transform-and-retrive",
    "title": "Week 2",
    "section": "Transform and retrive",
    "text": "Transform and retrive\n\n\n\nst_crs(conus)$epsg\n[1] 4326\nst_crs(conus)$proj4string\n[1] \"+proj=longlat +datum=WGS84 +no_defs\"\nst_crs(conus)$datum\n[1] \"WGS84\"\n\n\n\nconus5070 &lt;- st_transform(conus, 5070)\n\nst_crs(conus5070)$epsg\n[1] 5070\nst_crs(conus5070)$proj4string\n[1] \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\"\nst_crs(conus5070)$datum\n[1] \"NAD83\""
  },
  {
    "objectID": "slides/week-2-1.html#revisit-denver",
    "href": "slides/week-2-1.html#revisit-denver",
    "title": "Week 2",
    "section": "Revisit Denver",
    "text": "Revisit Denver\n\necho -104.9903 39.7392 | proj +proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\n-723281.88  6827.29\n\n\nred = false origin : blue = Denver"
  },
  {
    "objectID": "slides/week-2-1.html#geodesic-geometries",
    "href": "slides/week-2-1.html#geodesic-geometries",
    "title": "Week 2",
    "section": "Geodesic geometries",
    "text": "Geodesic geometries\n\nPCSs introduce errors in their geometric measurements because the distance between two points on an ellipsoid is difficult to replicate on a projected coordinate system unless these points are close to one another.\nIn most cases, such errors other sources of error in the feature representation outweigh measurement errors made in a PCS making them tolorable.\n\nHowever, if the domain of analysis is large (i.e.¬†the North American continent), then the measurement errors associated with a projected coordinate system may no longer be acceptable.\nA way to circumvent projected coordinate system limitations is to adopt a geodesic solution."
  },
  {
    "objectID": "slides/week-2-1.html#geodesic-measurments",
    "href": "slides/week-2-1.html#geodesic-measurments",
    "title": "Week 2",
    "section": "Geodesic Measurments",
    "text": "Geodesic Measurments\n\nA geodesic distance is the shortest distance between two points on an ellipsoid\nA geodesic area measurement is one that is measured on an ellipsoid.\nSuch measurements are independent of the underlying projected coordinate system.\nWhy does this matter?\nCompare the distances measured between Santa Barbara and Amsterdam. The blue line represents the shortest distance between the two points on a planar coordinate system. The red line as measured on a ellipsoid.\n\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\n\nAttaching package: 'maps'\nThe following object is masked from 'package:purrr':\n\n    map\nSpherical geometry (s2) switched off\nalthough coordinates are longitude/latitude, st_union assumes that they are\nplanar\nstars object downsampled to 1369 by 730 cells. See tm_shape manual (argument raster.downsample)"
  },
  {
    "objectID": "slides/week-2-1.html#section-5",
    "href": "slides/week-2-1.html#section-5",
    "title": "Week 2",
    "section": "",
    "text": "the geodesic distance looks weird given its curved appearance on the projected map.\nthis curvature is a byproduct of the current reference system‚Äôs increasing distance distortion as one moves towards the pole!\nWe can display the geodesic and planar distance on a 3D globe (or a projection that mimics the view of the 3D earth)."
  },
  {
    "objectID": "slides/week-2-1.html#section-6",
    "href": "slides/week-2-1.html#section-6",
    "title": "Week 2",
    "section": "",
    "text": "So if a geodesic measurement is more precise than a planar measurement, why not perform all spatial operations using geodesic geometry?\nThe downside is in its computational requirements.\nIt‚Äôs far more efficient to compute area/distance on a plane than it is on a spheroid.\nThis is because geodesic calculations have no simple algebraic solutions and involve approximations that may require iteration! (think optimization or nonlinear solutions)\nSo this may be a computationally taxing approach if processing 1,000(s) or 1,000,000(s) of line segments."
  },
  {
    "objectID": "slides/week-2-1.html#gedesic-area-and-length-measurements",
    "href": "slides/week-2-1.html#gedesic-area-and-length-measurements",
    "title": "Week 2",
    "section": "Gedesic Area and Length Measurements",
    "text": "Gedesic Area and Length Measurements\n\nNot all algorthimns are equal (in terms of speed or accuracy)\nSome more efficient algorithms that minimize computation time may reduce precision in the process.\nSome of ArcMap‚Äôs functions offer the option to compute geodesic distances and areas however ArcMap does not clearly indicate how its geodesic calculations are implemented (cite\nR is well documented, and is efficient!"
  },
  {
    "objectID": "slides/week-2-1.html#distances",
    "href": "slides/week-2-1.html#distances",
    "title": "Week 2",
    "section": "Distances",
    "text": "Distances\n?st_distance"
  },
  {
    "objectID": "slides/week-2-1.html#native-sf-binds-to-libwgeom",
    "href": "slides/week-2-1.html#native-sf-binds-to-libwgeom",
    "title": "Week 2",
    "section": "native sf binds to libwgeom",
    "text": "native sf binds to libwgeom"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example",
    "href": "slides/week-2-1.html#distance-example",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-1",
    "href": "slides/week-2-1.html#distance-example-1",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-2",
    "href": "slides/week-2-1.html#distance-example-2",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-3",
    "href": "slides/week-2-1.html#distance-example-3",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)\nUnits: [m]\n        [,1]    [,2]\n[1,]       0 4050406\n[2,] 4050406       0"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-4",
    "href": "slides/week-2-1.html#distance-example-4",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)\nUnits: [m]\n        [,1]    [,2]\n[1,]       0 4050406\n[2,] 4050406       0\nUnits: [¬∞]\n         1        2\n1  0.00000 46.12338\n2 46.12338  0.00000"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-5",
    "href": "slides/week-2-1.html#distance-example-5",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)\nUnits: [m]\n        [,1]    [,2]\n[1,]       0 4050406\n[2,] 4050406       0\nUnits: [¬∞]\n         1        2\n1  0.00000 46.12338\n2 46.12338  0.00000\nUnits: [m]\n        1       2\n1       0 4017987\n2 4017987       0"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-6",
    "href": "slides/week-2-1.html#distance-example-6",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)\nUnits: [m]\n        [,1]    [,2]\n[1,]       0 4050406\n[2,] 4050406       0\nUnits: [¬∞]\n         1        2\n1  0.00000 46.12338\n2 46.12338  0.00000\nUnits: [m]\n        1       2\n1       0 4017987\n2 4017987       0\nUnits: [m]\n        1       2\n1       0 3823549\n2 3823549       0"
  },
  {
    "objectID": "slides/week-2-1.html#distance-example-7",
    "href": "slides/week-2-1.html#distance-example-7",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"), crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n        y         x name\n1 40.7128  -74.0060  NYC\n2 34.4208 -119.6982   SB\nSimple feature collection with 2 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\nGeodetic CRS:  WGS 84\n  name                  geometry\n1  NYC   POINT (-74.006 40.7128)\n2   SB POINT (-119.6982 34.4208)\nUnits: [m]\n        [,1]    [,2]\n[1,]       0 4050406\n[2,] 4050406       0\nUnits: [¬∞]\n         1        2\n1  0.00000 46.12338\n2 46.12338  0.00000\nUnits: [m]\n        1       2\n1       0 4017987\n2 4017987       0\nUnits: [m]\n        1       2\n1       0 3823549\n2 3823549       0"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus",
    "href": "slides/week-2-1.html#area-example-conus",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus-1",
    "href": "slides/week-2-1.html#area-example-conus-1",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus-2",
    "href": "slides/week-2-1.html#area-example-conus-2",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df)"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus-3",
    "href": "slides/week-2-1.html#area-example-conus-3",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) ))"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus-4",
    "href": "slides/week-2-1.html#area-example-conus-4",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-2-1.html#area-example-conus-5",
    "href": "slides/week-2-1.html#area-example-conus-5",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw() +\n  labs(x = \"SRS\", y = \"m2\")"
  },
  {
    "objectID": "slides/week-2-1.html#units-in-sf",
    "href": "slides/week-2-1.html#units-in-sf",
    "title": "Week 2",
    "section": "Units in sf",
    "text": "Units in sf\n\nThe CRS in sf encodes the units of measurement relating to spatial features\nWhere possible geometric operations such as st_distance(), st_length() and st_area() report results with a units attribute appropriate for the CRS:\nThis can be both handy and very confusing for those new to it. Consider the following:\n\n\n(l = sum(st_length(conus)))\n94980149 [m]\n(a = sum(st_area(conus)))\n7.83761e+12 [m^2]"
  },
  {
    "objectID": "slides/week-2-1.html#section-7",
    "href": "slides/week-2-1.html#section-7",
    "title": "Week 2",
    "section": "",
    "text": "We can set units if we do manipulations as well using the units package\n\nunits::set_units(l, \"km\")\n94980.15 [km]\nunits::set_units(l, \"mile\")\n59017.93 [mile]\n\nunits::set_units(a, \"ha\")\n783760974 [ha]\nunits::set_units(a, \"km2\")\n7837610 [km^2]\nunits::set_units(a, \"in2\")\n1.214832e+16 [in^2]"
  },
  {
    "objectID": "slides/week-2-1.html#units-are-a-class",
    "href": "slides/week-2-1.html#units-are-a-class",
    "title": "Week 2",
    "section": "Units are a class",
    "text": "Units are a class\n\nunits are an S3 data object with attribute information and ‚Äúrules of engagement‚Äù\n\n\nclass(st_length(conus)) \n[1] \"units\"\nattributes(st_length(conus)) |&gt; unlist()\nunits.numerator           class \n            \"m\"         \"units\" \n\nst_length(conus) + 100\nError in Ops.units(st_length(conus), 100): both operands of the expression should be \"units\" objects\n\nconus |&gt; \n  mutate(area = st_area(.)) |&gt; \n  ggplot(aes(x = name, y = area)) + \n  geom_col()\nError in `stopifnot()`:\n‚Ñπ In argument: `area = st_area(.)`.\nCaused by error:\n! object '.' not found"
  },
  {
    "objectID": "slides/week-2-1.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "href": "slides/week-2-1.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "title": "Week 2",
    "section": "Unit values can be stripped of their attributes if need be:",
    "text": "Unit values can be stripped of their attributes if need be:\n\n# Via drop_units\n(units::drop_units(sum(st_length(conus))))\n[1] 94980149\n\n# Via casting\n(as.numeric(sum(st_length(conus))))\n[1] 94980149"
  },
  {
    "objectID": "slides/leaflet-examples.html",
    "href": "slides/leaflet-examples.html",
    "title": "Interactive Mapping in R",
    "section": "",
    "text": "This is the supplementary notes and examples for an introduction to leaflet.\nIt is based on data and examples seen in class\nBuilt on the excellent tutorial from RStudio\n\nIf not already installed, install leaflet:\n\ninstall.packages(\"leaflet\")\n\nThen attach the library:\n\nlibrary(leaflet)\n\nBring in the other needed libraries:\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(USAboundaries)\n\n\n\nBasic Usage\nCreating a Leaflet map requires a few basic steps (not dissimilar to ggplot):\n\nInitialize a map widget by calling leaflet().\nAdd layers (i.e., features) to the map by using layer functions (e.g.¬†addTiles, addMarkers, addPolygons,‚Ä¶)\nPrint the map widget to display it.\n\n\nHere‚Äôs a basic example:\n\nleaflet() |&gt;\n  addTiles() |&gt;\n  addMarkers(lng=-105.0848, lat=40.5729, popup=\"CSU\")\n\n\n\n\n\n\n\nBy default, leaflet sets the view of the map to the range of latitude/longitude data in the map layers\nYou can adjust these if needed using:\n\nsetView(): sets the center of the map view and the zoom level;\nfitBounds(): fits the view into the rectangle [lng1, lat1] ‚Äì [lng2, lat2];\nclearBounds() clears the bound\n\n\n\n\n\nBasemaps\n\nDefault (OpenStreetMap) Tiles\nThe easiest way to add tiles is by calling addTiles() with no arguments; by default, OpenStreetMap tiles are used.\n\nleaflet() |&gt; \n  setView(lng=-105.0848, lat=40.5729, zoom = 16) |&gt; \n  addTiles()\n\n\n\n\n\n\n\nThird-Party Tiles\n\nMany third-party basemaps can be added using the addProviderTiles() function\nAs a convenience, leaflet provides a named list of all the third-party tile providers supported by the plugin: just type providers$ and choose from one of the options.\n\n\nlength(providers)\n\n#&gt; [1] 233\n\nnames(providers) |&gt; \n  head()\n\n#&gt; [1] \"OpenStreetMap\"        \"OpenStreetMap.Mapnik\" \"OpenStreetMap.DE\"    \n#&gt; [4] \"OpenStreetMap.CH\"     \"OpenStreetMap.France\" \"OpenStreetMap.HOT\"\n\n\n\nNote that some tile set providers require you to register. You can pass access tokens/keys, and other options, to the tile provider by populating the options argument with the providerTileOptions() function.\n\n\nI would personal stick with the OSM, CartoDB, ESRI, and Stamen servers ‚Ä¶ [see more here] (https://leaflet-extras.github.io/leaflet-providers/preview/)\n\nBelow are a few examples:\n\n\nCartoDB\n\nleaflet() |&gt; \n  setView(lng=-105.0848, lat=40.5729, zoom = 16) |&gt; \n  addProviderTiles(providers$CartoDB)\n\n\n\n\n\n\n\nESRI Imagery\n\nleaflet() |&gt; \n  setView(lng=-105.0848, lat=40.5729, zoom = 16) |&gt; \n  addProviderTiles(providers$Esri.WorldImagery)\n\n\n\n\n\n\n\nCombining Tile Layers\nYou can stack multiple tile layers if the front tiles have some level of opacity. Here we layer the Stamen.TonerLines with aerial imagery\n\nleaflet() |&gt; \n  setView(lng=-105.0848, lat=40.5729, zoom = 14) |&gt; \n  addProviderTiles(providers$Esri.WorldImagery) |&gt; \n  addProviderTiles(providers$Stadia.StamenTonerLines,\n                   options = providerTileOptions(opacity = .5)) \n\n\n\n\n\n\n\n\n\nMarkers\nMarkers are one way to identify point information on a map:\n\n\nExample Starbucks data:\n\n(starbucks = read_csv('data/directory.csv') |&gt; \n  filter(City %in% c(\"Fort Collins\", \"Loveland\"),\n         `State/Province` == \"CO\") |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt; \n  select(store_name = `Store Name`, phone = `Phone Number`, address = `Street Address`, city = City, brand = Brand))\n\n#&gt; Simple feature collection with 21 features and 5 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -105.12 ymin: 40.38 xmax: -105.01 ymax: 40.61\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 21 √ó 6\n#&gt;    store_name                phone address city  brand        geometry\n#&gt;    &lt;chr&gt;                     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;POINT [¬∞]&gt;\n#&gt;  1 Harmony & Timberline-For‚Ä¶ 970-‚Ä¶ 4609 S‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.04 40.52)\n#&gt;  2 Safeway-Fort Collins #10‚Ä¶ 970-‚Ä¶ 460A S‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.08 40.58)\n#&gt;  3 Scotch Pines              970-‚Ä¶ 2601 S‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.06 40.55)\n#&gt;  4 King Soopers-Fort Collin‚Ä¶ 970-‚Ä¶ 2602 S‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.04 40.55)\n#&gt;  5 Safeway-Fort Collins #29‚Ä¶ 970-‚Ä¶ 2160 W‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.12 40.55)\n#&gt;  6 Harmony & JFK             (970‚Ä¶ 250 E.‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.07 40.52)\n#&gt;  7 Safeway-Fort Collins #15‚Ä¶ 970-‚Ä¶ 1426 E‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.05 40.52)\n#&gt;  8 SuperTarget Fort Collins‚Ä¶ &lt;NA&gt;  2936 C‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.08 40.53)\n#&gt;  9 King Soopers-Fort Collin‚Ä¶ 970-‚Ä¶ 1015 S‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.12 40.57)\n#&gt; 10 King Soopers-Ft. Collins‚Ä¶ 970-‚Ä¶ 1842 N‚Ä¶ Fort‚Ä¶ Star‚Ä¶ (-105.08 40.61)\n#&gt; # ‚Ñπ 11 more rows\n\n\n\n\nMarkers\nMarkers are added using the addMarkers or addAwesomeMarkers\nTheir default appearance is a blue dropped pin.\nAs with most layer functions, - the popup argument adds a message to be displayed on click - the label argument display a text label either on hover\n\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addMarkers(data = starbucks, popup = ~store_name, label = ~city)\n\n\n\n\n\n\n\nAwesome Icons\nUsing the Font Awesome Icons seen in lab one, we can make markers with more specific coloring and icons\n\nHere we define the icon as a green marker with a coffee icon from the fa library\nFor fun we can make the coffee cups spin‚Ä¶\n\nWe then use addAwesomeMarkers to spcifiy the icon we created using the icon argument:\n\nicons = awesomeIcons(icon = 'coffee', markerColor = \"green\", library = 'fa', spin = TRUE)\n\nleaflet(data = starbucks) |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addAwesomeMarkers(icon = icons, popup = ~store_name)\n\n\n\n\n\n\n\nCustom Popups\nYou can use HTML, CSS, and Java Script to modify your pop-ups\nFor example, we can associate the name of the Starbucks locations with their google maps URL as an hyper reference (href):\n\nstarbucks = starbucks |&gt; \n  mutate(url = paste0('https://www.google.com/maps/place/',\n                      gsub(\" \", \"+\", address), \"+\",\n                      gsub(\" \", \"+\", city)))\n\npop = paste0('&lt;a href=', starbucks$url, '&gt;', starbucks$store_name, \"&lt;/a&gt;\")\nhead(pop)\n\n#&gt; [1] \"&lt;a href=https://www.google.com/maps/place/4609+S+Timberline+Rd,+Unit+A101+Fort+Collins&gt;Harmony & Timberline-Fort Collins&lt;/a&gt;\"\n#&gt; [2] \"&lt;a href=https://www.google.com/maps/place/460A+South+College+Fort+Collins&gt;Safeway-Fort Collins #1071&lt;/a&gt;\"                    \n#&gt; [3] \"&lt;a href=https://www.google.com/maps/place/2601+S+Lemay,+Ste+130+Fort+Collins&gt;Scotch Pines&lt;/a&gt;\"                               \n#&gt; [4] \"&lt;a href=https://www.google.com/maps/place/2602+S+Timberline+Rd+Fort+Collins&gt;King Soopers-Fort Collins #97&lt;/a&gt;\"               \n#&gt; [5] \"&lt;a href=https://www.google.com/maps/place/2160+W+Drake+Rd,+Unit+6+Fort+Collins&gt;Safeway-Fort Collins #2913&lt;/a&gt;\"               \n#&gt; [6] \"&lt;a href=https://www.google.com/maps/place/250+E.+Harmony+Road+Fort+Collins&gt;Harmony & JFK&lt;/a&gt;\"\n\n\nWe can then add our custom popup to our icons:\n\nleaflet(data = starbucks) |&gt;\n  addProviderTiles(providers$CartoDB) |&gt; \n  addAwesomeMarkers(icon = icons, \n                    label = ~address, popup = pop)\n\n\n\n\n\n\n\nCircle Markers\nCircle markers are much like regular circles (shapes), except their radius in onscreen pixels stays constant regardless of zoom level (z).\n\nleaflet(data = starbucks) |&gt;\n  addProviderTiles(providers$CartoDB) |&gt; \n  addCircleMarkers(label = ~address, popup = pop)\n\n\n\n\n\n\nMarker Clustering\nSometimes while mapping many points, it is useful to cluster them. For example lets plot all starbucks in the world!\n\nall_co = read_csv('data/directory.csv') |&gt; \n  filter(!is.na(Latitude)) |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) \n\nleaflet(data = all_co) |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addMarkers(clusterOptions = markerClusterOptions())\n\n\n\n\n\n\n\n\n\n\nAdding color ramps\n\nColors can be add by factor, numeric, bins, or quartiles using the built in leaflet functions\nEach of these are defined by a palette, and a domain\n\nThe palette argument can be any of the following:\n\nA character vector of RGB or named colors.\n\nExamples: palette(), c(‚Äú#000000‚Äù, ‚Äú#0000FF‚Äù, ‚Äú#FFFFFF‚Äù), topo.colors(10)\n\nThe name of an RColorBrewer palette\n\nExamples: ‚ÄúBuPu‚Äù or ‚ÄúGreens‚Äù.\n\nThe full name of a viridis palette:\n\nExamples: ‚Äúviridis‚Äù, ‚Äúmagma‚Äù, ‚Äúinferno‚Äù, or ‚Äúplasma‚Äù.\n\nA function that receives a single value between 0 and 1 and returns a color.\n\nExamples: colorRamp(c(‚Äú#000000‚Äù, ‚Äú#FFFFFF‚Äù), interpolate = ‚Äúspline‚Äù).\n\n\nThe domain is the values - named by variable - that the color palette should range over\n\n# ?colorFactor\n\n# Create a palette that maps factor levels to colors\npal &lt;- colorFactor(c(\"darkgreen\", \"navy\"), domain = c(\"Goleta\", \"Santa Barbara\"))\n\nleaflet(data = starbucks) |&gt; addProviderTiles(providers$CartoDB) |&gt; \n  addCircleMarkers(color = ~pal(city), fillOpacity = .5, stroke = FALSE)\n\n\n\n\n\n\n\n\nShapes (Polylines, Polygons, Circles)\n\nGetting some data ‚Ä¶\n\n(covid = readr::read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-states.csv') |&gt; \n  filter(date == max(date)) |&gt; \n  right_join(USAboundaries::us_states(), by = c(\"state\" = \"name\")) |&gt; \n  filter(!stusps %in% c(\"AK\",\"PR\", \"HI\")) |&gt; \n  st_as_sf())\n\n#&gt; Simple feature collection with 49 features and 16 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7258 ymin: 24.49813 xmax: -66.9499 ymax: 49.38436\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 49 √ó 17\n#&gt;    date       state    fips   cases deaths statefp statens affgeoid geoid stusps\n#&gt;    &lt;date&gt;     &lt;chr&gt;    &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; \n#&gt;  1 2023-03-24 Tenness‚Ä¶ 47    2.46e6  29035 47      013258‚Ä¶ 0400000‚Ä¶ 47    TN    \n#&gt;  2 2023-03-24 Michigan 26    3.07e6  42311 26      017797‚Ä¶ 0400000‚Ä¶ 26    MI    \n#&gt;  3 2023-03-24 Massach‚Ä¶ 25    2.23e6  24441 25      006069‚Ä¶ 0400000‚Ä¶ 25    MA    \n#&gt;  4 2023-03-24 Maryland 24    1.37e6  16672 24      017149‚Ä¶ 0400000‚Ä¶ 24    MD    \n#&gt;  5 2023-03-24 Iowa     19    9.07e5  10770 19      017797‚Ä¶ 0400000‚Ä¶ 19    IA    \n#&gt;  6 2023-03-24 Maine    23    3.20e5   2981 23      017797‚Ä¶ 0400000‚Ä¶ 23    ME    \n#&gt;  7 2023-03-24 Texas    48    8.45e6  94518 48      017798‚Ä¶ 0400000‚Ä¶ 48    TX    \n#&gt;  8 2023-03-24 Louisia‚Ä¶ 22    1.58e6  18835 22      016295‚Ä¶ 0400000‚Ä¶ 22    LA    \n#&gt;  9 2023-03-24 Kansas   20    9.41e5  10232 20      004818‚Ä¶ 0400000‚Ä¶ 20    KS    \n#&gt; 10 2023-03-24 Kentucky 21    1.72e6  18348 21      017797‚Ä¶ 0400000‚Ä¶ 21    KY    \n#&gt; # ‚Ñπ 39 more rows\n#&gt; # ‚Ñπ 7 more variables: lsad &lt;chr&gt;, aland &lt;dbl&gt;, awater &lt;dbl&gt;, state_name &lt;chr&gt;,\n#&gt; #   state_abbr &lt;chr&gt;, jurisdiction_type &lt;chr&gt;, geometry &lt;MULTIPOLYGON [¬∞]&gt;\n\n\n\n\nPolygons\nAdding those cases counts to polygons over a YlOrRd color ramp\n\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addPolygons(data = covid, \n              fillColor  = ~colorQuantile(\"YlOrRd\", cases)(cases),\n              color = NA,\n              label = ~state_name)\n\n\n\n\n\n\n\nCircles\n\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB.DarkMatter) |&gt; \n  addCircles(data = st_centroid(covid), \n             fillColor  = ~colorQuantile(\"YlOrRd\", cases)(cases),\n             color = NA,\n             fillOpacity = .5,\n             radius = ~cases/50,\n             label = ~state)\n\n\n\n\n\n\n\n\nWeb based data\n\nUSGS Gage near UCSB: ID-11120000\nhttps://waterdata.usgs.gov/monitoring-location/11120000/\n\n\n\n\n\n\n\n\n\n\n\nNetwork Linked Data (GeoJSON)\nhttps://labs.waterdata.usgs.gov/api/nldi/linked-data/nwissite/USGS-11120000/navigate/UT\nTrance the Upper Tributary (UT) of the USGS-11120000\n\n\n\n\n\n\n\n\n\n\n\nAdding ‚ÄúWeb data‚Äù to the map\n\nid = \"11120000\"\n\n# base URL\n(base = dataRetrieval:::pkg.env$nldi_base)\n\n#&gt; [1] \"https://api.water.usgs.gov/nldi/linked-data/\"\n\n# Reading sf for URLs in line\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addPolylines(data = read_sf(paste0(base,'nwissite/USGS-',id,'/navigate/UT'))) |&gt; \n  addPolygons(data =  read_sf(paste0(base,'nwissite/USGS-',id,'/basin')), \n              fillColor =  \"transparent\", color = \"black\")\n\n\n\n\n\n\n\n\nWMS Tiles\nWMS tiles can be added directly to a map. Here we use the NEXRAD rainfall information (refelctivity) from the Iowa Mesonet Program\n(You may need to scroll out to find an)\n\nconus = filter(us_states(), !stusps %in% c(\"AK\", \"PR\", \"HI\"))\n\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addPolygons(data = st_union(conus), fillColor = \"transparent\",\n              color = \"black\", weight = 1) |&gt; \n  addWMSTiles(\n    \"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi\",\n    layers = \"nexrad-n0r-900913\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE)\n  )\n\n\n\n\n\n\n\n\nLayer Controls\nUses Leaflet‚Äôs built-in layers control you can choose one of several base layers, and any number of overlay layers to view.\nBy defining groups, you have the ability to toogle layers, and overlays on/off.\n\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB, group = \"Grayscale\") |&gt; \n  addProviderTiles(providers$Esri.WorldTerrain, group = \"Terrain\") |&gt; \n  addPolylines(data = read_sf(paste0(base,'nwissite/USGS-',id,'/navigate/UT'))) |&gt; \n  addPolygons(data =  read_sf(paste0(base,'nwissite/USGS-',id,'/basin')), fillColor =  \"transparent\", color = \"black\", group = \"basin\") |&gt; \n  addWMSTiles(\"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi\", layers = \"nexrad-n0r-900913\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE)) |&gt; \n  addLayersControl(overlayGroups = c(\"basin\"), baseGroups = c(\"Terrain\", \"Grayscale\"))\n\n\n\n‚ÄòFunction-ize‚Äô\nYou can wrap your mapping code in functions to allow reusability\n\nwatershed_map = function(gage_id){\nleaflet() |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addPolylines(data = read_sf(paste0(base,'nwissite/USGS-',gage_id,'/navigate/UT'))) |&gt; \n  addPolygons(data =  read_sf(paste0(base,'nwissite/USGS-',gage_id,'/basin')), \n              fillColor =  \"transparent\", color = \"black\", group = \"basin\") |&gt; \n  addWMSTiles(\"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi\", layers = \"nexrad-n0r-900913\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE))\n}\n\n\nwatershed_map(\"06752260\")\n\n\n\n\n\n\nAdding Details\n\nMeasures, graticules, and inset maps\n\n\nwatershed_map(\"06752260\") |&gt; \n  addMeasure() |&gt; \n  addGraticule() |&gt; \n  addMiniMap()\n\n\n\n\n\n\n\nleafem (new library)\n\nHome buttons and Mouse Coordinates\nSupport for raster and stars objects (to come)\n\n\nwatershed_map(\"06752260\") |&gt; \n  addMeasure() |&gt; \n  addGraticule() |&gt; \n  leafem::addHomeButton(group = \"basin\") |&gt; \n  leafem::addMouseCoordinates() \n\n\n\n\n\n\n\nleafpop (new library)\n\nPopup Tables\n\n\nleaflet(data = starbucks) |&gt; \n  addProviderTiles(providers$CartoDB) |&gt; \n  addCircleMarkers(\n    color = ~pal(city), \n    fillOpacity = .5,\n    stroke = FALSE, \n    popup = leafpop::popupTable(starbucks)\n  )\n\n\n\n\n\nMaking that table nicer‚Ä¶\n\nleaflet(data = starbucks) |&gt; addProviderTiles(providers$CartoDB) |&gt; \n  addCircleMarkers(\n    color = ~pal(city), fillOpacity = .5,\n    stroke = FALSE, \n    popup = leafpop::popupTable(st_drop_geometry(starbucks[,1:5]), feature.id = FALSE, row.numbers = FALSE)\n  )\n\n\n\n\n\n\n\n\nMapview\n\neasy, but less control\nSupport for raster and stars objects (to come in our class)\nImplements many of the leafem and leafpop functionalities\n\n\nlibrary(mapview)\nmapview(starbucks)"
  },
  {
    "objectID": "slides/week-2.html#section",
    "href": "slides/week-2.html#section",
    "title": "Week 2",
    "section": "",
    "text": "The remaining geometries 10 are rarer, but increasingly find implementations:\n\n\n\n\n\n\n\ntype\ndescription\n\n\n\n\nCIRCULARSTRING\nThe CIRCULARSTRING is the basic curve type, similar to a LINESTRING in the linear world. A single segment requires three points, the start and end points (first and third) and any other point on the arc. The exception to this is for a closed circle, where the start and end points are the same. In this case the second point MUST be the center of the arc, i.e., the opposite side of the circle. To chain arcs together, the last point of the previous arc becomes the first point of the next arc, just like in LINESTRING. This means that a valid circular string must have an odd number of points greater than 1.\n\n\nCOMPOUNDCURVE\nA compound curve is a single, continuous curve that has both curved (circular) segments and linear segments. That means that in addition to having well-formed components, the end point of every component (except the last) must be coincident with the start point of the following component.\n\n\nCURVEPOLYGON\nExample compound curve in a curve polygon: CURVEPOLYGON(COMPOUNDCURVE(CIRCULARSTRING(0 0,2 0, 2 1, 2 3, 4 3),(4 3, 4 5, 1 4, 0 0)), CIRCULARSTRING(1.7 1, 1.4 0.4, 1.6 0.4, 1.6 0.5, 1.7 1) )\n\n\nMULTICURVE\nA MultiCurve is a 1-dimensional GeometryCollection whose elements are Curves, it can include linear strings, circular strings or compound strings.\n\n\nMULTISURFACE\nA MultiSurface is a 2-dimensional GeometryCollection whose elements are Surfaces, all using coordinates from the same coordinate reference system.\n\n\nCURVE\nA Curve is a 1-dimensional geometric object usually stored as a sequence of Points, with the subtype of Curve specifying the form of the interpolation between Points\n\n\nSURFACE\nA Surface is a 2-dimensional geometric object\n\n\nPOLYHEDRALSURFACE\nA PolyhedralSurface is a contiguous collection of polygons, which share common boundary segments\n\n\nTIN\nA TIN (triangulated irregular network) is a PolyhedralSurface consisting only of Triangle patches.\n\n\nTRIANGLE\nA Triangle is a polygon with 3 distinct, non-collinear vertices and no interior boundary"
  },
  {
    "objectID": "slides/week-2.html#so-far",
    "href": "slides/week-2.html#so-far",
    "title": "Week 2",
    "section": "So far ‚Ä¶",
    "text": "So far ‚Ä¶\nWe‚Äôve discussed the simple feature standard\n\nGeometries (type, dimension, and structure)\n\n- Empty, Valid, Simple\n\nEncoding (WKT & WKB)\nA set of operations\n\nAnd the implementation of the simple features standard in R\n\nsfg: a single feature geometry\nsfc: a set of geometries (sfg) stored as a list\nsf: a sfc list joined with a data.frame (attributes)\n\nThis R implementation is ideal/special because it achieves the simple feature abstract goal of:\n\n‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes‚Ä¶‚Äù - standard.\n\nThe shapefile/GIS traditional GIS view does not do this and seperates geometry (shp), from projection (prj), from data (dbf) and relates them through an shx file"
  },
  {
    "objectID": "slides/week-2.html#integration-with-tidyverse",
    "href": "slides/week-2.html#integration-with-tidyverse",
    "title": "Week 2",
    "section": "Integration with tidyverse",
    "text": "Integration with tidyverse\n\nWe saw how the dplyr verbs still work on an sf object since sf extends the data.frame class\nHow geom_sf support mapping (‚Äúspatial plotting‚Äù) in ggplot\nHow to read spatial data into R via GDAL drivers:\n\nspatial files (read_sf)\nflat files via st_as_sf\n\nIntegration with a few GEOS geometry operations like:\n\nst_combine()\nst_union()"
  },
  {
    "objectID": "slides/week-2.html#taki",
    "href": "slides/week-2.html#taki",
    "title": "Week 2",
    "section": "Taki ‚Ä¶",
    "text": "Taki ‚Ä¶\n\n\n\nconus &lt;-  USAboundaries::us_states() |&gt;\n  filter(!state_name %in% c(\"Puerto Rico\", \n                            \"Alaska\", \n                            \"Hawaii\"))\n\nlength(st_geometry(conus))\n#&gt; [1] 49"
  },
  {
    "objectID": "slides/week-2.html#feature-resoloved-and-combined",
    "href": "slides/week-2.html#feature-resoloved-and-combined",
    "title": "Week 2",
    "section": "1 feature: resoloved and combined:",
    "text": "1 feature: resoloved and combined:\n\nst_cast / st_union work on sfg, sfc, and sf objects:\n\n\nconus &lt;- AOI::aoi_get(state = \"conus\")\n\nus_c_ml = st_combine(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")\n   \nus_u_ml = st_union(conus) |&gt;\n  st_cast(\"MULTILINESTRING\")"
  },
  {
    "objectID": "slides/week-2.html#so-what",
    "href": "slides/week-2.html#so-what",
    "title": "Week 2",
    "section": "So what?",
    "text": "So what?\nLets imagine we want to know the distance from Denver to the nearest state border:\nTo do this, we need to:\n\n1: define Denver as a geometry in a CRS\n2: determine the correct geometry types / representation\n3: calculate the distance between (1) and (2)"
  },
  {
    "objectID": "slides/week-2.html#make-denver-in-the-crs-of-our-states",
    "href": "slides/week-2.html#make-denver-in-the-crs-of-our-states",
    "title": "Week 2",
    "section": "1. Make ‚ÄúDenver‚Äù in the CRS of our states",
    "text": "1. Make ‚ÄúDenver‚Äù in the CRS of our states\n\ndenver_sf &lt;- data.frame(y = 39.7392, \n                       x = -104.9903, \n                       name = \"Denver\") |&gt; \n  st_as_sf(coords = c(\"x\", \"y\"), \n           crs = 4326)"
  },
  {
    "objectID": "slides/week-2.html#determine-the-3-closest-states",
    "href": "slides/week-2.html#determine-the-3-closest-states",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus\n\n\n\n#&gt; Simple feature collection with 49 features and 14 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_region state_division feature_code           state_name state_abbr\n#&gt; 1             3              6      1779775              Alabama         AL\n#&gt; 2             4              8      1779777              Arizona         AZ\n#&gt; 3             3              7      0068085             Arkansas         AR\n#&gt; 4             4              9      1779778           California         CA\n#&gt; 5             4              8      1779779             Colorado         CO\n#&gt; 6             1              1      1779780          Connecticut         CT\n#&gt; 7             3              5      1779781             Delaware         DE\n#&gt; 8             3              5      1702382 District of Columbia         DC\n#&gt; 9             3              5      0294478              Florida         FL\n#&gt; 10            3              5      1705317              Georgia         GA\n#&gt;                    name fip_class tiger_class combined_area_code\n#&gt; 1               Alabama      &lt;NA&gt;       G4000                 NA\n#&gt; 2               Arizona      &lt;NA&gt;       G4000                 NA\n#&gt; 3              Arkansas      &lt;NA&gt;       G4000                 NA\n#&gt; 4            California      &lt;NA&gt;       G4000                 NA\n#&gt; 5              Colorado      &lt;NA&gt;       G4000                 NA\n#&gt; 6           Connecticut      &lt;NA&gt;       G4000                 NA\n#&gt; 7              Delaware      &lt;NA&gt;       G4000                 NA\n#&gt; 8  District of Columbia      &lt;NA&gt;       G4000                 NA\n#&gt; 9               Florida      &lt;NA&gt;       G4000                 NA\n#&gt; 10              Georgia      &lt;NA&gt;       G4000                 NA\n#&gt;    metropolitan_area_code functional_status    land_area  water_area fip_code\n#&gt; 1                    &lt;NA&gt;                 A 131175477769  4591897964       01\n#&gt; 2                    &lt;NA&gt;                 A 294363973043   855871553       04\n#&gt; 3                    &lt;NA&gt;                 A 134660767709  3121950081       05\n#&gt; 4                    &lt;NA&gt;                 A 403671756816 20293573058       06\n#&gt; 5                    &lt;NA&gt;                 A 268418796417  1185716938       08\n#&gt; 6                    &lt;NA&gt;                 A  12541690473  1816424193       09\n#&gt; 7                    &lt;NA&gt;                 A   5046731559  1399179670       10\n#&gt; 8                    &lt;NA&gt;                 A    158316124    18709762       11\n#&gt; 9                    &lt;NA&gt;                 A 138961722096 45972570361       12\n#&gt; 10                   &lt;NA&gt;                 A 149486624386  4418360134       13\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-85.4883 30...\n#&gt; 2  MULTIPOLYGON (((-110.7507 3...\n#&gt; 3  MULTIPOLYGON (((-90.95577 3...\n#&gt; 4  MULTIPOLYGON (((-116.1062 3...\n#&gt; 5  MULTIPOLYGON (((-105.155 36...\n#&gt; 6  MULTIPOLYGON (((-72.5279 41...\n#&gt; 7  MULTIPOLYGON (((-75.13846 3...\n#&gt; 8  MULTIPOLYGON (((-77.00244 3...\n#&gt; 9  MULTIPOLYGON (((-83.10874 2...\n#&gt; 10 MULTIPOLYGON (((-81.09538 3..."
  },
  {
    "objectID": "slides/week-2.html#determine-the-3-closest-states-1",
    "href": "slides/week-2.html#determine-the-3-closest-states-1",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;              state_name                       geometry\n#&gt; 1               Alabama MULTIPOLYGON (((-85.4883 30...\n#&gt; 2               Arizona MULTIPOLYGON (((-110.7507 3...\n#&gt; 3              Arkansas MULTIPOLYGON (((-90.95577 3...\n#&gt; 4            California MULTIPOLYGON (((-116.1062 3...\n#&gt; 5              Colorado MULTIPOLYGON (((-105.155 36...\n#&gt; 6           Connecticut MULTIPOLYGON (((-72.5279 41...\n#&gt; 7              Delaware MULTIPOLYGON (((-75.13846 3...\n#&gt; 8  District of Columbia MULTIPOLYGON (((-77.00244 3...\n#&gt; 9               Florida MULTIPOLYGON (((-83.10874 2...\n#&gt; 10              Georgia MULTIPOLYGON (((-81.09538 3..."
  },
  {
    "objectID": "slides/week-2.html#determine-the-3-closest-states-2",
    "href": "slides/week-2.html#determine-the-3-closest-states-2",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\n#&gt; Simple feature collection with 49 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;              state_name                       geometry          dist\n#&gt; 1               Alabama MULTIPOLYGON (((-85.4883 30... 1571007.9 [m]\n#&gt; 2               Arizona MULTIPOLYGON (((-110.7507 3...  466602.9 [m]\n#&gt; 3              Arkansas MULTIPOLYGON (((-90.95577 3...  975519.6 [m]\n#&gt; 4            California MULTIPOLYGON (((-116.1062 3... 1000950.5 [m]\n#&gt; 5              Colorado MULTIPOLYGON (((-105.155 36...       0.0 [m]\n#&gt; 6           Connecticut MULTIPOLYGON (((-72.5279 41... 2636635.7 [m]\n#&gt; 7              Delaware MULTIPOLYGON (((-75.13846 3... 2485997.1 [m]\n#&gt; 8  District of Columbia MULTIPOLYGON (((-77.00244 3... 2388920.9 [m]\n#&gt; 9               Florida MULTIPOLYGON (((-83.10874 2... 1847447.4 [m]\n#&gt; 10              Georgia MULTIPOLYGON (((-81.09538 3... 1788781.6 [m]"
  },
  {
    "objectID": "slides/week-2.html#determine-the-3-closest-states-3",
    "href": "slides/week-2.html#determine-the-3-closest-states-3",
    "title": "Week 2",
    "section": "2. Determine the 3 closest states:",
    "text": "2. Determine the 3 closest states:\n\n\n\nconus |&gt;\n  select(state_name) %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0546 ymin: 36.99246 xmax: -95.30829 ymax: 45.00582\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado      0.0 [m] MULTIPOLYGON (((-105.155 36...\n#&gt; 2    Wyoming 140002.6 [m] MULTIPOLYGON (((-106.3212 4...\n#&gt; 3   Nebraska 161243.2 [m] MULTIPOLYGON (((-95.93779 4...\n\n\n\nThat‚Äôs close, but the distance to Colorado is 0, that‚Äôs not a state border."
  },
  {
    "objectID": "slides/week-2.html#geometry-selection",
    "href": "slides/week-2.html#geometry-selection",
    "title": "Week 2",
    "section": "Geometry Selection",
    "text": "Geometry Selection\n\nPolygon (therefore MULTIPOLGYGONS) describe areas!\nThe distance to a point in a polygon to that polygon is 0."
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus\n\n\n\n#&gt; Simple feature collection with 49 features and 14 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_region state_division feature_code           state_name state_abbr\n#&gt; 1             3              6      1779775              Alabama         AL\n#&gt; 2             4              8      1779777              Arizona         AZ\n#&gt; 3             3              7      0068085             Arkansas         AR\n#&gt; 4             4              9      1779778           California         CA\n#&gt; 5             4              8      1779779             Colorado         CO\n#&gt; 6             1              1      1779780          Connecticut         CT\n#&gt; 7             3              5      1779781             Delaware         DE\n#&gt; 8             3              5      1702382 District of Columbia         DC\n#&gt; 9             3              5      0294478              Florida         FL\n#&gt; 10            3              5      1705317              Georgia         GA\n#&gt;                    name fip_class tiger_class combined_area_code\n#&gt; 1               Alabama      &lt;NA&gt;       G4000                 NA\n#&gt; 2               Arizona      &lt;NA&gt;       G4000                 NA\n#&gt; 3              Arkansas      &lt;NA&gt;       G4000                 NA\n#&gt; 4            California      &lt;NA&gt;       G4000                 NA\n#&gt; 5              Colorado      &lt;NA&gt;       G4000                 NA\n#&gt; 6           Connecticut      &lt;NA&gt;       G4000                 NA\n#&gt; 7              Delaware      &lt;NA&gt;       G4000                 NA\n#&gt; 8  District of Columbia      &lt;NA&gt;       G4000                 NA\n#&gt; 9               Florida      &lt;NA&gt;       G4000                 NA\n#&gt; 10              Georgia      &lt;NA&gt;       G4000                 NA\n#&gt;    metropolitan_area_code functional_status    land_area  water_area fip_code\n#&gt; 1                    &lt;NA&gt;                 A 131175477769  4591897964       01\n#&gt; 2                    &lt;NA&gt;                 A 294363973043   855871553       04\n#&gt; 3                    &lt;NA&gt;                 A 134660767709  3121950081       05\n#&gt; 4                    &lt;NA&gt;                 A 403671756816 20293573058       06\n#&gt; 5                    &lt;NA&gt;                 A 268418796417  1185716938       08\n#&gt; 6                    &lt;NA&gt;                 A  12541690473  1816424193       09\n#&gt; 7                    &lt;NA&gt;                 A   5046731559  1399179670       10\n#&gt; 8                    &lt;NA&gt;                 A    158316124    18709762       11\n#&gt; 9                    &lt;NA&gt;                 A 138961722096 45972570361       12\n#&gt; 10                   &lt;NA&gt;                 A 149486624386  4418360134       13\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-85.4883 30...\n#&gt; 2  MULTIPOLYGON (((-110.7507 3...\n#&gt; 3  MULTIPOLYGON (((-90.95577 3...\n#&gt; 4  MULTIPOLYGON (((-116.1062 3...\n#&gt; 5  MULTIPOLYGON (((-105.155 36...\n#&gt; 6  MULTIPOLYGON (((-72.5279 41...\n#&gt; 7  MULTIPOLYGON (((-75.13846 3...\n#&gt; 8  MULTIPOLYGON (((-77.00244 3...\n#&gt; 9  MULTIPOLYGON (((-83.10874 2...\n#&gt; 10 MULTIPOLYGON (((-81.09538 3..."
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-1",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name)\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;              state_name                       geometry\n#&gt; 1               Alabama MULTIPOLYGON (((-85.4883 30...\n#&gt; 2               Arizona MULTIPOLYGON (((-110.7507 3...\n#&gt; 3              Arkansas MULTIPOLYGON (((-90.95577 3...\n#&gt; 4            California MULTIPOLYGON (((-116.1062 3...\n#&gt; 5              Colorado MULTIPOLYGON (((-105.155 36...\n#&gt; 6           Connecticut MULTIPOLYGON (((-72.5279 41...\n#&gt; 7              Delaware MULTIPOLYGON (((-75.13846 3...\n#&gt; 8  District of Columbia MULTIPOLYGON (((-77.00244 3...\n#&gt; 9               Florida MULTIPOLYGON (((-83.10874 2...\n#&gt; 10              Georgia MULTIPOLYGON (((-81.09538 3..."
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-2",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\")\n\n\n\n#&gt; Simple feature collection with 49 features and 1 field\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;              state_name                       geometry\n#&gt; 1               Alabama MULTILINESTRING ((-85.4883 ...\n#&gt; 2               Arizona MULTILINESTRING ((-110.7507...\n#&gt; 3              Arkansas MULTILINESTRING ((-90.95577...\n#&gt; 4            California MULTILINESTRING ((-116.1062...\n#&gt; 5              Colorado MULTILINESTRING ((-105.155 ...\n#&gt; 6           Connecticut MULTILINESTRING ((-72.5279 ...\n#&gt; 7              Delaware MULTILINESTRING ((-75.13846...\n#&gt; 8  District of Columbia MULTILINESTRING ((-77.00244...\n#&gt; 9               Florida MULTILINESTRING ((-83.10874...\n#&gt; 10              Georgia MULTILINESTRING ((-81.09538..."
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-3",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf))\n\n\n\n#&gt; Simple feature collection with 49 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;              state_name                       geometry          dist\n#&gt; 1               Alabama MULTILINESTRING ((-85.4883 ... 1571007.9 [m]\n#&gt; 2               Arizona MULTILINESTRING ((-110.7507...  466602.9 [m]\n#&gt; 3              Arkansas MULTILINESTRING ((-90.95577...  975519.6 [m]\n#&gt; 4            California MULTILINESTRING ((-116.1062... 1000950.5 [m]\n#&gt; 5              Colorado MULTILINESTRING ((-105.155 ...  140002.6 [m]\n#&gt; 6           Connecticut MULTILINESTRING ((-72.5279 ... 2636635.7 [m]\n#&gt; 7              Delaware MULTILINESTRING ((-75.13846... 2485997.1 [m]\n#&gt; 8  District of Columbia MULTILINESTRING ((-77.00244... 2388920.9 [m]\n#&gt; 9               Florida MULTILINESTRING ((-83.10874... 1847447.4 [m]\n#&gt; 10              Georgia MULTILINESTRING ((-81.09538... 1788781.6 [m]"
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-4",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3)\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0546 ymin: 36.99246 xmax: -95.30829 ymax: 45.00582\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 140002.6 [m] MULTILINESTRING ((-105.155 ...\n#&gt; 2    Wyoming 140002.6 [m] MULTILINESTRING ((-106.3212...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-95.93779...\n\n\n\nGood. However, we were only interested in the distance to the closest border not to ALL boarders. Therefore we calculated 48 (49 - 1) more distances then needed!\nWhile this is not to complex for 1 &lt;-&gt; 49 features imagine we had 28,000+ (like your lab)!\nThat would result in 1,344,000 more calculations then needed ‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "href": "slides/week-2.html#to-determine-distance-to-border-we-need-a-linear-representation-5",
    "title": "Week 2",
    "section": "To determine distance to border we need a linear representation:",
    "text": "To determine distance to border we need a linear representation:\n\n\n\nconus |&gt;\n  select(state_name) |&gt;\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  mutate(dist = st_distance(., denver_sf)) |&gt;\n  slice_min(dist, n = 3) -&gt;\n  near3\n\n\n\n\n\n#&gt; Simple feature collection with 3 features and 2 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -111.0569 ymin: 36.99243 xmax: -95.30829 ymax: 45.0059\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   state_name         dist                       geometry\n#&gt; 1   Colorado 139988.4 [m] MULTILINESTRING ((-109.06 3...\n#&gt; 2    Wyoming 139988.4 [m] MULTILINESTRING ((-111.0569...\n#&gt; 3   Nebraska 161243.2 [m] MULTILINESTRING ((-104.0531...\n\n\nGood. However, we were only interested in the distance to the closest border not to ALL boarders. Therefore we calculated 48 (49 - 1) more distances then needed!\nWhile this is not to complex for 1 &lt;-&gt; 49 features imagine we had 28,000+ (like) your lab!\nThat would result in 1,344,000 more calculations then needed ‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#revisting-the-idea-of-the-feature-level",
    "href": "slides/week-2.html#revisting-the-idea-of-the-feature-level",
    "title": "Week 2",
    "section": "Revisting the idea of the feature level:",
    "text": "Revisting the idea of the feature level:\n\nA ‚Äúfeature‚Äù can ‚Äúbe part of the whole‚Äù or the whole\n\nA island (POLYGON), or a set of islands acting as 1 unit (MULTIPOLYGON)\nA city (POINT), or a set of cities meeting a condition (MULTIPOINT)\nA road (LINESTRING), or a route (MULTILINESTRING)\n\nSince we want the distance to the nearest border, regardless of the state. Our feature is the set of borders with preserved boundaries.\nIn other words, a 1 feature MULTILINESTRING\n\n\n\nst_distance(denver_sf, st_cast(st_combine(conus), \"MULTILINESTRING\"))\n#&gt; Units: [m]\n#&gt;          [,1]\n#&gt; [1,] 140002.6\n\n\nThe same principle would apply if the question was ‚Äúdistance to national border‚Äù"
  },
  {
    "objectID": "slides/week-2.html#the-stickness-of-sfc-column",
    "href": "slides/week-2.html#the-stickness-of-sfc-column",
    "title": "Week 2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nGeometry columns are ‚Äústicky‚Äù meaning they persist through data manipulation:\n\n\n\nco |&gt; \n  select(name) |&gt; \n  slice(1:2)\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -106.0393 ymin: 37.3562 xmax: -103.7057 ymax: 40.00137\n#&gt; Geodetic CRS:  WGS 84\n#&gt;      name                       geometry\n#&gt; 1   Adams MULTIPOLYGON (((-105.0532 3...\n#&gt; 2 Alamosa MULTIPOLYGON (((-105.4855 3...\n\n\nDropping the geometry column requires dropping the geometry via sf:\n\n\n\n\nco |&gt; \n  st_drop_geometry() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n#&gt;      name\n#&gt; 1   Adams\n#&gt; 2 Alamosa\n\n\nOr cohersing the sf object to a data.frame:\n\n\n\n\nco |&gt; \n  as.data.frame() |&gt; #&lt;&lt;\n  select(name) |&gt; \n  slice(1:2)\n#&gt;      name\n#&gt; 1   Adams\n#&gt; 2 Alamosa"
  },
  {
    "objectID": "slides/week-2.html#the-stickness-of-sfc-column-1",
    "href": "slides/week-2.html#the-stickness-of-sfc-column-1",
    "title": "Week 2",
    "section": "The stickness of sfc column",
    "text": "The stickness of sfc column\n\nA simple features object (sf) is the connection of a sfc list-column and data.frame of attributes\n\n\n\nThis binding is unique compared to other column bindings built with things like\n\ndplyr::bind_cols()\ncbind()\ndo.call(cbind, list())"
  },
  {
    "objectID": "slides/week-2.html#coordinate-systems",
    "href": "slides/week-2.html#coordinate-systems",
    "title": "Week 2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nWhat makes a feature geometry spatial is the reference system‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#coordinate-systems-1",
    "href": "slides/week-2.html#coordinate-systems-1",
    "title": "Week 2",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\n\nCoordinate Reference Systems (CRS) defines how spatial features relate to the surface of the Earth.\nCRSs are either geographic or projected‚Ä¶\nCRSs are measurement units for coordinates:"
  },
  {
    "objectID": "slides/week-2.html#sf-tools",
    "href": "slides/week-2.html#sf-tools",
    "title": "Week 2",
    "section": "sf tools",
    "text": "sf tools\nIn sf we have three tools for exploring, define, and changing CRS systems:\n\nst_crs : Retrieve coordinate reference system from sf or sfc object\nst_set_crs : Set or replace coordinate reference system from object\nst_transform : Transform or convert coordinates of simple feature\nAgain, ‚Äúst‚Äù (like PostGIS) denotes it is an operation that can work on a ‚Äù s patial t ype‚Äù"
  },
  {
    "objectID": "slides/week-2.html#geographic-coordinate-systms-gcs",
    "href": "slides/week-2.html#geographic-coordinate-systms-gcs",
    "title": "Week 2",
    "section": "Geographic Coordinate Systms (GCS)",
    "text": "Geographic Coordinate Systms (GCS)\n\nA GCS identifies locations on the curved surface of the earth.\nLocations are measured in angular units from the center of the earth relative to the plane defined by the equator and the plane defined by the prime meridian.\nThe vertical angle describes the latitude and the horizontal angle the longitude\nIn most coordinate systems, the North-South and East-West directions are encoded as +/-.\nNorth and East are positive (+) and South and West are negative (-) sign.\nA GCS is defined by 3 components:\n\nan ellipsoid\na geoid\na datum"
  },
  {
    "objectID": "slides/week-2.html#sphere-and-ellipsoid",
    "href": "slides/week-2.html#sphere-and-ellipsoid",
    "title": "Week 2",
    "section": "Sphere and Ellipsoid",
    "text": "Sphere and Ellipsoid\n\nAssuming that the earth is a perfect sphere simplifies calculations and works for small-scale maps (maps that show a large area of the earth).\nBut ‚Ä¶ the earth is not a sphere do to its rotation inducing a centripetal force along the equator.\nThis results in an equatorial axis that is roughly 21 km longer than the polar axis.\nTo account for this, the earth is modeled as an ellipsoid (slighty squished sphere) defined by two radii:\n\nthe semi-major axis (along the equatorial radius)\nthe semi-minor axis (along the polar radius)"
  },
  {
    "objectID": "slides/week-2.html#section-1",
    "href": "slides/week-2.html#section-1",
    "title": "Week 2",
    "section": "",
    "text": "(co_c = st_combine(co_geom))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTIPOLYGON (((-105.0532 39.79106, -104.976 39...\n\n\n\n\n\n\n\n\n\n\n\n(co_u = st_union(co_geom))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; POLYGON ((-105.155 36.99526, -105.1208 36.99543...\n\n\n\n\n\n\n\n\n\n\n\n\n(co_c_ml = st_combine(co_geom) |&gt; \n   st_cast(\"MULTILINESTRING\"))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTILINESTRING ((-105.0532 39.79106, -104.976 ...\n\n\n\n\n\n\n\n\n\n\n\n(co_u_ml = st_union(co_geom)  |&gt; \n    st_cast(\"MULTILINESTRING\"))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTILINESTRING ((-105.155 36.99526, -105.1208 ..."
  },
  {
    "objectID": "slides/week-2.html#geoid",
    "href": "slides/week-2.html#geoid",
    "title": "Week 2",
    "section": "Geoid",
    "text": "Geoid\n\nThe ellipsoid gives us the earths form as a perfectly smooth object\nBut ‚Ä¶ the earth is not perfectly smooth\nDeviations from the perfect sphere are measurable and can influence measurements.\nA geoid is a mathematical model fore representing these deviations\n\nWe are not talking about mountains and ocean trenches but the earth‚Äôs gravitational potential which is tied to the flow of the earth‚Äôs hot and fluid core.\nTherefore the geoid is constantly changing, albeit a large temporal scale.\n\nThe measurement and representation of the earth‚Äôs shape is at the heart of geodesy\n\n\nNASA‚Äôs geoid models"
  },
  {
    "objectID": "slides/week-2.html#datum",
    "href": "slides/week-2.html#datum",
    "title": "Week 2",
    "section": "Datum",
    "text": "Datum\n\nSo how are we to reconcile our need to work with a (simple) mathematical model of the earth‚Äôs shape with the undulating nature of the geoid?\nWe align the geoid with the ellipsoid to map the the earths departures from the smooth assumption\nThe alignment can be local where the ellipsoid surface is closely fit to the geoid at a particular location on the earth‚Äôs surface\n\nor\n\ngeocentric where the ellipsoid is aligned with the center of the earth.\nThe alignment of the smooth ellipsoid to the geoid model defines a datum."
  },
  {
    "objectID": "slides/week-2.html#local-datums",
    "href": "slides/week-2.html#local-datums",
    "title": "Week 2",
    "section": "Local Datums",
    "text": "Local Datums\n\nThere are many local datums to choose from\nThe choice of datum is largely driven by the location\nWhen working in the USA, a the North American Datum of 1927 (or NAD27 for short) is standard\n\nNAD27 is not well suited for other parts of the world."
  },
  {
    "objectID": "slides/week-2.html#section-2",
    "href": "slides/week-2.html#section-2",
    "title": "Week 2",
    "section": "",
    "text": "Thanks to satellite and computational capabilities our estimates of these radii are be quite precise\n\nThe semi-major axis is 6,378,137 m\nThe semi-minor axis is 6,356,752 m\n\nDifferences in distance along the surfaces of an ellipsoid vs.¬†a perfect sphere are small but measurable (the difference can be as high as 20 km)"
  },
  {
    "objectID": "slides/week-2.html#geocentric-datum",
    "href": "slides/week-2.html#geocentric-datum",
    "title": "Week 2",
    "section": "Geocentric Datum",
    "text": "Geocentric Datum\n\nMany modern datums use a geocentric alignment\n\nWorld Geodetic Survey for 1984 (WGS84)\nNorth American Datums of 1983 (NAD83)\n\nMost popular geocentric datums use the WGS84 ellipsoid or the GRS80 ellipsoid which share nearly identical semi-major and semi-minor axes\n\n\n\n\n\n\n\n\n\n\nGeocentric datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1983\nNAD83\nContinental US\nThis is one of the most popular modern datums for the contiguous US.\n\n\nEuropean Terrestrial Reference System 1989\nETRS89\nWestern Europe\nThis is the most popular modern datum for much of Europe.\n\n\nWorld Geodetic System 1984\nWGS84\nGlobal\nDeveloped by the Department of Defense.\n\n\n\n\n\n\n\n\n\nNote\n\n\nNAD 27 is based on Clarke Ellipsoid of 1866 which is calculated by manual surveying. NAD83 is based on the Geodetic Reference System (GRS) of 1980."
  },
  {
    "objectID": "slides/week-2.html#section-3",
    "href": "slides/week-2.html#section-3",
    "title": "Week 2",
    "section": "",
    "text": "Examples of common local datums are shown in the following table:\n\n\n\n\n\n\n\n\n\nLocal datum\nAcronym\nBest for\nComment\n\n\n\n\nNorth American Datum of 1927\nNAD27\nContinental US\nThis is an old datum but still prevalent\n\n\nEuropean Datum of 1950\nED50\nWestern Europe\nDeveloped after World War II and still quite popular\n\n\nWorld Geodetic System 1972\nWGS72\nGlobal\nDeveloped by the Department of Defense."
  },
  {
    "objectID": "slides/week-2.html#building-a-gcs",
    "href": "slides/week-2.html#building-a-gcs",
    "title": "Week 2",
    "section": "Building a GCS",
    "text": "Building a GCS\n\nSo, a GCS is defined by the ellipsoid model and its alignment to the geoid defining the datum.\nSmooth Sphere - Mathmatical Geoid (in angular units)"
  },
  {
    "objectID": "slides/week-2.html#projected-coordinate-systems",
    "href": "slides/week-2.html#projected-coordinate-systems",
    "title": "Week 2",
    "section": "Projected Coordinate Systems",
    "text": "Projected Coordinate Systems\n\nThe surface of the earth is curved but maps (and to data GIS) is flat.\nA projected coordinate system (PCS) is a reference system for identifying locations and measuring features on a flat (2D) surfaces. I\nProjected coordinate systems have an origin, an x axis, a y axis, and a linear unit of measure.\nGoing from a GCS to a PCS requires mathematical transformations.\nThere are three main groups of projection types:\n\nconic\ncylindrical\nplanar"
  },
  {
    "objectID": "slides/week-2.html#projection-types",
    "href": "slides/week-2.html#projection-types",
    "title": "Week 2",
    "section": "Projection Types:",
    "text": "Projection Types:\n\n\nIn all cases, distortion is minimized at the line/point of tangency (denoted by black line/point)\nDistortions are minimized along the tangency lines and increase with the distance from those lines."
  },
  {
    "objectID": "slides/week-2.html#plannar",
    "href": "slides/week-2.html#plannar",
    "title": "Week 2",
    "section": "Plannar",
    "text": "Plannar\n\nA planar projection projects data onto a flat surface touching the globe at a point or along 1 line of tangency.\nTypically used to map polar regions."
  },
  {
    "objectID": "slides/week-2.html#cylindrical",
    "href": "slides/week-2.html#cylindrical",
    "title": "Week 2",
    "section": "Cylindrical",
    "text": "Cylindrical\n\nA cylindrical projection maps the surface onto a cylinder.\nThis projection could also be created by touching the Earth‚Äôs surface along 1 or 2 lines of tangency\nMost often when mapping the entire world."
  },
  {
    "objectID": "slides/week-2.html#conic",
    "href": "slides/week-2.html#conic",
    "title": "Week 2",
    "section": "Conic",
    "text": "Conic\n\nIn a conic projection, the Earth‚Äôs surface is projected onto a cone along 1 or 2 lines of tangency\nTherefore, it is the best suited for maps of mid-latitude areas."
  },
  {
    "objectID": "slides/week-2.html#spatial-properties",
    "href": "slides/week-2.html#spatial-properties",
    "title": "Week 2",
    "section": "Spatial Properties",
    "text": "Spatial Properties\n\nAll projections distort real-world geographic features.\nThink about trying to unpeel an orange while preserving the skin\nThe four spatial properties that are subject to distortion are: shape, area, distance and direction\n\nA map that preserves shape is called conformal;\none that preserves area is called equal-area;\none that preserves distance is called equidistant\none that preserves direction is called azimuthal\nEach map projection can preserve only one or two of the four spatial properties.\nOften, projections are named after the spatial properties they preserve.\n\nWhen working with small-scale (large area) maps and when multiple spatial properties are needed, it is best to break the analyses across projections to minimize errors associated with spatial distortion."
  },
  {
    "objectID": "slides/week-2.html#setting-crsspcss",
    "href": "slides/week-2.html#setting-crsspcss",
    "title": "Week 2",
    "section": "Setting CRSs/PCSs",
    "text": "Setting CRSs/PCSs\n\nWe saw that sfc objects have two attributes to store a CRS: epsg and proj4string\n\n\n\nst_geometry(conus)\n#&gt; Geometry set for 49 features \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 5 geometries:\n#&gt; MULTIPOLYGON (((-85.4883 30.99706, -85.36962 30...\n#&gt; MULTIPOLYGON (((-110.7507 37.00301, -110.8054 3...\n#&gt; MULTIPOLYGON (((-90.95577 34.11871, -90.9569 34...\n#&gt; MULTIPOLYGON (((-116.1062 32.61848, -116.0123 3...\n#&gt; MULTIPOLYGON (((-105.155 36.99526, -105.1208 36...\n\n\nThis implies that all geometries in a geometry list-column (sfc) must have the same CRS.\nproj4string is a generic, string-based description of a CRS, understood by PROJ\nIt defines projection types and parameter values for particular projections,\nAs a result it can cover an infinite amount of different projections.\nepsg is the integer ID for a known CRS that can be resolved into a proj4string.\n\nThis is somewhat equivalent to the idea that a 6-digit FIP code can be resolved to a state/county pair\n\nSome proj4string values can resolved back into their corresponding epsg ID, but this does not always work.\nThe importance of having epsg values stored with data besides proj4string values is that the epsg refers to particular, well-known CRS, whose parameters may change (improve) over time\nfixing only the proj4string may remove the possibility to benefit from such improvements, and limit some of the provenance of datasets (but may help reproducibility)"
  },
  {
    "objectID": "slides/week-2.html#proj4-coordinate-syntax",
    "href": "slides/week-2.html#proj4-coordinate-syntax",
    "title": "Week 2",
    "section": "PROJ4 coordinate syntax",
    "text": "PROJ4 coordinate syntax\nThe PROJ4 syntax contains a list of parameters, each prefixed with the + character.\nA list of some PROJ4 parameters follows and the full list can be found here:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\n+a\nSemi-major radius of the ellipsoid axis\n\n\n+b\nSemi-minor radius of the ellipsoid axis\n\n\n+datum\nDatum name\n\n\n+ellps\nEllipsoid name\n\n\n+lat_0\nLatitude of origin\n\n\n+lat_1\nLatitude of first standard parallel\n\n\n+lat_2\nLatitude of second standard parallel\n\n\n+lat_ts\nLatitude of true scale\n\n\n+lon_0\nCentral meridian\n\n\n+over\nAllow longitude output outside -180 to 180 range, disables wrapping\n\n\n+proj\nProjection name\n\n\n+south\nDenotes southern hemisphere UTM zone\n\n\n+units\nmeters, US survey feet, etc.\n\n\n+x_0\nFalse easting\n\n\n+y_0\nFalse northing\n\n\n+zone\nUTM zone"
  },
  {
    "objectID": "slides/week-2.html#section-4",
    "href": "slides/week-2.html#section-4",
    "title": "Week 2",
    "section": "",
    "text": "the geodesic distance looks weird given its curved appearance on the projected map.\nthis curvature is a byproduct of the current reference system‚Äôs increasing distance distortion as one moves towards the pole!\nWe can display the geodesic and planar distance on a 3D globe (or a projection that mimics the view of the 3D earth)."
  },
  {
    "objectID": "slides/week-2.html#transform-and-retrive",
    "href": "slides/week-2.html#transform-and-retrive",
    "title": "Week 2",
    "section": "Transform and retrive",
    "text": "Transform and retrive\n\n\n\nst_crs(conus)$epsg\n#&gt; [1] 4326\nst_crs(conus)$proj4string\n#&gt; [1] \"+proj=longlat +datum=WGS84 +no_defs\"\nst_crs(conus)$datum\n#&gt; [1] \"WGS84\"\n\n\n\nconus5070 &lt;- st_transform(conus, 5070)\n\nst_crs(conus5070)$epsg\n#&gt; [1] 5070\nst_crs(conus5070)$proj4string\n#&gt; [1] \"+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\"\nst_crs(conus5070)$datum\n#&gt; [1] \"NAD83\""
  },
  {
    "objectID": "slides/week-2.html#revisit-denver",
    "href": "slides/week-2.html#revisit-denver",
    "title": "Week 2",
    "section": "Revisit Denver",
    "text": "Revisit Denver\n\necho -104.9903 39.7392 | proj +proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs\n#&gt; -723281.88   6827.29\n\n\nred = false origin : blue = Denver"
  },
  {
    "objectID": "slides/week-2.html#geodesic-geometries",
    "href": "slides/week-2.html#geodesic-geometries",
    "title": "Week 2",
    "section": "Geodesic geometries",
    "text": "Geodesic geometries\n\nPCSs introduce errors in their geometric measurements because the distance between two points on an ellipsoid is difficult to replicate on a projected coordinate system unless these points are close to one another.\nIn most cases, such errors other sources of error in the feature representation outweigh measurement errors made in a PCS making them tolorable.\nHowever, if the domain of analysis is large (i.e.¬†the North American continent), then the measurement errors associated with a projected coordinate system may no longer be acceptable.\nA way to circumvent projected coordinate system limitations is to adopt a geodesic solution."
  },
  {
    "objectID": "slides/week-2.html#geodesic-measurments",
    "href": "slides/week-2.html#geodesic-measurments",
    "title": "Week 2",
    "section": "Geodesic Measurments",
    "text": "Geodesic Measurments\n\nA geodesic distance is the shortest distance between two points on an ellipsoid\nA geodesic area measurement is one that is measured on an ellipsoid.\nSuch measurements are independent of the underlying projected coordinate system.\nWhy does this matter?\nCompare the distances measured between Santa Barbara and Amsterdam. The blue line represents the shortest distance between the two points on a planar coordinate system. The red line as measured on a ellipsoid."
  },
  {
    "objectID": "slides/week-2.html#section-5",
    "href": "slides/week-2.html#section-5",
    "title": "Week 2",
    "section": "",
    "text": "So if a geodesic measurement is more precise than a planar measurement, why not perform all spatial operations using geodesic geometry?\nThe downside is in its computational requirements.\nIt‚Äôs far more efficient to compute area/distance on a plane than it is on a spheroid.\nThis is because geodesic calculations have no simple algebraic solutions and involve approximations that may require iteration! (think optimization or nonlinear solutions)\nSo this may be a computationally taxing approach if processing 1,000(s) or 1,000,000(s) of line segments."
  },
  {
    "objectID": "slides/week-2.html#section-6",
    "href": "slides/week-2.html#section-6",
    "title": "Week 2",
    "section": "",
    "text": "We can set units if we do manipulations as well using the units package\n\nunits::set_units(l, \"km\")\n#&gt; 100093.1 [km]\nunits::set_units(l, \"mile\")\n#&gt; 62194.96 [mile]\n\nunits::set_units(a, \"ha\")\n#&gt; 809649680 [ha]\nunits::set_units(a, \"km2\")\n#&gt; 8096497 [km^2]\nunits::set_units(a, \"in2\")\n#&gt; 1.25496e+16 [in^2]"
  },
  {
    "objectID": "slides/week-2.html#gedesic-area-and-length-measurements",
    "href": "slides/week-2.html#gedesic-area-and-length-measurements",
    "title": "Week 2",
    "section": "Gedesic Area and Length Measurements",
    "text": "Gedesic Area and Length Measurements\n\nNot all algorthimns are equal (in terms of speed or accuracy)\nSome more efficient algorithms that minimize computation time may reduce precision in the process.\nSome of ArcMap‚Äôs functions offer the option to compute geodesic distances and areas however ArcMap does not clearly indicate how its geodesic calculations are implemented (cite)\nR is well documented, and is efficient!"
  },
  {
    "objectID": "slides/week-2.html#distances",
    "href": "slides/week-2.html#distances",
    "title": "Week 2",
    "section": "Distances",
    "text": "Distances\n?st_distance"
  },
  {
    "objectID": "slides/week-2.html#native-sf-binds-to-libwgeom",
    "href": "slides/week-2.html#native-sf-binds-to-libwgeom",
    "title": "Week 2",
    "section": "native sf binds to libwgeom",
    "text": "native sf binds to libwgeom"
  },
  {
    "objectID": "slides/week-2.html#distance-example",
    "href": "slides/week-2.html#distance-example",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB"
  },
  {
    "objectID": "slides/week-2.html#distance-example-1",
    "href": "slides/week-2.html#distance-example-1",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week-2.html#distance-example-2",
    "href": "slides/week-2.html#distance-example-2",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)"
  },
  {
    "objectID": "slides/week-2.html#distance-example-3",
    "href": "slides/week-2.html#distance-example-3",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0"
  },
  {
    "objectID": "slides/week-2.html#distance-example-4",
    "href": "slides/week-2.html#distance-example-4",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000"
  },
  {
    "objectID": "slides/week-2.html#distance-example-5",
    "href": "slides/week-2.html#distance-example-5",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0"
  },
  {
    "objectID": "slides/week-2.html#distance-example-6",
    "href": "slides/week-2.html#distance-example-6",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 3823549\n#&gt; 2 3823549       0"
  },
  {
    "objectID": "slides/week-2.html#distance-example-7",
    "href": "slides/week-2.html#distance-example-7",
    "title": "Week 2",
    "section": "Distance Example",
    "text": "Distance Example\n\n\n\n(pts = data.frame(y = c(40.7128, 34.4208),\n                  x = c(-74.0060, -119.6982 ),\n                  name = c(\"NYC\",\"SB\")))\n\n(pts = st_as_sf(pts, coords = c(\"x\", \"y\"),\n                crs = 4326))\n\neqds = '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n# Greeat Circle Distance\nst_distance(pts)\n\n# Euclidean Distance\nst_distance(pts, which = \"Euclidean\")\n\n# Equal Area PCS\nst_distance(st_transform(pts, 5070))\n\n# Equal Distance\nst_distance(st_transform(pts, eqds))\n\n\n\n#&gt;         y         x name\n#&gt; 1 40.7128  -74.0060  NYC\n#&gt; 2 34.4208 -119.6982   SB\n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -119.6982 ymin: 34.4208 xmax: -74.006 ymax: 40.7128\n#&gt; Geodetic CRS:  WGS 84\n#&gt;   name                  geometry\n#&gt; 1  NYC   POINT (-74.006 40.7128)\n#&gt; 2   SB POINT (-119.6982 34.4208)\n#&gt; Units: [m]\n#&gt;         [,1]    [,2]\n#&gt; [1,]       0 4050406\n#&gt; [2,] 4050406       0\n#&gt; Units: [¬∞]\n#&gt;          1        2\n#&gt; 1  0.00000 46.12338\n#&gt; 2 46.12338  0.00000\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 4017987\n#&gt; 2 4017987       0\n#&gt; Units: [m]\n#&gt;         1       2\n#&gt; 1       0 3823549\n#&gt; 2 3823549       0"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus",
    "href": "slides/week-2.html#area-example-conus",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus-1",
    "href": "slides/week-2.html#area-example-conus-1",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus-2",
    "href": "slides/week-2.html#area-example-conus-2",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df)"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus-3",
    "href": "slides/week-2.html#area-example-conus-3",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) ))"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus-4",
    "href": "slides/week-2.html#area-example-conus-4",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-2.html#area-example-conus-5",
    "href": "slides/week-2.html#area-example-conus-5",
    "title": "Week 2",
    "section": "Area Example: CONUS",
    "text": "Area Example: CONUS\n\n\n\nus_u_mp = st_cast(us_u_ml, \"MULTIPOLYGON\")\n\ndf = data.frame(name = c(\"WGS84\", \"AEA\", \"EPDS\"),\n           area = c(sum(st_area(conus)),\n            sum(st_area(st_transform(conus, 5070))),\n            sum(st_area(st_transform(conus, eqds)))))\n\nggplot(df) +\n  geom_col(aes(x = name, y = as.numeric(area) )) +\n  theme_linedraw() +\n  labs(x = \"SRS\", y = \"m2\")"
  },
  {
    "objectID": "slides/week-2.html#units-in-sf",
    "href": "slides/week-2.html#units-in-sf",
    "title": "Week 2",
    "section": "Units in sf",
    "text": "Units in sf\n\nThe CRS in sf encodes the units of measurement relating to spatial features\nWhere possible geometric operations such as st_distance(), st_length() and st_area() report results with a units attribute appropriate for the CRS:\nThis can be both handy and very confusing for those new to it. Consider the following:\n\n\n(l = sum(st_length(conus)))\n#&gt; 100093081 [m]\n(a = sum(st_area(conus)))\n#&gt; 8.096497e+12 [m^2]"
  },
  {
    "objectID": "slides/week-2.html#section-7",
    "href": "slides/week-2.html#section-7",
    "title": "Week 2",
    "section": "",
    "text": "We can set units if we do manipulations as well using the units package\n\nunits::set_units(l, \"km\")\n#&gt; 94980.15 [km]\nunits::set_units(l, \"mile\")\n#&gt; 59017.93 [mile]\n\nunits::set_units(a, \"ha\")\n#&gt; 783760974 [ha]\nunits::set_units(a, \"km2\")\n#&gt; 7837610 [km^2]\nunits::set_units(a, \"in2\")\n#&gt; 1.214832e+16 [in^2]"
  },
  {
    "objectID": "slides/week-2.html#units-are-a-class",
    "href": "slides/week-2.html#units-are-a-class",
    "title": "Week 2",
    "section": "Units are a class",
    "text": "Units are a class\n\nunits are an S3 data object with attribute information and ‚Äúrules of engagement‚Äù\n\n\nclass(st_length(conus)) \n#&gt; [1] \"units\"\nattributes(st_length(conus)) |&gt; unlist()\n#&gt; units.numerator           class \n#&gt;             \"m\"         \"units\"\n\nst_length(conus) + 100\n#&gt; Error in Ops.units(st_length(conus), 100): both operands of the expression should be \"units\" objects\n\nconus |&gt; \n  mutate(area = st_area(.)) |&gt; \n  ggplot(aes(x = name, y = area)) + \n  geom_col()\n#&gt; Error in `stopifnot()`:\n#&gt; ‚Ñπ In argument: `area = st_area(.)`.\n#&gt; Caused by error:\n#&gt; ! object '.' not found"
  },
  {
    "objectID": "slides/week-2.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "href": "slides/week-2.html#unit-values-can-be-stripped-of-their-attributes-if-need-be",
    "title": "Week 2",
    "section": "Unit values can be stripped of their attributes if need be:",
    "text": "Unit values can be stripped of their attributes if need be:\n\n# Via drop_units\n(units::drop_units(sum(st_length(conus))))\n#&gt; [1] 100093081\n\n# Via casting\n(as.numeric(sum(st_length(conus))))\n#&gt; [1] 100093081"
  },
  {
    "objectID": "slides/Untitled.html#these-tools-are-all-functions",
    "href": "slides/Untitled.html#these-tools-are-all-functions",
    "title": "Week 3",
    "section": "These tools are all functions",
    "text": "These tools are all functions\n\nR is a statistical computing language that provides features as functions\nEven with just its base installation, R provides hundreds of functions:\n\n\nlength(lsf.str(\"package:base\")) + length(lsf.str(\"package:stats\")) + length(lsf.str(\"package:utils\"))\n#&gt; [1] 1947\n\n\nsf provides over 100 more\n\n\nlength(lsf.str(\"package:sf\")) \n#&gt; [1] 149\n\n\nand the core tidyverse packages (that we use) an additional ~750\n\n\nlength(lsf.str(\"package:dplyr\")) +\nlength(lsf.str(\"package:ggplot2\")) +\nlength(lsf.str(\"package:tidyr\")) +\nlength(lsf.str(\"package:forcats\")) +\nlength(lsf.str(\"package:purrr\")) \n#&gt; [1] 1025"
  },
  {
    "objectID": "slides/Untitled.html#to-date",
    "href": "slides/Untitled.html#to-date",
    "title": "Week 3",
    "section": "To date ‚Ä¶",
    "text": "To date ‚Ä¶\n\nWe have been using functions written for us - mostly by sf and the tidyverse\nThis how any commercial GIS suite operates as well\nAnalysis and workflows are limited to the tools kits and options exposed to the user\nIn R, a lot more is actually exposed!\nEverytime we install a new package, we download code that provides new specific features (as functions)\nEverytime we attach a package to a working session (library()) we are making those functions available/visible"
  },
  {
    "objectID": "slides/Untitled.html#functions-are-objects",
    "href": "slides/Untitled.html#functions-are-objects",
    "title": "Week 3",
    "section": "Functions are objects",
    "text": "Functions are objects\n\nJust like x = 10 binds the value of 10 to the name x creating an object visible in the environment,\nfunctions are objects that can be called by name to execute a set of directions over defined arguments.\n\n\nclass(sf::st_intersects)\n#&gt; [1] \"function\"\nclass(sf::st_as_sf)\n#&gt; [1] \"function\""
  },
  {
    "objectID": "slides/Untitled.html#our-own-functions-are-visable-as-objects-in-the-environemnt",
    "href": "slides/Untitled.html#our-own-functions-are-visable-as-objects-in-the-environemnt",
    "title": "Week 3",
    "section": "Our own functions are visable as objects in the environemnt",
    "text": "Our own functions are visable as objects in the environemnt\n\nx = 10\ny = data.frame(x = 1:10, y = 10:1)\nf = function(x,y){ x  + y }"
  },
  {
    "objectID": "slides/Untitled.html#advancing-your-programming-skills",
    "href": "slides/Untitled.html#advancing-your-programming-skills",
    "title": "Week 3",
    "section": "Advancing your programming skills",
    "text": "Advancing your programming skills\n\nOne of the best ways to improve your skills as a data scientist is to write functions.\nFunctions allow you to automate common tasks in a more general way than copy-and-pasting.\nThe more times you apply a function, the more incentive you have to optimize it for speed/accuracy\nThe more creative/unique your analyses and questions can be"
  },
  {
    "objectID": "slides/Untitled.html#the-form-of-a-function",
    "href": "slides/Untitled.html#the-form-of-a-function",
    "title": "Week 3",
    "section": "The form of a function:",
    "text": "The form of a function:\nCreating a function follows the form:\n\nname = function(arg1, arg2, *){\n  code\n  ..\n  return(...)\n}\n\nWhere:\n\nname is the function name (e.g.¬†st_as_sf)\n\nThis is the name on which R is able to call the object\n\narg1 is the first input\narg2 is the second input\n* is any other argument you want to define\ncode ... defines the instructions to carry out on arg1 and arg2\nreturn(...) is what the function returns"
  },
  {
    "objectID": "slides/Untitled.html#defining-a-function",
    "href": "slides/Untitled.html#defining-a-function",
    "title": "Week 3",
    "section": "Defining a function",
    "text": "Defining a function\n\nTo define a function we need to identify the code we have, and what can/should generalized for future uses?\n\n\nstates = USAboundaries::us_states() %&gt;% \n  filter(!name %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n\n\nHere the input data (us_states) could change\nSo could the variable name we filter by (name)"
  },
  {
    "objectID": "slides/Untitled.html#function-signiture",
    "href": "slides/Untitled.html#function-signiture",
    "title": "Week 3",
    "section": "Function Signiture",
    "text": "Function Signiture\nSo, lets start with a function that takes general input data and a variable name\n\nget_conus = function(data, var){\n\n}"
  },
  {
    "objectID": "slides/Untitled.html#function-arguments",
    "href": "slides/Untitled.html#function-arguments",
    "title": "Week 3",
    "section": "Function arguments",
    "text": "Function arguments\nFunction arguments typically include two two broad sets: - the data to compute on, - arguments that control the details of the calculation\n\nIn st_transform x is the data, crs is the proj4string/EPSG code\nIn ms_simplify input is the data, keep defines the directions\nIn get_conus: data provides the data, var defines the column to filter"
  },
  {
    "objectID": "slides/Untitled.html#section",
    "href": "slides/Untitled.html#section",
    "title": "Week 3",
    "section": "",
    "text": "Generally, data arguments should come first.\nDetail arguments should go on the end\nIt can be useful - and good practice - to define default values.\n\nshould almost always be the most common value.\nThe exceptions to this rule are to do with safety of the process.\n\ne.g.¬†na.rm = FALSE"
  },
  {
    "objectID": "slides/Untitled.html#code-body",
    "href": "slides/Untitled.html#code-body",
    "title": "Week 3",
    "section": "Code body",
    "text": "Code body\nWe then have to carry these generalizations into the function directions using the arguments as our operators:\n\nget_conus = function(data, var){\n  conus = filter(data, !!var %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n  return(conus)\n}\n\n\nhere, we replace us_states() with data\nwe use get() to return the value of a named object\nWe assign our filtered object to the name conus\nAnd explicitly return the conus object from the function\nThe value returned by the function is usually the last evaluated statement, if we don‚Äôt specify return we can take advantage of this default:\n\n\nget_conus = function(data, var){\n  filter(data, !get(var) %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n}"
  },
  {
    "objectID": "slides/Untitled.html#cities",
    "href": "slides/Untitled.html#cities",
    "title": "Week 3",
    "section": "Cities",
    "text": "Cities\n\ncities = read_csv(\"../labs/data/uscities.csv\") %&gt;%\n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) %&gt;% \n  get_conus(\"state_name\")\n\nplot(cities$geometry, pch = 16, cex = .1)"
  },
  {
    "objectID": "slides/Untitled.html#its-ok-to-be-more-detailed",
    "href": "slides/Untitled.html#its-ok-to-be-more-detailed",
    "title": "Week 3",
    "section": "It‚Äôs ok to be more detailed",
    "text": "It‚Äôs ok to be more detailed\n\nAnother advantage of functions is that if our requirements change, we only need to make the change our code in one place.\nThis also means we can spend more time fine-tuning our code since we know it will be recycled.\nHere we can be more focused and make sure to remove other potential ‚Äúnon-conus‚Äù states from any input object:\n\n\nget_conus = function(data, var){\n  filter(data, !get(var) %in% \n           c(\"Hawaii\", \"Puerto Rico\", \"Alaska\",\n             \"Guam\", \"District of Columbia\"))\n}"
  },
  {
    "objectID": "slides/Untitled.html#using-our-function-1",
    "href": "slides/Untitled.html#using-our-function-1",
    "title": "Week 3",
    "section": "Using our function",
    "text": "Using our function\n\nconus = get_conus(us_states(), \"name\")\nnrow(conus)\n#&gt; [1] 48"
  },
  {
    "objectID": "slides/Untitled.html#point-in-polygon-case-study",
    "href": "slides/Untitled.html#point-in-polygon-case-study",
    "title": "Week 3",
    "section": "Point-in-Polygon Case Study",
    "text": "Point-in-Polygon Case Study\n\nThe power of GIS lies in analyzing multiple data sources together.\nOften the answer you want lies in many different layers and you need to do some analysis to extract and compile information.\nOne common analysis is Points-in-Polygon (PIP).\nPIP is useful when you want to know how many - or what kind of - points fall within the bounds of each polygon"
  },
  {
    "objectID": "slides/Untitled.html#data",
    "href": "slides/Untitled.html#data",
    "title": "Week 3",
    "section": "Data",
    "text": "Data\nCONUS counties\n\ncounties = st_transform(us_counties()[,-9], 5070) %&gt;% \n  select(name, geoid, state_name) %&gt;% \n  get_conus(\"state_name\")\n\nCONUS Starbucks\n\nstarbucks = read_csv('data/directory.csv') %&gt;% \n  filter(!is.na(Latitude), Country == \"US\") %&gt;% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %&gt;% \n  st_transform(5070) %&gt;% \n  st_filter(counties) %&gt;% \n  select(store_name = `Store Name`)\n\nColorado Counties\n\nco = filter(counties, state_name == \"Colorado\")"
  },
  {
    "objectID": "slides/Untitled.html#step-1-spatial-join",
    "href": "slides/Untitled.html#step-1-spatial-join",
    "title": "Week 3",
    "section": "Step 1: Spatial Join",
    "text": "Step 1: Spatial Join\nTo count the Starbucks locations in CA counties, we start by joining the CA counties to the locations:\n\nHere we uses the counties as the x table and the locations as the y table\nThis is because we want to add the starbucks information to the county sf object.\nRemember the default of st_join is a left_join on the st_intersects predicate\n\n\n(starbucks1 = st_join(co, starbucks))\n#&gt; Simple feature collection with 511 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1146480 ymin: 1566911 xmax: -504612.5 ymax: 2073715\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; First 10 features:\n#&gt;         name geoid state_name                        store_name\n#&gt; 1       Yuma 08125   Colorado                              &lt;NA&gt;\n#&gt; 2   San Juan 08111   Colorado                              &lt;NA&gt;\n#&gt; 3       Baca 08009   Colorado                              &lt;NA&gt;\n#&gt; 4    Prowers 08099   Colorado                              &lt;NA&gt;\n#&gt; 5     Custer 08027   Colorado                              &lt;NA&gt;\n#&gt; 6    Fremont 08043   Colorado     City Market - Canon City #417\n#&gt; 7       Mesa 08077   Colorado    I-70 Business Loop & 32 Rd - C\n#&gt; 7.1     Mesa 08077   Colorado    Hwy 6 & 25 Rd - Grand Junction\n#&gt; 7.2     Mesa 08077   Colorado   City Market-Grand Junction #444\n#&gt; 7.3     Mesa 08077   Colorado City Market - Grand Junction #432\n#&gt;                           geometry\n#&gt; 1   MULTIPOLYGON (((-575240.5 1...\n#&gt; 2   MULTIPOLYGON (((-1042591 16...\n#&gt; 3   MULTIPOLYGON (((-617878.8 1...\n#&gt; 4   MULTIPOLYGON (((-587200.4 1...\n#&gt; 5   MULTIPOLYGON (((-847581.3 1...\n#&gt; 6   MULTIPOLYGON (((-863875.9 1...\n#&gt; 7   MULTIPOLYGON (((-1114392 18...\n#&gt; 7.1 MULTIPOLYGON (((-1114392 18...\n#&gt; 7.2 MULTIPOLYGON (((-1114392 18...\n#&gt; 7.3 MULTIPOLYGON (((-1114392 18..."
  },
  {
    "objectID": "slides/Untitled.html#step-2-point-counts-by-polygon",
    "href": "slides/Untitled.html#step-2-point-counts-by-polygon",
    "title": "Week 3",
    "section": "Step 2: Point counts by Polygon",
    "text": "Step 2: Point counts by Polygon\ncount() is a dplyr function that ‚Äúlets you quickly count the unique values of one or more variables: df %&gt;% count(a, b) is roughly equivalent to df %&gt;% group_by(a, b) %&gt;% summarise(n = n())‚Äù\n\n(count(starbucks1, geoid))\n#&gt; Simple feature collection with 64 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1146480 ymin: 1566911 xmax: -504612.5 ymax: 2073715\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; First 10 features:\n#&gt;    geoid  n                       geometry\n#&gt; 1  08001 35 MULTIPOLYGON (((-765835.6 1...\n#&gt; 2  08003  1 MULTIPOLYGON (((-878691.4 1...\n#&gt; 3  08005 58 MULTIPOLYGON (((-769015.2 1...\n#&gt; 4  08007  1 MULTIPOLYGON (((-1004101 16...\n#&gt; 5  08009  1 MULTIPOLYGON (((-617878.8 1...\n#&gt; 6  08011  1 MULTIPOLYGON (((-640691.8 1...\n#&gt; 7  08013 36 MULTIPOLYGON (((-819541.3 1...\n#&gt; 8  08014  9 MULTIPOLYGON (((-775389.1 1...\n#&gt; 9  08015  1 MULTIPOLYGON (((-905015.4 1...\n#&gt; 10 08017  1 MULTIPOLYGON (((-616732 176..."
  },
  {
    "objectID": "slides/Untitled.html#step-3-combine-the-processes",
    "href": "slides/Untitled.html#step-3-combine-the-processes",
    "title": "Week 3",
    "section": "Step 3: Combine the processes ‚Ä¶",
    "text": "Step 3: Combine the processes ‚Ä¶\n\nstarbucks1 = st_join(co, starbucks) %&gt;% \n   count(geoid)\n\nplot(starbucks1['n'])"
  },
  {
    "objectID": "slides/Untitled.html#now-for-colorado",
    "href": "slides/Untitled.html#now-for-colorado",
    "title": "Week 3",
    "section": "Now for Colorado?",
    "text": "Now for Colorado?\nWe can anticipate that PIP is a useful process we want to implement over variable points and polygons pairs\nSo, lets make a function named point_in_polygon, that takes a point dataset and a polygon dataset\n\npoint_in_polygon = function(points, polygon){\n st_join(polygon, points) %&gt;% \n   count(geoid)\n}"
  },
  {
    "objectID": "slides/Untitled.html#generalizing-the-count-variable",
    "href": "slides/Untitled.html#generalizing-the-count-variable",
    "title": "Week 3",
    "section": "Generalizing the count variable",
    "text": "Generalizing the count variable\n\nIn its current form, point_in_polygon only counts on geoid\nLets modify that by making the variable name an input\n\nagain, we use get() to return the value of a named object\nwe call this, variable id\n\n\n\npoint_in_polygon2 = function(points, polygon, var){\n  st_join(polygon, points) %&gt;% \n    count(get(var))\n}"
  },
  {
    "objectID": "slides/Untitled.html#optimizing-functions",
    "href": "slides/Untitled.html#optimizing-functions",
    "title": "Week 3",
    "section": "Optimizing functions",
    "text": "Optimizing functions\n\nLets apply our function over the counties and see how long it takes\nWe can check the time it takes by wrapping our function in system.time\n\n\nsystem.time({\n  us = point_in_polygon(starbucks, counties)\n})\n\n# user    system  elapsed \n# 3.719   0.354   4.309"
  },
  {
    "objectID": "slides/Untitled.html#to-keep-geometery-or-not",
    "href": "slides/Untitled.html#to-keep-geometery-or-not",
    "title": "Week 3",
    "section": "To keep geometery or not?",
    "text": "To keep geometery or not?\n\nRemember our geometries are sticky, that means they carry through all calculations - whether they are needed or not\nWe can ease alot of computational overhead by being mindfull of when we retain our geometry data with our attribute data.\n\n\n\n\nsystem.time({\n  st_join(counties, starbucks) %&gt;% \n    count(geoid) \n})\n\n#user    system  elapsed \n#3.970   0.421   5.521\n\n\n\nsystem.time({\n  st_join(counties, starbucks) %&gt;% \n    st_drop_geometry() %&gt;% \n    count(geoid) %&gt;% \n    left_join(counties, by = 'geoid') %&gt;% \n    st_as_sf() \n})\n\n# user    system  elapsed \n# 0.396   0.017   0.598"
  },
  {
    "objectID": "slides/Untitled.html#section-1",
    "href": "slides/Untitled.html#section-1",
    "title": "Week 3",
    "section": "",
    "text": "# How many seconds per point?\n# How many seconds per point?\n(point_per_sec = .598 / (nrow(counties) * nrow(starbucks)))\n#&gt; [1] 1.442037e-08\n\n# How will this scale to our dams data\n# (assuming the process is linear)\n\npoint_per_sec * (nrow(counties) * 91000)\n#&gt; [1] 4.077171\n\nAwesome!\nEffectivly a 86% decrease in time needed ((29-4) / 29)\n‚ÄúFunction-izing‚Äù our improvements\n\npoint_in_polygon3 = function(points, polygon, var){\n  st_join(polygon, points) %&gt;% \n    st_drop_geometry() %&gt;% \n    count(get(var)) %&gt;% \n    setNames(c(var, \"n\")) %&gt;% #&lt;&lt; \n    left_join(polygon, by = var) %&gt;% \n    st_as_sf() \n}"
  },
  {
    "objectID": "slides/Untitled.html#what-else-can-we-wrap",
    "href": "slides/Untitled.html#what-else-can-we-wrap",
    "title": "Week 3",
    "section": "What else can we wrap?",
    "text": "What else can we wrap?\n\nWhat about a really nice, clean, informative plot?\nggplots look great but can be time consuming to program‚Ä¶\nA function would allow us to take care of the groundwork\n\n\nplot_pip = function(data){\n  ggplot() + \n    geom_sf(data = data, aes(fill = log(n)), alpha = .9, size = .2) + \n    scale_fill_gradient(low = \"white\", high = \"darkgreen\") + \n    theme_void() + \n    theme(legend.position = 'none',\n          plot.title = element_text(face = \"bold\", color = \"darkgreen\", hjust = .5, size = 24)) +\n    labs(title = \"Starbucks Locations\",\n         caption = paste0(sum(data$n), \" locations represented\")) \n}\n\n\nThis is great because we can devote the time to making a nice plot and we will be able to recycle the work over other cases‚Ä¶"
  },
  {
    "objectID": "slides/Untitled.html#test-1",
    "href": "slides/Untitled.html#test-1",
    "title": "Week 3",
    "section": "Test",
    "text": "Test\n\n\n\npoint_in_polygon3(starbucks, filter(counties, state_name == \"California\"), \"geoid\") %&gt;% \nplot_pip()\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, filter(counties, state_name == \"New York\"), \"geoid\") %&gt;% \nplot_pip()\n\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, counties, \"geoid\") %&gt;% \n  plot_pip()\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, states, var = \"name\") %&gt;% \n  plot_pip()"
  },
  {
    "objectID": "slides/Untitled.html#section-2",
    "href": "slides/Untitled.html#section-2",
    "title": "Week 3",
    "section": "",
    "text": "sf::sf_use_s2(FALSE)\ncountries = st_as_sf(rnaturalearth::countries110)\n\nurl = '/Users/mikejohnson/Downloads/earthquakes-2025-03-29_21-55-22_-0600.tsv'\n\nquakes  = read_delim(url, delim = \"\\t\") %&gt;% \n  filter(!is.na(Latitude), !is.na(Longitude)) %&gt;% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %&gt;%     \n  st_transform(st_crs(countries))\n\nnrow(countries)\n#&gt; [1] 177\nnrow(quakes)\n#&gt; [1] 6443\nnrow(st_intersection(quakes, countries))\n#&gt; [1] 4317"
  },
  {
    "objectID": "slides/Untitled.html#moving-beyond-starbucks",
    "href": "slides/Untitled.html#moving-beyond-starbucks",
    "title": "Week 3",
    "section": "Moving beyond Starbucks?",
    "text": "Moving beyond Starbucks?\n\nHere is a nice tutorial of point-in-polygon in QGIS. It is looking at earthquakes by country.\nJust like us they use naturalearth data for the polygon areas\nAnd they are looking at earthquake data maintained by NOAA.\nIn R, we can read the NOAA data directly from a URL.\nThe data is a tab delimited txt file so we use readr::read_delim()"
  },
  {
    "objectID": "slides/Untitled.html#tools-for-reading-and-writing-data",
    "href": "slides/Untitled.html#tools-for-reading-and-writing-data",
    "title": "Week 3",
    "section": "tools for reading and writing data:",
    "text": "tools for reading and writing data:\n\nread_sf / write_sf\nread_csv / write_csv\nread_excel"
  },
  {
    "objectID": "slides/Untitled.html#tools-for-data-maniputation",
    "href": "slides/Untitled.html#tools-for-data-maniputation",
    "title": "Week 3",
    "section": "tools for data maniputation",
    "text": "tools for data maniputation\n\nfilter\nselect\nmutate\ngroup_by\nsummarize\nrollmean, lag"
  },
  {
    "objectID": "slides/Untitled.html#tools-to-managemanipulate-data-typestructure",
    "href": "slides/Untitled.html#tools-to-managemanipulate-data-typestructure",
    "title": "Week 3",
    "section": "tools to manage/manipulate data type/structure",
    "text": "tools to manage/manipulate data type/structure\n\nas.numeric\nas.factor\nst_as_sf\ndata.frame"
  },
  {
    "objectID": "slides/Untitled.html#tools-for-merging-and-shaping-data",
    "href": "slides/Untitled.html#tools-for-merging-and-shaping-data",
    "title": "Week 3",
    "section": "tools for merging and shaping data",
    "text": "tools for merging and shaping data\n\ninner_join\nleft_join\nright_join\nfull_join\npivot_longer\npivot_wider"
  },
  {
    "objectID": "slides/Untitled.html#tools-for-measuring-geometries",
    "href": "slides/Untitled.html#tools-for-measuring-geometries",
    "title": "Week 3",
    "section": "tools for measuring geometries:",
    "text": "tools for measuring geometries:\n\nst_distance\nst_area\nst_length\nset_units / drop_units"
  },
  {
    "objectID": "slides/Untitled.html#so-why-write-functions-opposed-to-scripts",
    "href": "slides/Untitled.html#so-why-write-functions-opposed-to-scripts",
    "title": "Week 3",
    "section": "So why write functions opposed to scripts?",
    "text": "So why write functions opposed to scripts?\n\nThe process can be named\nAs requirements change, you only need to update code in one place\nYou eliminate the chance of making incidental mistakes when you copy and paste (forgetting to change dist_to_state to dist_to_border).\nfunctions can be ‚Äòsourced‚Äô into Rmd files and R Scripts\nYou save youself time"
  },
  {
    "objectID": "slides/Untitled.html#rule-of-thumb",
    "href": "slides/Untitled.html#rule-of-thumb",
    "title": "Week 3",
    "section": "Rule of thumb  ",
    "text": "Rule of thumb  \n\nData is the first argument (better for pipes!)\nWhenever you have copy-and pasted code more than twice you should write a function\n\nFor example how many times have we coded:\n\nstates = USAboundaries::us_states() %&gt;% \n  filter(!name %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n\n\nOr made the same table with knitr/kableExtra only changing the col.names and data.frame\nOr calculated a distance, changed the units, and dropped them?\nAll of these task are repetitive and prone to making errors that could impact our analysis but not break our code‚Ä¶"
  },
  {
    "objectID": "slides/Untitled.html#using-our-function",
    "href": "slides/Untitled.html#using-our-function",
    "title": "Week 3",
    "section": "Using our function:",
    "text": "Using our function:\n\nLike any object, we have to run the lines of code to save it as an object before we can use it directly in our code:\nBut then ‚Ä¶\n\n\n\nStates\n\nx = get_conus(data = us_states(), var = \"name\")\nplot(x$geometry)\n\n\n\n\n\n\n\n\n\nCounties\n\nx2 = get_conus(data = us_counties()[,-9], var = \"state_name\")\nplot(x2$geometry)"
  },
  {
    "objectID": "slides/Untitled.html#test",
    "href": "slides/Untitled.html#test",
    "title": "Week 3",
    "section": "Test",
    "text": "Test\n\n\n\nco_sb = point_in_polygon(starbucks, co)\nplot(co_sb['n'])\n\n\n\n\n\n\n\n\n\nca_sb = point_in_polygon(starbucks, \n                         filter(counties, state_name == \"California\"))\nplot(co_sb['n'])\n\n\n\n\n\n\n\n\n\n\nor_sb = point_in_polygon(starbucks, \n                         filter(counties, \n                                state_name == \"Oregon\"))\nplot(or_sb['n'])\n\n\n\n\n\n\n\n\n\nny_sb = point_in_polygon(starbucks, \n                         filter(counties, \n                                state_name == \"New York\"))\nplot(ny_sb['n'])"
  },
  {
    "objectID": "slides/Untitled.html#applying-the-new-function",
    "href": "slides/Untitled.html#applying-the-new-function",
    "title": "Week 3",
    "section": "Applying the new function",
    "text": "Applying the new function\n\nHere, we can apply the PIP function over states and count by name\n\n\nstates = get_conus(us_states(), \"name\") %&gt;% \n  st_transform(5070)\n\nstate_sb = point_in_polygon2(starbucks, states, 'name')\n\nplot(state_sb['n'])"
  },
  {
    "objectID": "slides/Untitled.html#section-3",
    "href": "slides/Untitled.html#section-3",
    "title": "Week 3",
    "section": "",
    "text": "sf::sf_use_s2(FALSE)\ncountries = st_as_sf(rnaturalearth::countries110)\n\nurl = '/Users/mikejohnson/Downloads/earthquakes-2025-03-29_21-55-22_-0600.tsv'\n\nquakes  = read_delim(url, delim = \"\\t\") %&gt;% \n  filter(!is.na(Latitude), !is.na(Longitude)) %&gt;% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %&gt;%     \n  st_transform(st_crs(countries))\n\nnrow(countries)\n#&gt; [1] 177\nnrow(quakes)\n#&gt; [1] 6443\nnrow(st_intersection(quakes, countries))\n#&gt; [1] 4317"
  },
  {
    "objectID": "slides/Untitled.html#pip-plotting-method",
    "href": "slides/Untitled.html#pip-plotting-method",
    "title": "Week 3",
    "section": "PIP ‚Äì> Plotting Method",
    "text": "PIP ‚Äì&gt; Plotting Method\n\nWe can use our functions right out of the box for this data\nBut‚Ä¶ somethings are not quite right..\n\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") %&gt;% \n  plot_pip()"
  },
  {
    "objectID": "slides/Untitled.html#modify-for-our-analysis",
    "href": "slides/Untitled.html#modify-for-our-analysis",
    "title": "Week 3",
    "section": "Modify for our analysis ‚Ä¶",
    "text": "Modify for our analysis ‚Ä¶\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") %&gt;% \n  plot_pip() + #&lt;&lt;\n  labs(title = \"Earthquake Locations\") + \n  scale_fill_viridis_c() + \n  geom_sf(data = quakes, size = .25, alpha = .05, col = 'red')"
  },
  {
    "objectID": "slides/Untitled.html#improve-the-anaylsis",
    "href": "slides/Untitled.html#improve-the-anaylsis",
    "title": "Week 3",
    "section": "Improve the anaylsis‚Ä¶",
    "text": "Improve the anaylsis‚Ä¶\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") %&gt;% \n  plot_pip() + \n  labs(title = \"Earthquake Locations\",\n       subtitle = \"Most impacted countries\") + \n  theme(plot.subtitle = element_text(hjust = .5),\n        plot.title = element_text(color = \"navy\")) + \n  scale_fill_viridis_c() + \n  geom_sf(data = quakes, size = .3, alpha = .05, col = 'red') +\n  gghighlight::gghighlight(n &gt; (mean(n) + sd(n)))"
  },
  {
    "objectID": "slides/Untitled.html#thats-not-bad",
    "href": "slides/Untitled.html#thats-not-bad",
    "title": "Week 3",
    "section": "Thats not bad‚Ä¶",
    "text": "Thats not bad‚Ä¶\n\n# How many seconds per point?\n(point_per_sec = 4.3 / (nrow(counties) * nrow(starbucks)))\n#&gt; [1] 1.036916e-07\n\n\n# How will this scale to our dams data\n# (assuming the process is linear)\n\npoint_per_sec * (nrow(counties) * 91000)\n#&gt; [1] 29.31745\n\n\n~ 30 seconds to test ~282,100,000 point/polygon relations is not bad, but could be a bottle neck in analysis\nLets look at a common means for improvement‚Ä¶"
  },
  {
    "objectID": "slides/functions.html#tools-for-reading-and-writing-data",
    "href": "slides/functions.html#tools-for-reading-and-writing-data",
    "title": "Week 3",
    "section": "tools for reading and writing data:",
    "text": "tools for reading and writing data:\n\nread_sf / write_sf\nread_csv / write_csv\nread_excel"
  },
  {
    "objectID": "slides/functions.html#tools-for-data-maniputation",
    "href": "slides/functions.html#tools-for-data-maniputation",
    "title": "Week 3",
    "section": "tools for data maniputation",
    "text": "tools for data maniputation\n\nfilter\nselect\nmutate\ngroup_by\nsummarize\nrollmean, lag"
  },
  {
    "objectID": "slides/functions.html#tools-to-managemanipulate-data-typestructure",
    "href": "slides/functions.html#tools-to-managemanipulate-data-typestructure",
    "title": "Week 3",
    "section": "tools to manage/manipulate data type/structure",
    "text": "tools to manage/manipulate data type/structure\n\nas.numeric\nas.factor\nst_as_sf\ndata.frame"
  },
  {
    "objectID": "slides/functions.html#tools-for-merging-and-shaping-data",
    "href": "slides/functions.html#tools-for-merging-and-shaping-data",
    "title": "Week 3",
    "section": "tools for merging and shaping data",
    "text": "tools for merging and shaping data\n\ninner_join\nleft_join\nright_join\nfull_join\npivot_longer\npivot_wider"
  },
  {
    "objectID": "slides/functions.html#tools-for-measuring-geometries",
    "href": "slides/functions.html#tools-for-measuring-geometries",
    "title": "Week 3",
    "section": "tools for measuring geometries:",
    "text": "tools for measuring geometries:\n\nst_distance\nst_area\nst_length\nset_units / drop_units"
  },
  {
    "objectID": "slides/functions.html#these-tools-are-all-functions",
    "href": "slides/functions.html#these-tools-are-all-functions",
    "title": "Week 3",
    "section": "These tools are all functions",
    "text": "These tools are all functions\n\nR is a statistical computing language that provides features as functions\nEven with just its base installation, R provides hundreds of functions:\n\n\nlength(lsf.str(\"package:base\")) + length(lsf.str(\"package:stats\")) + length(lsf.str(\"package:utils\"))\n#&gt; [1] 1947\n\n\nsf provides over 100 more\n\n\nlength(lsf.str(\"package:sf\")) \n#&gt; [1] 149\n\n\nand the core tidyverse packages (that we use) an additional ~750\n\n\nlength(lsf.str(\"package:dplyr\")) +\nlength(lsf.str(\"package:ggplot2\")) +\nlength(lsf.str(\"package:tidyr\")) +\nlength(lsf.str(\"package:forcats\")) +\nlength(lsf.str(\"package:purrr\")) \n#&gt; [1] 1025"
  },
  {
    "objectID": "slides/functions.html#to-date",
    "href": "slides/functions.html#to-date",
    "title": "Week 3",
    "section": "To date ‚Ä¶",
    "text": "To date ‚Ä¶\n\nWe have been using functions written for us - mostly by sf and the tidyverse\nThis how any commercial GIS suite operates as well\nAnalysis and workflows are limited to the tools kits and options exposed to the user\nIn R, a lot more is actually exposed!\nEvery time we install a new package, we download code that provides new specific features (as functions)\nEvery time we attach a package to a working session (library()) we are making those functions available/visible"
  },
  {
    "objectID": "slides/functions.html#functions-are-objects",
    "href": "slides/functions.html#functions-are-objects",
    "title": "Week 3",
    "section": "Functions are objects",
    "text": "Functions are objects\n\nJust like x = 10 binds the value of 10 to the name x creating an object visible in the environment,\nfunctions are objects that can be called by name to execute a set of directions over defined arguments.\n\n\nclass(sf::st_intersects)\n#&gt; [1] \"function\"\nclass(sf::st_as_sf)\n#&gt; [1] \"function\""
  },
  {
    "objectID": "slides/functions.html#our-own-functions-are-visable-as-objects-in-the-environemnt",
    "href": "slides/functions.html#our-own-functions-are-visable-as-objects-in-the-environemnt",
    "title": "Week 3",
    "section": "Our own functions are visable as objects in the environemnt",
    "text": "Our own functions are visable as objects in the environemnt\n\nx = 10\ny = data.frame(x = 1:10, y = 10:1)\nf = function(x,y){ x  + y }"
  },
  {
    "objectID": "slides/functions.html#advancing-your-programming-skills",
    "href": "slides/functions.html#advancing-your-programming-skills",
    "title": "Week 3",
    "section": "Advancing your programming skills",
    "text": "Advancing your programming skills\n\nOne of the best ways to improve your skills as a data scientist is to write functions.\nFunctions allow you to automate common tasks in a more general way than copy-and-pasting.\nThe more times you apply a function, the more incentive you have to optimize it for speed/accuracy\nThe more creative/unique your analyses and questions can be"
  },
  {
    "objectID": "slides/functions.html#so-why-write-functions-opposed-to-scripts",
    "href": "slides/functions.html#so-why-write-functions-opposed-to-scripts",
    "title": "Week 3",
    "section": "So why write functions opposed to scripts?",
    "text": "So why write functions opposed to scripts?\n\nThe process can be named\nAs requirements change, you only need to update code in one place\nYou eliminate the chance of making incidental mistakes when you copy and paste (forgetting to change dist_to_state to dist_to_border).\nfunctions can be ‚Äòsourced‚Äô into Qmd/Rmd files and R Scripts\nYou save yourself time"
  },
  {
    "objectID": "slides/functions.html#rule-of-thumb",
    "href": "slides/functions.html#rule-of-thumb",
    "title": "Week 3",
    "section": "Rule of thumb  ",
    "text": "Rule of thumb  \n\nData is the first argument (better for pipes!)\nWhenever you have copy-and pasted code more than twice you should write a function\n\nFor example how many times have we coded:\n\nstates = USAboundaries::us_states() |&gt; \n  filter(!name %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n\n\nOr made the same table with knitr/kableExtra only changing the col.names and data.frame\nOr calculated a distance, changed the units, and dropped them?\nAll of these task are repetitive and prone to making errors that could impact our analysis but not break our code‚Ä¶"
  },
  {
    "objectID": "slides/functions.html#the-form-of-a-function",
    "href": "slides/functions.html#the-form-of-a-function",
    "title": "Week 3",
    "section": "The form of a function:",
    "text": "The form of a function:\nCreating a function follows the form:\n\nname = function(arg1, arg2, *){\n  code\n  ..\n  return(...)\n}\n\nWhere:\n\nname is the function name (e.g.¬†st_as_sf)\n\nThis is the name on which R is able to call the object\n\narg1 is the first input\narg2 is the second input\n* is any other argument you want to define\ncode ... defines the instructions to carry out on arg1 and arg2\nreturn(...) is what the function returns"
  },
  {
    "objectID": "slides/functions.html#defining-a-function",
    "href": "slides/functions.html#defining-a-function",
    "title": "Week 3",
    "section": "Defining a function",
    "text": "Defining a function\n\nTo define a function we need to identify the code we have, and what can/should generalized for future uses?\n\n\nstates = USAboundaries::us_states() |&gt; \n  filter(!name %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n\n\nHere the input data (us_states) could change\nSo could the variable name we filter by (name)"
  },
  {
    "objectID": "slides/functions.html#function-signiture",
    "href": "slides/functions.html#function-signiture",
    "title": "Week 3",
    "section": "Function Signiture",
    "text": "Function Signiture\nSo, lets start with a function that takes general input data and a variable name\n\nget_conus = function(data, var){\n\n}"
  },
  {
    "objectID": "slides/functions.html#function-arguments",
    "href": "slides/functions.html#function-arguments",
    "title": "Week 3",
    "section": "Function arguments",
    "text": "Function arguments\nFunction arguments typically include two two broad sets: - the data to compute on, - arguments that control the details of the calculation\n\nIn st_transform x is the data, crs is the proj4string/EPSG code\nIn ms_simplify input is the data, keep defines the directions\nIn get_conus: data provides the data, var defines the column to filter"
  },
  {
    "objectID": "slides/functions.html#section",
    "href": "slides/functions.html#section",
    "title": "Week 3",
    "section": "",
    "text": "Generally, data arguments should come first.\nDetail arguments should go on the end\nIt can be useful - and good practice - to define default values.\n\nshould almost always be the most common value.\nThe exceptions to this rule are to do with safety of the process.\n\ne.g.¬†na.rm = FALSE"
  },
  {
    "objectID": "slides/functions.html#code-body",
    "href": "slides/functions.html#code-body",
    "title": "Week 3",
    "section": "Code body",
    "text": "Code body\nWe then have to carry these generalizations into the function directions using the arguments as our operators:\n\nget_conus = function(data, var){\n  conus = filter(data, !get(var) %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n  return(conus)\n}\n\n\nhere, we replace us_states() with data\nwe use get() to return the value of a named object\nWe assign our filtered object to the name conus\nAnd explicitly return the conus object from the function\nThe value returned by the function is usually the last evaluated statement, if we don‚Äôt specify return we can take advantage of this default:\n\n\nget_conus = function(data, var){\n  filter(data, !get(var) %in% c(\"Hawaii\", \"Puerto Rico\", \"Alaska\"))\n}"
  },
  {
    "objectID": "slides/functions.html#using-our-function",
    "href": "slides/functions.html#using-our-function",
    "title": "Week 3",
    "section": "Using our function:",
    "text": "Using our function:\n\nLike any object, we have to run the lines of code to save it as an object before we can use it directly in our code:\nBut then ‚Ä¶\n\n\n\nStates\n\nx = get_conus(data = us_states(), var = \"name\")\nplot(x$geometry)\n\n\n\n\n\n\n\n\n\nCounties\n\nx2 = get_conus(data = us_counties()[,-9], var = \"state_name\")\nplot(x2$geometry)"
  },
  {
    "objectID": "slides/functions.html#cities",
    "href": "slides/functions.html#cities",
    "title": "Week 3",
    "section": "Cities",
    "text": "Cities\n\ncities = read_csv(\"../labs/data/uscities.csv\") |&gt;\n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) |&gt; \n  get_conus(\"state_name\")\n\nplot(cities$geometry, pch = 16, cex = .1)"
  },
  {
    "objectID": "slides/functions.html#its-ok-to-be-more-detailed",
    "href": "slides/functions.html#its-ok-to-be-more-detailed",
    "title": "Week 3",
    "section": "It‚Äôs ok to be more detailed",
    "text": "It‚Äôs ok to be more detailed\n\nAnother advantage of functions is that if our requirements change, we only need to make the change our code in one place.\nThis also means we can spend more time fine-tuning our code since we know it will be recycled.\nHere we can be more focused and make sure to remove other potential ‚Äúnon-conus‚Äù states from any input object:\n\n\nget_conus = function(data, var){\n  filter(data, !get(var) %in% \n           c(\"Hawaii\", \"Puerto Rico\", \"Alaska\",\n             \"Guam\", \"District of Columbia\"))\n}"
  },
  {
    "objectID": "slides/functions.html#using-our-function-1",
    "href": "slides/functions.html#using-our-function-1",
    "title": "Week 3",
    "section": "Using our function",
    "text": "Using our function\n\nconus = get_conus(us_states(), \"name\")\nnrow(conus)\n#&gt; [1] 48"
  },
  {
    "objectID": "slides/functions.html#point-in-polygon-case-study",
    "href": "slides/functions.html#point-in-polygon-case-study",
    "title": "Week 3",
    "section": "Point-in-Polygon Case Study",
    "text": "Point-in-Polygon Case Study\n\nThe power of GIS lies in analyzing multiple data sources together.\nOften the answer you want lies in many different layers and you need to do some analysis to extract and compile information.\nOne common analysis is Points-in-Polygon (PIP).\nPIP is useful when you want to know how many - or what kind of - points fall within the bounds of each polygon"
  },
  {
    "objectID": "slides/functions.html#data",
    "href": "slides/functions.html#data",
    "title": "Week 3",
    "section": "Data",
    "text": "Data\nCONUS counties\n\ncounties = st_transform(us_counties()[,-9], 5070) |&gt; \n  select(name, geoid, state_name) |&gt; \n  get_conus(\"state_name\")\n\nCONUS Starbucks\n\nstarbucks = read_csv('data/directory.csv') |&gt; \n  filter(!is.na(Latitude), Country == \"US\") |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt; \n  st_transform(5070) |&gt; \n  st_filter(counties) |&gt; \n  select(store_name = `Store Name`)\n\nColorado Counties\n\nco = filter(counties, state_name == \"Colorado\")"
  },
  {
    "objectID": "slides/functions.html#step-1-spatial-join",
    "href": "slides/functions.html#step-1-spatial-join",
    "title": "Week 3",
    "section": "Step 1: Spatial Join",
    "text": "Step 1: Spatial Join\nTo count the Starbucks locations in CA counties, we start by joining the CA counties to the locations:\n\nHere we uses the counties as the x table and the locations as the y table\nThis is because we want to add the starbucks information to the county sf object.\nRemember the default of st_join is a left_join on the st_intersects predicate\n\n\n(starbucks1 = st_join(co, starbucks))\n#&gt; Simple feature collection with 511 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1146480 ymin: 1566911 xmax: -504612.5 ymax: 2073715\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; First 10 features:\n#&gt;         name geoid state_name                        store_name\n#&gt; 1       Yuma 08125   Colorado                              &lt;NA&gt;\n#&gt; 2   San Juan 08111   Colorado                              &lt;NA&gt;\n#&gt; 3       Baca 08009   Colorado                              &lt;NA&gt;\n#&gt; 4    Prowers 08099   Colorado                              &lt;NA&gt;\n#&gt; 5     Custer 08027   Colorado                              &lt;NA&gt;\n#&gt; 6    Fremont 08043   Colorado     City Market - Canon City #417\n#&gt; 7       Mesa 08077   Colorado    I-70 Business Loop & 32 Rd - C\n#&gt; 7.1     Mesa 08077   Colorado    Hwy 6 & 25 Rd - Grand Junction\n#&gt; 7.2     Mesa 08077   Colorado   City Market-Grand Junction #444\n#&gt; 7.3     Mesa 08077   Colorado City Market - Grand Junction #432\n#&gt;                           geometry\n#&gt; 1   MULTIPOLYGON (((-575240.5 1...\n#&gt; 2   MULTIPOLYGON (((-1042591 16...\n#&gt; 3   MULTIPOLYGON (((-617878.8 1...\n#&gt; 4   MULTIPOLYGON (((-587200.4 1...\n#&gt; 5   MULTIPOLYGON (((-847581.3 1...\n#&gt; 6   MULTIPOLYGON (((-863875.9 1...\n#&gt; 7   MULTIPOLYGON (((-1114392 18...\n#&gt; 7.1 MULTIPOLYGON (((-1114392 18...\n#&gt; 7.2 MULTIPOLYGON (((-1114392 18...\n#&gt; 7.3 MULTIPOLYGON (((-1114392 18..."
  },
  {
    "objectID": "slides/functions.html#step-2-point-counts-by-polygon",
    "href": "slides/functions.html#step-2-point-counts-by-polygon",
    "title": "Week 3",
    "section": "Step 2: Point counts by Polygon",
    "text": "Step 2: Point counts by Polygon\ncount() is a dplyr function that ‚Äúlets you quickly count the unique values of one or more variables: df |&gt; count(a, b) is roughly equivalent to df |&gt; group_by(a, b) |&gt; summarize(n = n())‚Äù\n\n(count(starbucks1, geoid))\n#&gt; Simple feature collection with 64 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1146480 ymin: 1566911 xmax: -504612.5 ymax: 2073715\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; First 10 features:\n#&gt;    geoid  n                       geometry\n#&gt; 1  08001 35 MULTIPOLYGON (((-765835.6 1...\n#&gt; 2  08003  1 MULTIPOLYGON (((-878691.4 1...\n#&gt; 3  08005 58 MULTIPOLYGON (((-769015.2 1...\n#&gt; 4  08007  1 MULTIPOLYGON (((-1004101 16...\n#&gt; 5  08009  1 MULTIPOLYGON (((-617878.8 1...\n#&gt; 6  08011  1 MULTIPOLYGON (((-640691.8 1...\n#&gt; 7  08013 36 MULTIPOLYGON (((-819541.3 1...\n#&gt; 8  08014  9 MULTIPOLYGON (((-775389.1 1...\n#&gt; 9  08015  1 MULTIPOLYGON (((-905015.4 1...\n#&gt; 10 08017  1 MULTIPOLYGON (((-616732 176..."
  },
  {
    "objectID": "slides/functions.html#step-3-combine-the-processes",
    "href": "slides/functions.html#step-3-combine-the-processes",
    "title": "Week 3",
    "section": "Step 3: Combine the processes ‚Ä¶",
    "text": "Step 3: Combine the processes ‚Ä¶\n\nstarbucks1 = st_join(co, starbucks) |&gt; \n   count(geoid)\n\nplot(starbucks1['n'])"
  },
  {
    "objectID": "slides/functions.html#now-for-colorado",
    "href": "slides/functions.html#now-for-colorado",
    "title": "Week 3",
    "section": "Now for Colorado?",
    "text": "Now for Colorado?\nWe can anticipate that PIP is a useful process we want to implement over variable points and polygons pairs\nSo, lets make a function named point_in_polygon, that takes a point dataset and a polygon dataset\n\npoint_in_polygon = function(points, polygon){\n st_join(polygon, points) |&gt; \n   count(geoid)\n}"
  },
  {
    "objectID": "slides/functions.html#test",
    "href": "slides/functions.html#test",
    "title": "Week 3",
    "section": "Test",
    "text": "Test\n\n\n\nco_sb = point_in_polygon(starbucks, co)\nplot(co_sb['n'])\n\n\n\n\n\n\n\n\n\nca_sb = point_in_polygon(starbucks, \n                         filter(counties, state_name == \"California\"))\nplot(co_sb['n'])\n\n\n\n\n\n\n\n\n\n\nor_sb = point_in_polygon(starbucks, \n                         filter(counties, \n                                state_name == \"Oregon\"))\nplot(or_sb['n'])\n\n\n\n\n\n\n\n\n\nny_sb = point_in_polygon(starbucks, \n                         filter(counties, \n                                state_name == \"New York\"))\nplot(ny_sb['n'])"
  },
  {
    "objectID": "slides/functions.html#generalizing-the-count-variable",
    "href": "slides/functions.html#generalizing-the-count-variable",
    "title": "Week 3",
    "section": "Generalizing the count variable",
    "text": "Generalizing the count variable\n\nIn its current form, point_in_polygon only counts on geoid\nLets modify that by making the variable name an input\n\nagain, we use get() to return the value of a named object\nwe call this, variable id\n\n\n\npoint_in_polygon2 = function(points, polygon, var){\n  st_join(polygon, points) |&gt; \n    count(get(var))\n}"
  },
  {
    "objectID": "slides/functions.html#applying-the-new-function",
    "href": "slides/functions.html#applying-the-new-function",
    "title": "Week 3",
    "section": "Applying the new function",
    "text": "Applying the new function\n\nHere, we can apply the PIP function over states and count by name\n\n\nstates = get_conus(us_states(), \"name\") |&gt; \n  st_transform(5070)\n\nstate_sb = point_in_polygon2(starbucks, states, 'name')\n\nplot(state_sb['n'])"
  },
  {
    "objectID": "slides/functions.html#optimizing-functions",
    "href": "slides/functions.html#optimizing-functions",
    "title": "Week 3",
    "section": "Optimizing functions",
    "text": "Optimizing functions\n\nLets apply our function over the counties and see how long it takes\nWe can check the time it takes by wrapping our function in system.time\n\n\nsystem.time({\n  us = point_in_polygon(starbucks, counties)\n})\n\n# user    system  elapsed \n# 3.719   0.354   4.309"
  },
  {
    "objectID": "slides/functions.html#thats-not-bad",
    "href": "slides/functions.html#thats-not-bad",
    "title": "Week 3",
    "section": "Thats not bad‚Ä¶",
    "text": "Thats not bad‚Ä¶\n\n# How many seconds per point?\n(point_per_sec = 4.3 / (nrow(counties) * nrow(starbucks)))\n#&gt; [1] 1.036916e-07\n\n\n# How will this scale to our dams data\n# (assuming the process is linear)\n\npoint_per_sec * (nrow(counties) * 91000)\n#&gt; [1] 29.31745\n\n\n~ 30 seconds to test ~282,100,000 point/polygon relations is not bad, but could be a bottle neck in analysis\nLets look at a common means for improvement‚Ä¶"
  },
  {
    "objectID": "slides/functions.html#to-keep-geometery-or-not",
    "href": "slides/functions.html#to-keep-geometery-or-not",
    "title": "Week 3",
    "section": "To keep geometery or not?",
    "text": "To keep geometery or not?\n\nRemember our geometries are sticky, that means they carry through all calculations - whether they are needed or not\nWe can ease alot of computational overhead by being mindful of when we retain our geometry data with our attribute data.\n\n\n\n\nsystem.time({\n  st_join(counties, starbucks) |&gt; \n    count(geoid) \n})\n\n#user    system  elapsed \n#3.970   0.421   5.521\n\n\n\nsystem.time({\n  st_join(counties, starbucks) |&gt; \n    st_drop_geometry() |&gt; \n    count(geoid) |&gt; \n    left_join(counties, by = 'geoid') |&gt; \n    st_as_sf() \n})\n\n# user    system  elapsed \n# 0.396   0.017   0.598"
  },
  {
    "objectID": "slides/functions.html#section-1",
    "href": "slides/functions.html#section-1",
    "title": "Week 3",
    "section": "",
    "text": "# How many seconds per point?\n# How many seconds per point?\n(point_per_sec = .598 / (nrow(counties) * nrow(starbucks)))\n#&gt; [1] 1.442037e-08\n\n# How will this scale to our dams data\n# (assuming the process is linear)\n\npoint_per_sec * (nrow(counties) * 91000)\n#&gt; [1] 4.077171\n\nAwesome!\nEffectively a 86% decrease in time needed ((29-4) / 29)\n‚ÄúFunction-izing‚Äù our improvements\n\npoint_in_polygon3 = function(points, polygon, var){\n  st_join(polygon, points) |&gt; \n    st_drop_geometry() |&gt; \n    count(get(var)) |&gt; \n    setNames(c(var, \"n\")) |&gt; #&lt;&lt; \n    left_join(polygon, by = var) |&gt; \n    st_as_sf() \n}"
  },
  {
    "objectID": "slides/functions.html#what-else-can-we-wrap",
    "href": "slides/functions.html#what-else-can-we-wrap",
    "title": "Week 3",
    "section": "What else can we wrap?",
    "text": "What else can we wrap?\n\nWhat about a really nice, clean, informative plot?\nggplots look great but can be time consuming to program‚Ä¶\nA function would allow us to take care of the groundwork\n\n\nplot_pip = function(data){\n  ggplot() + \n    geom_sf(data = data, aes(fill = log(n)), alpha = .9, size = .2) + \n    scale_fill_gradient(low = \"white\", high = \"darkgreen\") + \n    theme_void() + \n    theme(legend.position = 'none',\n          plot.title = element_text(face = \"bold\", color = \"darkgreen\", hjust = .5, size = 24)) +\n    labs(title = \"Starbucks Locations\",\n         caption = paste0(sum(data$n), \" locations represented\")) \n}\n\n\nThis is great because we can devote the time to making a nice plot and we will be able to recycle the work over other cases‚Ä¶"
  },
  {
    "objectID": "slides/functions.html#test-1",
    "href": "slides/functions.html#test-1",
    "title": "Week 3",
    "section": "Test",
    "text": "Test\n\n\n\npoint_in_polygon3(starbucks, filter(counties, state_name == \"California\"), \"geoid\") |&gt; \nplot_pip()\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, filter(counties, state_name == \"New York\"), \"geoid\") |&gt; \nplot_pip()\n\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, counties, \"geoid\") |&gt; \n  plot_pip()\n\n\n\n\n\n\n\n\n\npoint_in_polygon3(starbucks, states, var = \"name\") |&gt; \n  plot_pip()"
  },
  {
    "objectID": "slides/functions.html#moving-beyond-starbucks",
    "href": "slides/functions.html#moving-beyond-starbucks",
    "title": "Week 3",
    "section": "Moving beyond Starbucks?",
    "text": "Moving beyond Starbucks?\n\nHere is a nice tutorial of point-in-polygon in QGIS. It is looking at earthquakes by country.\nJust like us they use naturalearth data for the polygon areas\nAnd they are looking at earthquake data maintained by NOAA.\nIn R, we can read the NOAA data directly from a URL.\nThe data is a tab delimited txt file so we use readr::read_delim()"
  },
  {
    "objectID": "slides/functions.html#section-2",
    "href": "slides/functions.html#section-2",
    "title": "Week 3",
    "section": "",
    "text": "sf::sf_use_s2(FALSE)\ncountries = st_as_sf(rnaturalearth::countries110)\n\nquakes = 'data/earthquakes-2025-03-29_21-55-22_-0600.tsv' |&gt; \n  read_delim(delim = \"\\t\") |&gt; \n  filter(!is.na(Latitude), !is.na(Longitude)) |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt;     \n  st_transform(st_crs(countries))\n\nnrow(countries)\n#&gt; [1] 177\nnrow(quakes)\n#&gt; [1] 6443\nnrow(st_intersection(quakes, countries))\n#&gt; [1] 4317"
  },
  {
    "objectID": "slides/functions.html#pip-plotting-method",
    "href": "slides/functions.html#pip-plotting-method",
    "title": "Week 3",
    "section": "PIP ‚Äì> Plotting Method",
    "text": "PIP ‚Äì&gt; Plotting Method\n\nWe can use our functions right out of the box for this data\nBut‚Ä¶ somethings are not quite right..\n\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") |&gt; \n  plot_pip()"
  },
  {
    "objectID": "slides/functions.html#modify-for-our-analysis",
    "href": "slides/functions.html#modify-for-our-analysis",
    "title": "Week 3",
    "section": "Modify for our analysis ‚Ä¶",
    "text": "Modify for our analysis ‚Ä¶\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") |&gt; \n  plot_pip() + #&lt;&lt;\n  labs(title = \"Earthquake Locations\") + \n  scale_fill_viridis_c() + \n  geom_sf(data = quakes, size = .25, alpha = .05, col = 'red')"
  },
  {
    "objectID": "slides/functions.html#improve-the-anaylsis",
    "href": "slides/functions.html#improve-the-anaylsis",
    "title": "Week 3",
    "section": "Improve the anaylsis‚Ä¶",
    "text": "Improve the anaylsis‚Ä¶\n\npoint_in_polygon3(quakes, countries, var = \"ADMIN\") |&gt; \n  plot_pip() + \n  labs(title = \"Earthquake Locations\",\n       subtitle = \"Most impacted countries\") + \n  theme(plot.subtitle = element_text(hjust = .5),\n        plot.title = element_text(color = \"navy\")) + \n  scale_fill_viridis_c() + \n  geom_sf(data = quakes, size = .3, alpha = .05, col = 'red') +\n  gghighlight::gghighlight(n &gt; (mean(n) + sd(n)))"
  },
  {
    "objectID": "slides/week-2.html#todays-data-colorado-counties",
    "href": "slides/week-2.html#todays-data-colorado-counties",
    "title": "Week 2",
    "section": "Todays Data: Colorado Counties!",
    "text": "Todays Data: Colorado Counties!\n\n#&gt; Simple feature collection with 64 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    geoid       name      aland state_nm                       geometry\n#&gt; 1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n#&gt; 2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n#&gt; 3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n#&gt; 4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n#&gt; 5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n#&gt; 6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n#&gt; 7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n#&gt; 8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n#&gt; 9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n#&gt; 10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3..."
  },
  {
    "objectID": "slides/week-2.html#section-8",
    "href": "slides/week-2.html#section-8",
    "title": "Week 2",
    "section": "",
    "text": "We can set units if we do manipulations as well using the units package\n\nunits::set_units(l, \"km\")\n#&gt; 94980.15 [km]\nunits::set_units(l, \"mile\")\n#&gt; 59017.93 [mile]\n\nunits::set_units(a, \"ha\")\n#&gt; 783760974 [ha]\nunits::set_units(a, \"km2\")\n#&gt; 7837610 [km^2]\nunits::set_units(a, \"in2\")\n#&gt; 1.214832e+16 [in^2]"
  },
  {
    "objectID": "slides/week-2.html#conus",
    "href": "slides/week-2.html#conus",
    "title": "Week 2",
    "section": "CONUS",
    "text": "CONUS\n\n\n\nconus &lt;-  USAboundaries::us_states() |&gt;\n  filter(!state_name %in% c(\"Puerto Rico\", \n                            \"Alaska\", \n                            \"Hawaii\"))\n\nlength(st_geometry(conus))\n#&gt; [1] 49\n\n\n\nggplot() + \n  geom_sf(data = conus, aes(fill = state_name)) + \n  theme_linedraw() + \n  theme(legend.position = \"none\") + \n  labs(title = paste(\"CONUS:\", length(st_geometry(conus)), \"feature(s)\") ) + \n  scale_fill_viridis_d()"
  },
  {
    "objectID": "slides/week-2.html#what-makes-spatial-data-spatial",
    "href": "slides/week-2.html#what-makes-spatial-data-spatial",
    "title": "Week 2",
    "section": "What makes spatial data spatial?",
    "text": "What makes spatial data spatial?\n\nWhat makes a feature geometry spatial is the reference system‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#geometrycollection-1",
    "href": "slides/week-2.html#geometrycollection-1",
    "title": "Week 2",
    "section": "GEOMETRYCOLLECTION",
    "text": "GEOMETRYCOLLECTION\n\nIn case we end up with GEOMETRYCOLLECTION objects, the next question is often what to do with them. One thing we can do is extract elements from them:\n\n\n\nst_collection_extract(j, \"POLYGON\")\n#&gt; Geometry set for 3 features \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 5.5 ymin: -0.5 xmax: 8 ymax: 1.5\n#&gt; CRS:           NA\n#&gt; MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\n#&gt; MULTIPOLYGON (((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)))\n#&gt; MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\n\nst_collection_extract(j, \"POINT\")\n#&gt; POINT (1 0)\n\nst_collection_extract(j, \"LINESTRING\")\n#&gt; LINESTRING (4 0, 3 0)"
  },
  {
    "objectID": "slides/week-2.html#conversion-between-types",
    "href": "slides/week-2.html#conversion-between-types",
    "title": "Week 2",
    "section": "Conversion between types",
    "text": "Conversion between types\nWe can convert simple feature geometries using the st_cast generic (up to the extent that a conversion is feasible):\n\nmethods(st_cast)\n#&gt;  [1] st_cast.CIRCULARSTRING*     st_cast.COMPOUNDCURVE*     \n#&gt;  [3] st_cast.CURVE*              st_cast.GEOMETRYCOLLECTION*\n#&gt;  [5] st_cast.LINESTRING*         st_cast.MULTICURVE*        \n#&gt;  [7] st_cast.MULTILINESTRING*    st_cast.MULTIPOINT*        \n#&gt;  [9] st_cast.MULTIPOLYGON*       st_cast.MULTISURFACE*      \n#&gt; [11] st_cast.POINT*              st_cast.POLYGON*           \n#&gt; [13] st_cast.sf*                 st_cast.sfc*               \n#&gt; [15] st_cast.sfc_CIRCULARSTRING*\n#&gt; see '?methods' for accessing help and source code"
  },
  {
    "objectID": "slides/week-2.html#conversion-between-types-1",
    "href": "slides/week-2.html#conversion-between-types-1",
    "title": "Week 2",
    "section": "Conversion between types",
    "text": "Conversion between types\nLets take the Larimer County in our Colorado sf object:\n\n(co1 = filter(co, name == \"Larimer\")$geometry)\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -106.1954 ymin: 40.25778 xmax: -104.9431 ymax: 40.99844\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTIPOLYGON (((-105.6533 40.26046, -105.6094 4...\n(co_ls = st_cast(co1, \"MULTILINESTRING\"))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -106.1954 ymin: 40.25778 xmax: -104.9431 ymax: 40.99844\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTILINESTRING ((-105.6533 40.26046, -105.6094..."
  },
  {
    "objectID": "slides/week-2.html#smaller",
    "href": "slides/week-2.html#smaller",
    "title": "Week 2",
    "section": ".{smaller}",
    "text": ".{smaller}\n\n\n\n(co_c = st_combine(co_geom))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTIPOLYGON (((-105.0532 39.79106, -104.976 39...\n\n\n\n\n\n\n\n\n\n\n\n(co_u = st_union(co_geom))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; POLYGON ((-105.155 36.99526, -105.1208 36.99543...\n\n\n\n\n\n\n\n\n\n\n\n\n(co_c_ml = st_combine(co_geom) |&gt; \n   st_cast(\"MULTILINESTRING\"))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTILINESTRING ((-105.0532 39.79106, -104.976 ...\n\n\n\n\n\n\n\n\n\n\n\n(co_u_ml = st_union(co_geom)  |&gt; \n    st_cast(\"MULTILINESTRING\"))\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\n#&gt; MULTILINESTRING ((-105.155 36.99526, -105.1208 ..."
  },
  {
    "objectID": "slides/week-2.html#conversion-between-types-2",
    "href": "slides/week-2.html#conversion-between-types-2",
    "title": "Week 2",
    "section": "Conversion between types",
    "text": "Conversion between types\nIt is often convenient to analyze the the points that make up a LINESTRING However ‚Ä¶\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt; \n  st_linestring() |&gt; \n  st_cast(\"POINT\")\n#&gt; Warning in st_cast.LINESTRING(st_linestring(rbind(c(0, 0), c(1, 1), c(1, :\n#&gt; point from first coordinate only\n#&gt; POINT (0 0)\n\n\ndoes not do what we expect, because it will convert a single geometry into a new single geometry (one line to one point)\n\n\nInstead, we must recognize that a collection of points is what defines a LINSETRING and a collection of POINTs, operating as a single unit, is a MULTIPOINT\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt; \n  st_linestring() |&gt; \n  st_cast(\"MULTIPOINT\")\n#&gt; MULTIPOINT ((0 0), (1 1), (1 0), (0 1))\n\n\n\nIf we really wanted the individual POINT geometries, we need to work with sets:\n\n(p &lt;- rbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt; \n   st_linestring() |&gt; \n   st_sfc() |&gt; #&lt;&lt;\n   st_cast(\"POINT\"))\n#&gt; Geometry set for 4 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\n#&gt; CRS:           NA\n#&gt; POINT (0 0)\n#&gt; POINT (1 1)\n#&gt; POINT (1 0)\n#&gt; POINT (0 1)"
  },
  {
    "objectID": "labs/keys/lab3-key.html",
    "href": "labs/keys/lab3-key.html",
    "title": "Lab 3: Tesselations, Point-in-Polygon",
    "section": "",
    "text": "Background\nIn this lab we will an explore the impacts of tessellated surfaces and the modifiable areal unit problem (MAUP) using the National Dam Inventory maintained by the United States Army Corps of Engineers. Doing this will require repetitive tasks that we will write as functions and careful consideration of feature aggregation/simplification, spatial joins, and data visualization. The end goal is to visualize the distribution of dams and there purposes across the country.\nDISCLAIMER: This lab will be crunching a TON of data, in some cases 562,590,604 values for a single process! Therefore, I encourage you to run your code chuck-by-chunk rather then regularly knitting. Your final knit may take a couple of minutes to process. I know this is painful but be proud that, all said, your report will be analyzing billions of meaningful data and geometric relations.\n\nThis labs covers 4 main skills:\n\nTessellating Surfaces to discritized space\nGeometry Simplification: to expedite expensive intersections\nWriting functions to expedite repetitious reporting and mapping tasks\nPoint-in-polygon counts to aggregate point data\n\n\nLibraries\n\n\n\n\nQuestion 1:\nHere we will prepare five tessellated surfaces from CONUS and write a function to plot them in a descriptive way.\n\nStep 1.1\nFirst, we need a spatial file of CONUS counties. For future area calculations we want these in an equal area projection (EPSG:5070).\nTo achieve this:\n\nget an sf object of US counties (AOI::aoi_get(state = \"conus\", county = \"all\"))\ntransform the data to EPSG:5070\n\n\ncounties &lt;- AOI::aoi_get(state = \"conus\", county = \"all\") %&gt;% \n  st_transform(5070)\n\n\n\nStep 1.2\nFor triangle based tessellations we need point locations to serve as our ‚Äúanchors‚Äù.\nTo achieve this:\n\ngenerate county centroids using st_centroid\nSince, we can only tessellate over a feature we need to combine or union the resulting 3,108 POINT features into a single MULTIPOINT feature\nSince these are point objects, the difference between union/combine is mute\n\n\ncentroids = st_centroid(counties) %&gt;% \n  st_combine()\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\n\n\nStep 1.3\nTessellations/Coverage‚Äôs describe the extent of a region with geometric shapes, called tiles, with no overlaps or gaps.\nTiles can range in size, shape, area and have different methods for being created.\nSome methods generate triangular tiles across a set of defined points (e.g.¬†voroni and delauny triangulation)\nOthers generate equal area tiles over a known extent (st_make_grid)\nFor this lab, we will create surfaces of CONUS using using 4 methods, 2 based on an extent and 2 based on point anchors:\nTessellations :\n\nst_voroni: creates voroni tessellation\nst_traingulate: triangulates set of points (not constrained)\n\nCoverage‚Äôs:\n\nst_make_grid: Creates a square grid covering the geometry of an sf or sfc object\nst_make_grid(square = FALSE): Create a hexagonal grid covering the geometry of an sf or sfc object\nThe side of coverage tiles can be defined by a cell resolution or a specified number of cell in the X and Y direction\n\n\nFor this step:\n\nMake a voroni tessellation over your county centroids (MULTIPOINT)\nMake a triangulated tessellation over your county centroids (MULTIPOINT)\nMake a gridded coverage with n = 70, over your counties object\nMake a hexagonal coverage with n = 70, over your counties object\n\nIn addition to creating these 4 coverage‚Äôs we need to add an ID to each tile.\nTo do this:\n\nadd a new column to each tessellation that spans from 1:n().\nRemember that ALL tessellation methods return an sfc GEOMETRYCOLLECTION, and to add attribute information - like our ID - you will have to coerce the sfc list into an sf object (st_sf or st_as_sf)\n\nLast, we want to ensure that our surfaces are topologically valid/simple.\n\nTo ensure this, we can pass our surfaces through st_cast.\nRemember that casting an object explicitly (e.g.¬†st_cast(x, \"POINT\")) changes a geometry\nIf no output type is specified (e.g.¬†st_cast(x)) then the cast attempts to simplify the geometry.\nIf you don‚Äôt do this you might get unexpected ‚ÄúTopologyException‚Äù errors.\n\n\ngrid = st_make_grid(counties, n = 70) %&gt;% \n  st_as_sf() %&gt;% \n  st_cast() %&gt;% \n  mutate(id = 1:n())\n\nhex = st_make_grid(counties, n = 70, square = FALSE) %&gt;% \n  st_as_sf() %&gt;% \n  st_cast() %&gt;% \n  mutate(id = 1:n())\n\n# Triangulation (of centroids)\ntri = st_triangulate(centroids) %&gt;% \n  st_as_sf() %&gt;% \n  st_cast() %&gt;% \n  mutate(id = 1:n())\n\n# Voroni tessellation (of centroids)\nvor = st_voronoi(centroids)  %&gt;%\n  st_as_sf() %&gt;% \n  st_cast() %&gt;% \n  mutate(id = 1:n())\n\n\n\nStep 1.4\nIf you plot the above tessellations you‚Äôll see the triangulated surfaces produce regions far beyond the boundaries of CONUS.\nWe need to cut these boundaries to CONUS border.\nTo do this, we will call on st_intersection, but will first need a geometry of CONUS to serve as our differencing feature. We can get this by unioning our existing county boundaries.\n\n# Generate simplified CONUS boundary\nusa_u = st_union(counties) \n\n\n\nStep 1.5\nWith a single feature boundary, we must carefully consider the complexity of the geometry. Remember, the more points our geometry contains, the more computations needed for spatial predicates our differencing. For a task like ours, we do not need a finely resolved coastal boarder.\nTo achieve this:\n\nSimplify your unioned border using the Visvalingam algorithm provided by rmapshaper::ms_simplify.\nChoose what percentage of vertices to retain using the keep argument and work to find the highest number that provides a shape you are comfortable with for the analysis:\n\n\nusa = rmapshaper::ms_simplify(usa_u, keep = .05)\n\n\nOnce you are happy with your simplification, use the mapview::npts function to report the number of points in your original object, and the number of points in your simplified object.\nHow many points were you able to remove? What are the consequences of doing this computationally?\n\n\nmapview::npts(usa_u)\n\n[1] 11292\n\nmapview::npts(usa)\n\n[1] 577\n\n\n\nFinally, use your simplified object to crop the two triangulated tessellations with st_intersection:\n\n\nvor_crop  = st_intersection(vor, usa) \n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\ntri_crop  = st_intersection(tri, usa) \n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\nhex_crop  = st_filter(hex, usa) \ngrid_crop = st_filter(grid, usa) \n\n\n\nStep 1.6\nThe last step is to plot your tessellations. We don‚Äôt want to write out 5 ggplots (or mindlessly copy and paste üòÑ)\nInstead, lets make a function that takes an sf object as arg1 and a character string as arg2 and returns a ggplot object showing arg1 titled with arg2.\n\nThe form of a function is:\n\nname = function(arg1, arg2) {\n  \n  ... code goes here ...\n  \n  }\n\n\nFor this function:\n\nThe name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string that will title the plot\nIn your function, the code should follow our standard ggplot practice where your data is arg1, and your title is arg2\nThe function should also enforce the following:\n\na white fill\na navy border\na size of 0.2\n`theme_void``\na caption that reports the number of features in arg1\n\nYou will need to paste character stings and variables together.\n\n\n\n\nplot_tess = function(data, title){\n  ggplot() + \n    geom_sf(data = data, fill = \"white\", col = \"navy\", size = .2) +   \n    theme_void() +\n    labs(title = title, caption = paste(\"This tesselation has:\", nrow(data), \"tiles\" )) +\n    theme(plot.title = element_text(hjust = .5, color =  \"navy\", face = \"bold\"))\n}\n\n\n\nStep 1.7\nUse your new function to plot each of your tessellated surfaces and the original county data (5 plots in total):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2:\nIn this question, we will write out a function to summarize our tessellated surfaces. Most of this should have been done in your daily assignments.\n\nStep 2.1\nFirst, we need a function that takes a sf object and a character string and returns a data.frame.\nFor this function:\n\nThe function name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string describing the object\nIn your function, calculate the area of arg1; convert the units to km2; and then drop the units\nNext, create a data.frame containing the following:\n\ntext from arg2\nthe number of features in arg1\nthe mean area of the features in arg1 (km2)\nthe standard deviation of the features in arg1\nthe total area (km2) of arg1\n\nReturn this data.frame\n\n\nsum_tess = function(data, type){\n  areakm2 = drop_units(set_units(st_area(data), \"km2\"))\n  data.frame(type = type, count = length(areakm2),  mean = round(mean(areakm2), 2),  sd = round(sd(areakm2),2), tot = round(sum(areakm2), 2))\n}\n\n\n\nStep 2.2\nUse your new function to summarize each of your tessellations and the original counties.\n\n\nStep 2.3\nMultiple data.frame objects can bound row-wise with bind_rows into a single data.frame\nFor example, if your function is called sum_tess, the following would bind your summaries of the triangulation and voroni object.\n\ntess_summary = bind_rows(\n  sum_tess(triangulation ,\"triangulation\"),\n  sum_tess(voroni, \"voroni\"))\n\n\n\nStep 2.4\nOnce your 5 summaries are bound (2 tessellations, 2 coverage‚Äôs, and the raw counties) print the data.frame as a nice table using knitr/kableExtra.\n\n\ntypecountmeansdtottriangulation6,1981,290.371,598.407,997,700voroni3,1082,604.432,917.828,094,557counties3,1082,605.053,443.718,096,496grid3,1302,761.290.008,642,833Hexagon2,3083,781.180.008,726,961\n\n\n\n\nStep 2.5\nComment on the traits of each tessellation. Be specific about how these traits might impact the results of a point-in-polygon analysis in the contexts of the modifiable areal unit problem and with respect computational requirements.\n\n\n\n\nQuestion 3:\nThe data we are going to analysis in this lab is from US Army Corp of Engineers National Dam Inventory (NID). This dataset documents ~91,000 dams in the United States and a variety of attribute information including design specifications, risk level, age, and purpose.\nFor the remainder of this lab we will analysis the distributions of these dams (Q3) and their purpose (Q4) through using a point-in-polygon analysis.\n\nStep 3.1\nIn the tradition of this class - and true to data science/GIS work - you need to find, download, and manage raw data. While the raw NID data is no longer easy to get with the transition of the USACE services to ESRI Features Services, I staged the data in the resources directory of this class. To get it, navigate to that location and download the raw file into you lab data directory.\n\nReturn to your RStudio Project and read the data in using the readr::read_csv\n\nAfter reading the data in, be sure to remove rows that don‚Äôt have location values (!is.na())\nConvert the data.frame to a sf object by defining the coordinates and CRS\nTransform the data to a CONUS AEA (EPSG:5070) projection - matching your tessellation\nFilter to include only those within your CONUS boundary\n\n\n\ndams = readr::read_csv('../data/NID2019_U.csv') \n\nRows: 91457 Columns: 69\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (44): DAM_NAME, OTHER_DAM_NAME, DAM_FORMER_NAME, NIDID, SECTION, COUNTY,...\ndbl (24): RECORDID, STATEID, LONGITUDE, LATITUDE, DISTANCE, YEAR_COMPLETED, ...\nlgl  (1): URL_ADDRESS\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndams2 = dams %&gt;% \n  filter(!is.na(LATITUDE) ) %&gt;%\n  st_as_sf(coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4236) %&gt;% \n  st_transform(5070) %&gt;% \n  st_filter(usa)\n\n\n\nStep 3.2\nFollowing the in-class examples develop an efficient point-in-polygon function that takes:\n\npoints as arg1,\npolygons as arg2,\nThe name of the id column as arg3\n\nThe function should make use of spatial and non-spatial joins, sf coercion and dplyr::count. The returned object should be input sf object with a column - n - counting the number of points in each tile.\n\npoint_in_polygon = function(points, polygon, id){\n  st_join(polygon, points) %&gt;% \n    st_drop_geometry() %&gt;% \n    count(.data[[id]]) %&gt;% \n    left_join(polygon) %&gt;% \n    st_as_sf() \n}\n\n\n\nStep 3.3\nApply your point-in-polygon function to each of your five tessellated surfaces where:\n\nYour points are the dams\nYour polygons are the respective tessellation\nThe id column is the name of the id columns you defined.\n\n\nvor_pts    &lt;-  point_in_polygon(points = dams2, polygon = vor_crop, id = \"id\")\n\nJoining with `by = join_by(id)`\n\ngrid_pts   &lt;-  point_in_polygon(dams2, grid_crop, \"id\")\n\nJoining with `by = join_by(id)`\n\ntri_pts    &lt;-  point_in_polygon(dams2, tri_crop, \"id\")\n\nJoining with `by = join_by(id)`\n\ncount_pts  &lt;-  point_in_polygon(dams2, counties, \"fip_code\")\n\nJoining with `by = join_by(fip_code)`\n\nhex_pts    &lt;-  point_in_polygon(dams2, hex_crop, \"id\")\n\nJoining with `by = join_by(id)`\n\n\n\n\nStep 3.4\nLets continue the trend of automating our repetitive tasks through function creation. This time make a new function that extends your previous plotting function.\nFor this function:\n\nThe name can be anything you chose, arg1 should take an sf object, and arg2 should take a character string that will title the plot\nThe function should also enforce the following:\n\nthe fill aesthetic is driven by the count column n\nthe col is NA\nthe fill is scaled to a continuous viridis color ramp\ntheme_void\na caption that reports the number of dams in arg1 (e.g.¬†sum(n))\n\nYou will need to paste character stings and variables together.\n\n\n\n\nmake_plot2 = function(data, title){\n ggplot() + \n    geom_sf(data = data, aes(fill = n), col = NA) +\n    scale_fill_viridis_c() + \n    theme_void() + \n    labs(fill = title,\n         caption = paste(\"There are\", sum(data$n), \" total dams counted\"))\n}\n\n\n\nStep 3.5\nApply your plotting function to each of the 5 tessellated surfaces with Point-in-Polygon counts:\n\n\nStep 3.6\nComment on the influence of the tessellated surface in the visualization of point counts. How does this related to the MAUP problem. Moving forward you will only use one tessellation, which will you chose and why?\nWhile there is not ‚Äúright‚Äù answer, justify your selection here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 4\nThe NID provides a comprehensive data dictionary here. In it we find that dam purposes are designated by a character code.\nThese are shown below for convenience (built using knitr on a data.frame called nid_classifier):\n\n\n\nNID 2019: Dam Purposes\n\n\nabbr\npurpose\n\n\n\n\nI\nIrrigation\n\n\nH\nHydroelectric\n\n\nC\nFlood Control\n\n\nN\nNavigation\n\n\nS\nWater Supply\n\n\nR\nRecreation\n\n\nP\nFire Protection\n\n\nF\nFish and Wildlife\n\n\nD\nDebris Control\n\n\nT\nTailings\n\n\nG\nGrade Stabilization\n\n\nO\nOther\n\n\n\n\n\n\n\n\nIn the data dictionary, we see a dam can have multiple purposes.\nIn these cases, the purpose codes are concatenated in order of decreasing importance. For example, SCR would indicate the primary purposes are Water Supply, then Flood Control, then Recreation.\nA standard summary indicates there are over 400 unique combinations of dam purposes:\n\n\nunique(dams2$PURPOSES) %&gt;% length\n\n[1] 493\n\n\n\nBy storing dam codes as a concatenated string, there is no easy way to identify how many dams serve any one purpose‚Ä¶ for example where are the hydro electric dams?\n\n\nTo overcome this data structure limitation, we can identify how many dams serve each purpose by splitting the PURPOSES values (strsplit) and tabulating the unlisted results as a data.frame. Effectively this is double/triple/quadruple counting dams bases on how many purposes they serve:\n\n\nJoining with `by = join_by(abbr)`\n\n\nThe result of this would indicate:\n\n\n\n\n\n\n\n\n\n\nStep 4.1\n\nYour task is to create point-in-polygon counts for at least 4 of the above dam purposes:\nYou will use grepl to filter the complete dataset to those with your chosen purpose\nRemember that grepl returns a boolean if a given pattern is matched in a string\ngrepl is vectorized so can be used in dplyr::filter\n\n\nFor example:\n\n# Find flood control dams in the first 5 records:\ndams2$PURPOSES[1:5]\n\n[1] \"FR\" \"R\"  \"C\"  \"FR\" \"R\" \n\ngrepl(\"F\", dams2$PURPOSES[1:5])\n\n[1]  TRUE FALSE FALSE  TRUE FALSE\n\n\n\nFor your analysis, choose at least four of the above codes, and describe why you chose them. Then for each of them, create a subset of dams that serve that purpose using dplyr::filter and grepl\nFinally, use your point-in-polygon function to count each subset across your elected tessellation\n\n\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\nJoining with `by = join_by(id)`\n\n\n\n\nStep 4.2\n\nNow use your plotting function from Q3 to map these counts.\nBut! you will use gghighlight to only color those tiles where the count (n) is greater then the (mean + 1 standard deviation) of the set\nSince your plotting function returns a ggplot object already, the gghighlight call can be added ‚Äú+‚Äù directly to the function.\nThe result of this exploration is to highlight the areas of the country with the most\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 4.3\nComment of geographic distribution of dams you found. Does it make sense? How might the tessellation you chose impact your findings? How does the distribution of dams coincide with other geographic factors such as river systems, climate, ect?\n\n\n\nQuestion 5:\nYou have also been asked to identify the largest, at risk, flood control dams in the country\nYou must also map the Mississippi River System - This data is available here under the ‚ÄòData & Resources‚Äô tab - Download the shapefile and unzip it into your data directory. - Use read_sf to import this data and filter it to only include the Mississippi SYSTEM\nTo achieve this:\nCreate an interactive map using leaflet to show the largest (NID_STORAGE); high-hazard (HAZARD == ‚ÄúH‚Äù) dam in each state\n\nThe markers should be drawn as opaque, circle markers, filled red with no border, and a radius set equal to the (NID_Storage / 1,500,000)\nThe map tiles should be selected from any of the tile providers\nA popup table should be added using leafem::popup and should only include the dam name, storage, purposes, and year completed.\nThe Mississippi system should be added at a Polyline feature.\n\n\nlibrary(leaflet)\n\nmiss = read_sf('../../slides/data/majorrivers_0_0/MajorRivers.shp') %&gt;% \n  filter(SYSTEM== \"Mississippi\")\n\nbiggest_dams = dams2 %&gt;% \n  filter(HAZARD == \"H\", grepl(\"C\", PURPOSES)) %&gt;% \n  group_by(STATE) %&gt;% \n  slice_max(NID_STORAGE, n = 2 ) %&gt;% \n  st_transform(4326) %&gt;% \n  mutate(label = paste(DAM_NAME, \"\\n\", PURPOSES)) %&gt;% \n  select(DAM_NAME, NID_STORAGE, PURPOSES, YEAR_COMPLETED)\n\nleaflet() %&gt;% \n  addProviderTiles(providers$CartoDB.Positron) %&gt;% \n  addCircleMarkers(data = biggest_dams, \n                   fillOpacity = 1, \n                   fillColor = \"red\", \n                   color = NA, \n                   radius  = ~NID_STORAGE/15e5,\n                   popup = leafpop::popupTable(st_drop_geometry(biggest_dams),\n                    row.numbers = F, \n                    feature.id  = F)) %&gt;% \n  addPolylines(data = miss)\n\n\n\n\n\n\n\n\nRubric\n\nQuestion 1: Tessellations (30)\nQuestion 2: Tessellation Comparison (30)\nQuestion 3: PIP (30)\nQuestion 4: Conditional PIP (30)\nQuestion 5: Dam Age (20)\nWell Structured and appealing Qmd deployed as web page (10)\n\nTotal: 150\n\n\nSubmission\nYou will submit a URL to your web page deployed with GitHub pages.\nTo do this:\n\nRender your lab document\nStage/commit/push your files\nIf you followed the naming conventions in the ‚ÄúSet Up‚Äù of lab 1, your lab 3 link will be available at:\n\nhttps://USERNAME.github.io/csu-523c/lab-03.html\nSubmit this URL in the appropriate Canvas dropbox. Also take a moment to update your personal webpage with this link and some bullet points of what you learned. While not graded as part of this lab, it will be extra credit!"
  },
  {
    "objectID": "labs/keys/lab4.html#libraries",
    "href": "labs/keys/lab4.html#libraries",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(rstac) # STAC API\nlibrary(terra) # Raster Data handling\nlibrary(sf) # Vector data processing\nlibrary(mapview) # Rapid Interactive visualization\n\nAlmost all remote sensing / image analysis begins with the same basic steps:\n\nIdentify an area of interest (AOI)\nIdentify the temporal range of interest\nIdentify the relevant images\nDownload the images\nAnalyze the products"
  },
  {
    "objectID": "labs/keys/lab4.html#step-1-aoi-identification",
    "href": "labs/keys/lab4.html#step-1-aoi-identification",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Step 1: AOI identification",
    "text": "Step 1: AOI identification\nFirst we need to identify an AOI. We want to be able to extract the flood extents for Palo, Iowa and its surroundings. To do this we will use the geocoding capabilities within the AOI package.\n\npalo &lt;- AOI::geocode(\"Palo, Iowa\", bbox = TRUE)\n\nThis region defines the AOI for this analysis."
  },
  {
    "objectID": "labs/keys/lab4.html#step-2-temporal-identification",
    "href": "labs/keys/lab4.html#step-2-temporal-identification",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Step 2: Temporal identification",
    "text": "Step 2: Temporal identification\nThe flood event occurred on September 26, 2016. A primary challenge with remote sensing is the fact that all satellite imagery is not available at all times. In this case Landsat 8 has an 8 day revisit time. To ensure we capture an image within the date of the flood, lets set our time range to the period between September 24th - 29th of 2016. We will define this duration in the form YYYY-MM-DD/YYYY-MM-DD.\n\ntemporal_range &lt;- \"2016-09-24/2016-09-29\""
  },
  {
    "objectID": "labs/keys/lab4.html#step-3-identifying-the-relevant-images",
    "href": "labs/keys/lab4.html#step-3-identifying-the-relevant-images",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Step 3: Identifying the relevant images",
    "text": "Step 3: Identifying the relevant images\nThe next step is to identify the images that are available for our AOI and time range. This is where the rstac package comes in. The rstac package provides a simple interface to the SpatioTemporal Asset Catalog (STAC) API, which is a standard for discovering and accessing geospatial data.\nSTAC is a specification for describing geospatial data in a consistent way, making it easier to discover and access datasets. It provides a standardized way to describe the metadata of geospatial assets, including their spatial and temporal extents, data formats, and other relevant information.\n\nCatalog: A catalog is a collection of STAC items and collections. It serves as a top-level container for organizing and managing geospatial data. A catalog can contain multiple collections, each representing a specific dataset or group of related datasets.\nItems: The basic unit of data in STAC. Each item represents a single asset, such as a satellite image or a vector dataset. Items contain metadata that describes the asset, including its spatial and temporal extents, data format, and other relevant information.\nAsset: An asset is a specific file or data product associated with an item. For example, a single satellite image may have multiple assets, such as different bands or processing levels. Assets are typically stored in a cloud storage system and can be accessed via URLs.\n\nFor this project we are going to use a STAC catalog to identify the data available for our analysis. We want data from the Landsat 8 collection which is served by the USGS (via AWS), Google, and Microsoft Planetary Computer (MPC). MPC is the one that provides free access so we will use that data store.\nIf you go to this link you see the JSON representation of the full data holdings. If you CMD/CTL+F on that page for Landsat you‚Äôll find the references for the available data stores.\nWithin R, we can open a connection to this endpoint with the stac function:\n\n# Open a connection to the MPC STAC API\n(stac_query &lt;- stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\"))\n\n###rstac_query\n- url: https://planetarycomputer.microsoft.com/api/stac/v1/\n- params:\n- field(s): version, base_url, endpoint, params, verb, encode\n\n\nThat connection will provide an open entry to ALL data hosted by MPC. The stac_search function allows us to reduce the catalog to assets that match certain criteria (just like dplyr::filter reduces a data.frame). The get_request() function sends your search to the STAC API returning the metadata about the objects that match a criteria. The service implementation at MPC sets a return limit of 250 items (but it could be overridden with the limit parameter).\nHere, we are interested in the ‚ÄúLandsat Collection 2 Level-2‚Äù data. From the JSON file (seen in the browser). To start, lets search for that collection using the stac -&gt; stac_search ‚Äì&gt; get_request workflow:\n\n(stac_query &lt;-stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt; \n  stac_search(\n    collections = \"landsat-c2-l2\") |&gt; \n  get_request())\n\n###Items\n- features (250 item(s)):\n  - LC09_L2SR_093057_20250331_02_T1\n  - LC09_L2SR_093056_20250331_02_T1\n  - LC09_L2SR_093055_20250331_02_T2\n  - LC09_L2SR_093054_20250331_02_T2\n  - LC09_L2SR_093022_20250331_02_T2\n  - LC09_L2SP_093018_20250331_02_T1\n  - LC09_L2SP_093017_20250331_02_T1\n  - LC09_L2SP_093016_20250331_02_T1\n  - LC09_L2SP_093015_20250331_02_T1\n  - LC09_L2SP_093014_20250331_02_T2\n  - ... with 240 more feature(s).\n- assets: \nang, atran, blue, cdist, coastal, drad, emis, emsd, green, lwir11, mtl.json, mtl.txt, mtl.xml, nir08, qa, qa_aerosol, qa_pixel, qa_radsat, red, rendered_preview, swir16, swir22, tilejson, trad, urad\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nAwesome! So the first 250 items from the Level-2 Landsat collection were returned. Within each item, there are a number of assets (e.g.¬†the red, green, blue bands) and all items have some associated fields like the sub item assets, the bounding box, etc. We can now refine our search to limit the returned results to those that cover our AOI and time range of interest:\n\n(stac_query &lt;- stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt; \n  stac_search(\n    collections = \"landsat-c2-l2\",\n    datetime    = temporal_range,\n    bbox        = st_bbox(palo)) |&gt; \n  get_request())\n\n###Items\n- features (2 item(s)):\n  - LC08_L2SP_025031_20160926_02_T1\n  - LE07_L2SP_026031_20160925_02_T1\n- assets: \nang, atmos_opacity, atran, blue, cdist, cloud_qa, coastal, drad, emis, emsd, green, lwir, lwir11, mtl.json, mtl.txt, mtl.xml, nir08, qa, qa_aerosol, qa_pixel, qa_radsat, red, rendered_preview, swir16, swir22, tilejson, trad, urad\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nBy adding these constraints, we now see just two items. One from the Landsat 7 Level 2 dataset, and one from the Landsat 8 Level 2 dataset. For this lab, lets focus on the Landsat 8 item. We can use either the item or the id search criteria to elect this:\n\n(stac_query &lt;- stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt; \n  stac_search(\n    collections = \"landsat-c2-l2\",\n    datetime    = temporal_range,\n    bbox        = st_bbox(palo),\n    limit = 1) |&gt; \n  get_request())\n\n###Items\n- features (1 item(s)):\n  - LC08_L2SP_025031_20160926_02_T1\n- assets: \nang, atran, blue, cdist, coastal, drad, emis, emsd, green, lwir11, mtl.json, mtl.txt, mtl.xml, nir08, qa, qa_aerosol, qa_pixel, qa_radsat, red, rendered_preview, swir16, swir22, tilejson, trad, urad\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n## OR ## \n\n(stac_query &lt;- stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt; \n  stac_search(\n    id = 'LC08_L2SP_025031_20160926_02_T1',\n    collections = \"landsat-c2-l2\",\n    datetime    = temporal_range,\n    bbox        = st_bbox(palo)) |&gt; \n  get_request())\n\n###Items\n- features (1 item(s)):\n  - LC08_L2SP_025031_20160926_02_T1\n- assets: \nang, atran, blue, cdist, coastal, drad, emis, emsd, green, lwir11, mtl.json, mtl.txt, mtl.xml, nir08, qa, qa_aerosol, qa_pixel, qa_radsat, red, rendered_preview, swir16, swir22, tilejson, trad, urad\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type\n\n\nThe last thing we need to do, is sign this request. In rstac, items_sign(sign_planetary_computer()) signs STAC item asset URLs retrieved from Microsoft‚Äôs Planetary Computer, ensuring they include authentication tokens for access. sign_planetary_computer() generates the necessary signing function, and items_sign() applies it to STAC items. This is essential for accessing datasets hosted on the Planetary Computer, and other catalog were data access might be requester-paid or limited.\n\n(stac_query &lt;- stac(\"https://planetarycomputer.microsoft.com/api/stac/v1\") |&gt; \n  stac_search(\n    collections = \"landsat-c2-l2\",\n    datetime    = temporal_range,\n    bbox        = st_bbox(palo),\n    limit = 1) |&gt; \n  get_request() |&gt; \n  items_sign(sign_planetary_computer()))\n\n###Items\n- features (1 item(s)):\n  - LC08_L2SP_025031_20160926_02_T1\n- assets: \nang, atran, blue, cdist, coastal, drad, emis, emsd, green, lwir11, mtl.json, mtl.txt, mtl.xml, nir08, qa, qa_aerosol, qa_pixel, qa_radsat, red, rendered_preview, swir16, swir22, tilejson, trad, urad\n- item's fields: \nassets, bbox, collection, geometry, id, links, properties, stac_extensions, stac_version, type"
  },
  {
    "objectID": "labs/keys/lab4.html#step-4-downloading-needed-images",
    "href": "labs/keys/lab4.html#step-4-downloading-needed-images",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Step 4: Downloading needed images",
    "text": "Step 4: Downloading needed images\nOK! Now that we have identified the item we want, we are ready to download the data using assets_download(). In total, a Landsat 8 item has the following 11 bands:\n\nknitr::include_graphics(\"../images/lsat8-bands.jpg\")\n\n\n\n\n\n\n\n\nFor this lab, lets just get the first 6 bands. Assets are extracted from a STAC item by the asset name (look at the print statements of the stac_query). Let‚Äôs define a vector of the assets we want:\n\n# Bands 1-6\nbands &lt;- c('coastal', 'blue', 'green', 'red', 'nir08', 'swir16')\n\nNow we can use the assets_download() function to download the data. The output_dir argument specifies where to save the files, and the overwrite argument specifies whether to overwrite existing files with the same name.\n\nassets_download(items = stac_query,\n                asset_names = bands, \n                output_dir = '../data', \n                overwrite = TRUE)\n\nAnd that does it! You now have the process needed to get you data.\nWith a set of local files, you can create a raster object! Remember your files need to be in the order of the bands (double check step 2).\n\nlist.files() can search a directory for a pattern and return a list of files. The recursive argument will search all sub-directories. The full.names argument will return the full path to the files.\nThe rast() function will read the files into a raster object.\nThe setNames() function will set the names of the bands to the names we defined above.\n\n\nls &lt;- list.files(\"../data\", \"LC08_L2SP_025031_20160926\", recursive = TRUE, full.names = TRUE) |&gt; \n  rast() |&gt;  \n  setNames(bands)"
  },
  {
    "objectID": "labs/keys/lab4.html#step-5-analyize-the-images",
    "href": "labs/keys/lab4.html#step-5-analyize-the-images",
    "title": "Lab 4: Rasters & Remote Sensing",
    "section": "Step 5: Analyize the images",
    "text": "Step 5: Analyize the images\nWe only want to analyze our image for the regions surrounding Palo (our AOI). Transform your AOI to the CRS of the landsat stack and use it to crop your raster stack.\n\nbbox &lt;- st_buffer(palo, 5000) |&gt; \n  st_transform(crs(ls))\n\npalo_ls = crop(ls, bbox)\n\nAwesome! We have now (1) identified, (2) downloaded, and (3) saved our images.\nWe have loaded them as a multiband SpatRast object and cropped the domain to our AOI. Lets make a few RGB plots to see what these images reveal.\n\n\n\n\n\n\nNote\n\n\n\nThere are many online examples that discuss the applications of the available bands in Landsat. What we want to do here is simply show how loading different combinations into the RGB channels make different features stand out. A useful reference of popular band combinations is here."
  },
  {
    "objectID": "labs/keys/lab5-key.html#libraries",
    "href": "labs/keys/lab5-key.html#libraries",
    "title": "Lab 5: Terrain Processing and OSM",
    "section": "Libraries",
    "text": "Libraries\nAttach your needed libraries:\n\nlibrary(sf)       # vector manipulation\nlibrary(terra)    # raster manipulation\n\nterra 1.8.29\n\nlibrary(whitebox) # terrain analysis\n\n# Data libraries\nlibrary(osmdata)  # OSM API\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\n\nlibrary(elevatr)  # Elevation Web Tiles\n\nelevatr v0.99.0 NOTE: Version 0.99.0 of 'elevatr' uses 'sf' and 'terra'.  Use \nof the 'sp', 'raster', and underlying 'rgdal' packages by 'elevatr' is being \ndeprecated; however, get_elev_raster continues to return a RasterLayer.  This \nwill be dropped in future versions, so please plan accordingly."
  },
  {
    "objectID": "labs/keys/lab5-key.html#flooding-jargon",
    "href": "labs/keys/lab5-key.html#flooding-jargon",
    "title": "Lab 5: Terrain Processing and OSM",
    "section": "Flooding Jargon",
    "text": "Flooding Jargon\n\nstage = height of the water in a channel\nstreamflow = the rate of water flowing in a channel\nbasin = an area in which all cells contribute to a common outlet (an area or ridge of land that separates waters flowing to different rivers, basins, or seas)\nflowpath = the linear path over which water flows (river)\nHAND = Height Above Nearest Drainage, ‚Äúhow high is a cell above its nearest river cell?‚Äù"
  },
  {
    "objectID": "labs/keys/lab6-key.html",
    "href": "labs/keys/lab6-key.html",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "In this lab, we will explore predictive modeling in hydrology using the tidymodels framework and the CAMELS (Catchment Attributes and Meteorology for Large-sample Studies) dataset.\n\n\n\n\n\n\n\n\n\n\n\ntidymodels is an R framework designed for machine learning and statistical modeling. Built on the principles of the tidyverse, tidymodels provides a consistent and modular approach to tasks like data preprocessing, model training, evaluation, and validation. By leveraging the strengths of packages such as recipes, parsnip, and yardstick, tidymodels streamlines the modeling workflow, making it easier to experiment with different models while maintaining reproducibility and interpretability.\n\n\n\nThe CAMELS dataset is a widely used resource in hydrology and environmental science, providing data on over 500 self-draining river basins across the United States. It includes meteorological forcings, streamflow observations, and catchment attributes such as land cover, topography, and soil properties. This dataset is particularly valuable for large-sample hydrology studies, enabling researchers to develop and test models across diverse climatic and physiographic conditions.\nIn this lab, we will focus on predicting mean streamflow for these basins using their associated characteristics. CAMELS has been instrumental in various hydrologic and machine learning applications, including:\n\nCalibrating Hydrologic Models ‚Äì Used for parameter tuning in models like SAC-SMA, VIC, and HBV, improving regional and large-sample studies.\nTraining Machine Learning Models ‚Äì Supports deep learning (e.g., LSTMs) and regression-based streamflow predictions, often outperforming traditional methods.\nUnderstanding Model Behavior ‚Äì Assists in assessing model generalization, uncertainty analysis, and the role of catchment attributes.\nBenchmarking & Regionalization ‚Äì Facilitates large-scale model comparisons and parameter transfer to ungauged basins.\nHybrid Modeling ‚Äì Enhances physics-based models with machine learning for bias correction and improved hydrologic simulations.\n\nA notable study by Kratzert et al.¬†(2019) demonstrated that LSTMs can outperform conceptual models in streamflow prediction. As part of this lab, we will explore how to programmatically download and load the data into R."
  },
  {
    "objectID": "labs/keys/lab6-key.html#what-is-tidymodels",
    "href": "labs/keys/lab6-key.html#what-is-tidymodels",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "tidymodels is an R framework designed for machine learning and statistical modeling. Built on the principles of the tidyverse, tidymodels provides a consistent and modular approach to tasks like data preprocessing, model training, evaluation, and validation. By leveraging the strengths of packages such as recipes, parsnip, and yardstick, tidymodels streamlines the modeling workflow, making it easier to experiment with different models while maintaining reproducibility and interpretability."
  },
  {
    "objectID": "labs/keys/lab6-key.html#what-is-the-camels-dataset",
    "href": "labs/keys/lab6-key.html#what-is-the-camels-dataset",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "The CAMELS dataset is a widely used resource in hydrology and environmental science, providing data on over 500 self-draining river basins across the United States. It includes meteorological forcings, streamflow observations, and catchment attributes such as land cover, topography, and soil properties. This dataset is particularly valuable for large-sample hydrology studies, enabling researchers to develop and test models across diverse climatic and physiographic conditions.\nIn this lab, we will focus on predicting mean streamflow for these basins using their associated characteristics. CAMELS has been instrumental in various hydrologic and machine learning applications, including:\n\nCalibrating Hydrologic Models ‚Äì Used for parameter tuning in models like SAC-SMA, VIC, and HBV, improving regional and large-sample studies.\nTraining Machine Learning Models ‚Äì Supports deep learning (e.g., LSTMs) and regression-based streamflow predictions, often outperforming traditional methods.\nUnderstanding Model Behavior ‚Äì Assists in assessing model generalization, uncertainty analysis, and the role of catchment attributes.\nBenchmarking & Regionalization ‚Äì Facilitates large-scale model comparisons and parameter transfer to ungauged basins.\nHybrid Modeling ‚Äì Enhances physics-based models with machine learning for bias correction and improved hydrologic simulations.\n\nA notable study by Kratzert et al.¬†(2019) demonstrated that LSTMs can outperform conceptual models in streamflow prediction. As part of this lab, we will explore how to programmatically download and load the data into R."
  },
  {
    "objectID": "labs/keys/lab6-key.html#lab-goals",
    "href": "labs/keys/lab6-key.html#lab-goals",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Lab Goals",
    "text": "Lab Goals\nIn this lab, you will:\n\nLearn how to programatically download and access data.\nPractice using tidymodels for predictive modeling.\nTrain and evaluate models to predict mean streamflow across the country.\nInterpret and compare model performance using workflows.\n\nBy the end of this lab, you will have hands-on experience applying machine learning techniques to real-world data, helping to bridge the gap between statistical modeling and environmental science."
  },
  {
    "objectID": "labs/keys/lab6-key.html#data-download",
    "href": "labs/keys/lab6-key.html#data-download",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Data Download",
    "text": "Data Download\nThe CAMELS dataset is hosted by NCAR and can be accessed here under the ‚ÄúIndividual Files‚Äù section. The root URL for all data seen on the ‚ÄúIndividual Files‚Äù page is:\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\nNear the bottom of that page, there are many .txt files that contain the data we want. Some hold climate data for each basin, some hold geology data, some hold soil data, etc. There is also a PDF with descriptions of the columns in each file. We are going to download all of the .txt files and the PDF."
  },
  {
    "objectID": "labs/keys/lab6-key.html#getting-the-documentation-pdf",
    "href": "labs/keys/lab6-key.html#getting-the-documentation-pdf",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Getting the documentation PDF",
    "text": "Getting the documentation PDF\nWe can download the documentation PDF which provides a descriptions for the various columns as many are not self-explanatory. Here we can use download.file to download the PDF to our data directory.\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              '../data/camels_attributes_v2.0.pdf')"
  },
  {
    "objectID": "labs/keys/lab6-key.html#getting-basin-characteristics",
    "href": "labs/keys/lab6-key.html#getting-basin-characteristics",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Getting Basin characteristics",
    "text": "Getting Basin characteristics\nNow we want to download the .txt files that store the actual data documented in the PDF. Doing this file by file (like we did with the PDF) is possible, but lets look at a better/easier way‚Ä¶\n\nLets create a vector storing the data types/file names we want to download:\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n\n\n\n\n\n\nglue\n\n\n\n\n\nThe glue package provides an efficient way to interpolate and manipulate strings. It is particularly useful for dynamically constructing text, formatting outputs, and embedding R expressions within strings.\n\nKey Features of glue:\n\nString Interpolation: Embed R expressions inside strings using {}.\nImproved Readability: Eliminates the need for cumbersome paste(), paste0() and sprintf() commands.\nMulti-line Strings: Easily handle multi-line text formatting.\nSafe and Efficient: Optimized for performance and readability.\n\n\n\nBasic Usage\n\nTo use glue, you need to load the package and then call the glue() function with the desired string template. You can embed R expressions within curly braces {} to interpolate values into the string.\n\n\nclass &lt;- \"ESS 330\"\nyear  &lt;- 2024\n\nglue(\"We are taking {class} together in {year}\")\n\nWe are taking ESS 330 together in 2024\n\n\n\n\nMultiples\n\nYou can also use glue to interpolate multiple values at once\n\n\nclasses &lt;- c(\"ESS 330\", \"ESS 523c\")\n\nglue(\"We are taking {classes} together in {year}\")\n\nWe are taking ESS 330 together in 2024\nWe are taking ESS 523c together in 2024\n\n\n\n\n\n\n\nUsing glue, we can construct the needed URLs and file names for the data we want to download:\n\n\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('../data/camels_{types}.txt')\n\n\nNow we can download the data: walk2 comes from the purrr package and is used to apply a function to multiple arguments in parallel (much like map2 works over paired lists). Here, we are asking walk2 to pass the first element of remote_files and the first element of local_files to the download.file function to download the data, and setting quiet = TRUE to suppress output. The process is then iterated for the second element of each vector, and so on.\n\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n\nOnce downloaded, the data can be read it into R using readr::read_delim(), again instead of applying this to each file individually, we can use map to apply the function to each element of the local_files list.\n\n\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\n\nThis gives us a list of data.frames, one for each file that we want to merge into a single table. So far in class we have focused on *_join functions to merge data based on a primary and foreign key relationship.\n\nIn this current list, we have &gt;2 tables, but, have a shared column called gauge_id that we can use to merge the data. However, since we have more then a left and right hand table, we need a more robust tool. We will use the powerjoin package to merge the data into a single data frame. powerjoin is a flexible package for joining lists of data.frames. It provides a wide range of join types, including inner, left, right, full, semi, anti, and cross joins making it a versatile tool for data manipulation and analysis, and one that should feel familiar to users of dplyr.\nIn this case, we are join to merge every data.frame in the list (n = 6) by the shared gauge_id column. Since we want to keep all data, we want a full join.\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\n\n\n\n\n\nNote\n\n\n\nAlternatively, we could have read straight form the urls. Strongly consider the implications of this approach as the longevity and persistence of the data is not guaranteed.\n\n# Read and merge data\ncamels &lt;- map(remote_files, read_delim, show_col_types = FALSE) |&gt; \n  power_full_join(by = 'gauge_id')"
  },
  {
    "objectID": "labs/keys/lab6-key.html#exploratory-data-analysis",
    "href": "labs/keys/lab6-key.html#exploratory-data-analysis",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nFirst, lets make a map of the sites. Use the borders() ggplot function to add state boundaries to the map and initially color the points by the mean flow (q_mean) at each site.\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\nWe can take a moment here to are learn a few new things about ggplot2!\n\n\n\n\n\n\nColor scales\n\n\n\nIn ggplot, sometimes you want different things (like bars, dots, or lines) to have different colors. But how does R know which colors to use? That‚Äôs where color scales come in!\nscales can be used to map data values to colors (scale_color_*) or fill aesthetics (scale_fill_*). There are two main types of color scales:\n\nDiscrete color scales ‚Äì for things that are categories, like ‚Äúapples,‚Äù ‚Äúbananas,‚Äù and ‚Äúcherries.‚Äù Each gets its own separate color.\n\n\nscale_color_manual(values = c(\"red\", \"yellow\", \"pink\")) #lets you pick your own colors.\n\nOr\n\nscale_color_brewer(palette = \"Set1\") #uses a built-in color set.\n\n\nContinuous color scales ‚Äì for numbers, like temperature (cold to hot) or height (short to tall). The color changes smoothly.\n\n\nscale_color_gradient(low = \"blue\", high = \"red\") #makes small numbers blue and big numbers red."
  },
  {
    "objectID": "labs/keys/lab6-key.html#visual-eda",
    "href": "labs/keys/lab6-key.html#visual-eda",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Visual EDA",
    "text": "Visual EDA\n\nLets start by looking that the 3 dimensions (variables) of this data. We‚Äôll start with a XY plot of aridity and rainfall. We are going to use the scale_color_viridis_c() function to color the points by the q_mean column. This scale functions maps the color of the points to the values in the q_mean column along the viridis continuous (c) palette. Because a scale_color_* function is applied, it maps to the known color aesthetic in the plot.\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOk! so it looks like there is a relationship between rainfall, aridity, and rainfall but it looks like an exponential decay function and is certainly not linear.\nTo test a transformation, we can log transform the x and y axes using the scale_x_log10() and scale_y_log10() functions:\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nGreat! We can see a log-log relationship between aridity and rainfall provides a more linear relationship. This is a common relationship in hydrology and is often used to estimate rainfall in ungauged basins. However, once the data is transformed, the lack of spread in the streamflow data is quite evident with high mean flow values being compressed to the low end of aridity/high end of rainfall.\nTo address this, we can visualize how a log transform may benifit the q_mean data as well. Since the data is represented by color, rather then an axis, we can use the trans (transform) argument in the scale_color_viridis_c() function to log transform the color scale.\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nExcellent! Treating these three right skewed variables as log transformed, we can see a more evenly spread relationship between aridity, rainfall, and mean flow. This is a good sign for building a model to predict mean flow using aridity and rainfall."
  },
  {
    "objectID": "labs/keys/lab6-key.html#lets-start-by-splitting-the-data",
    "href": "labs/keys/lab6-key.html#lets-start-by-splitting-the-data",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Lets start by splitting the data",
    "text": "Lets start by splitting the data\nFirst, we set a seed for reproducabilty, then transform the q_mean column to a log scale. Remember it is error prone to apply transformations to the outcome variable within a recipe. So, we‚Äôll do it a prioi.\nOnce set, we can split the data into a training and testing set. We are going to use 80% of the data for training and 20% for testing with no stratification.\nAdditionally, we are going to create a 10-fold cross validation dataset to help us evaluate multi-model setups.\n\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)"
  },
  {
    "objectID": "labs/keys/lab6-key.html#preprocessor-recipe",
    "href": "labs/keys/lab6-key.html#preprocessor-recipe",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Preprocessor: recipe",
    "text": "Preprocessor: recipe\nIn lecture, we have focused on using formulas as a workflow preprocessor. Separately we have used the recipe function to define a series of data preprocessing steps. Here, we are going to use the recipe function to define a series of data preprocessing steps.\nWe learned quite a lot about the data in the visual EDA. We know that the q_mean, aridity and p_mean columns are right skewed and can be helped by log transformations. We also know that the relationship between aridity and p_mean is non-linear and can be helped by adding an interaction term to the model. To implement these, lets build a recipe!\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())"
  },
  {
    "objectID": "labs/keys/lab6-key.html#naive-base-lm-approach",
    "href": "labs/keys/lab6-key.html#naive-base-lm-approach",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Naive base lm approach:",
    "text": "Naive base lm approach:\nOk, to start, lets do what we are comfortable with ‚Ä¶ fitting a linear model to the data. First, we use prep and bake on the training data to apply the recipe. Then, we fit a linear model to the data.\n\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n# Sanity Interaction term from recipe ... these should be equal!!\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "labs/keys/lab6-key.html#where-things-get-a-little-messy",
    "href": "labs/keys/lab6-key.html#where-things-get-a-little-messy",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Where things get a little messy‚Ä¶",
    "text": "Where things get a little messy‚Ä¶\nOk so now we have our trained model lm_base and want to validate it on the test data.\n\nRemember a models ability to predict on new data is the most important part of the modeling process. It really doesnt matter how well it does on data it has already seen!\n\nWe have to be careful about how we do this with the base R approach:\n\nWrong version 1: augment\nThe broom package provides a convenient way to extract model predictions and residuals. We can use the augment function to add predicted values to the test data. However, if we use augment directly on the test data, we will get incorrect results because the preprocessing steps defined in the recipe object have not been applied to the test data.\n\nnrow(camels_test)\n\n[1] 135\n\nnrow(camels_train)\n\n[1] 536\n\nbroom::augment(lm_base, data = camels_test)\n\nError in `$&lt;-`:\n! Assigned data `predict(x, na.action = na.pass, ...) %&gt;% unname()` must\n  be compatible with existing data.\n‚úñ Existing data has 135 rows.\n‚úñ Assigned data has 535 rows.\n‚Ñπ Only vectors of size 1 are recycled.\nCaused by error in `vectbl_recycle_rhs_rows()`:\n! Can't recycle input of size 535 to size 135.\n\n\n\n\nWrong version 2: predict\nThe predict function can be used to make predictions on new data. However, if we use predict directly on the test data, we will get incorrect results because the preprocessing steps defined in the recipe object have not been applied to the test data.\n\ncamels_test$p2 = predict(lm_base, newdata = camels_test)\n\n## Scales way off!\nggplot(camels_test, aes(x = p2, y = logQmean)) + \n  geom_point() + \n  # Linear fit line, no error bands\n  geom_smooth(method = \"lm\", se = FALSE, size =1) +\n  # 1:1 line\n  geom_abline(color = \"red\", size = 1) + \n  labs(title = \"Linear Model Using `predict()`\",\n       x = \"Predicted Log Mean Flow\",\n       y = \"Observed Log Mean Flow\") + \n  theme_linedraw()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCorrect version: prep -&gt; bake -&gt; predict\nTo correctly evaluate the model on the test data, we need to apply the same preprocessing steps to the test data that we applied to the training data. We can do this using the prep and bake functions with the recipe object. This ensures the test data is transformed in the same way as the training data before making predictions.\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)"
  },
  {
    "objectID": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual",
    "href": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: statistical and visual",
    "text": "Model Evaluation: statistical and visual\nNow that we have the predicted values, we can evaluate the model using the metrics function from the yardstick package. This function calculates common regression metrics such as RMSE, R-squared, and MAE between the observed and predicted values.\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\nOk so that was a bit burdensome, is really error prone (fragile), and is worthless if we wanted to test a different algorithm‚Ä¶ lets look at a better approach!"
  },
  {
    "objectID": "labs/keys/lab6-key.html#using-a-workflow-instead",
    "href": "labs/keys/lab6-key.html#using-a-workflow-instead",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Using a workflow instead",
    "text": "Using a workflow instead\ntidymodels provides a framework for building and evaluating models using a consistent and modular workflow. The workflows package allows you to define a series of modeling steps, including data preprocessing, model fitting, and model fitting, in a single object. This makes it easier to experiment with different models, compare performance, and ensure reproducibility.\nworkflows are built from a model, a preprocessor, and a execution. Here, we are going to use the linear_reg function to define a linear regression model, set the engine to lm, and the mode to regression. We then add our recipe to the workflow, fit the model to the training data, and extract the model coefficients.\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\nLets ensure we replicated the results from the lm_base model. How do they look to you?\n\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01"
  },
  {
    "objectID": "labs/keys/lab6-key.html#making-predictions",
    "href": "labs/keys/lab6-key.html#making-predictions",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Making Predictions",
    "text": "Making Predictions\nNow that lm_wf is a workflow, data is not embedded in the model, we can use augment with the new_data argument to make predictions on the test data.\n\n#\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  62"
  },
  {
    "objectID": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual-1",
    "href": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual-1",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: statistical and visual",
    "text": "Model Evaluation: statistical and visual\nAs with EDA, applying for graphical and statistical evaluation of the model is a key Here, we use the metrics function to extract the default metrics (rmse, rsq, mae) between the observed and predicted mean streamflow values.\nWe then create a scatter plot of the observed vs predicted values, colored by aridity, to visualize the model performance.\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()"
  },
  {
    "objectID": "labs/keys/lab6-key.html#switch-it-up",
    "href": "labs/keys/lab6-key.html#switch-it-up",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Switch it up!",
    "text": "Switch it up!\nThe real power of this approach is that we can easily switch out the models/recipes and see how it performs. Here, we are going to instead use a random forest model to predict mean streamflow. We define a random forest model using the rand_forest function, set the engine to ranger, and the mode to regression. We then add the recipe, fit the model, and evaluate the skill.\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train)"
  },
  {
    "objectID": "labs/keys/lab6-key.html#predictions",
    "href": "labs/keys/lab6-key.html#predictions",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Predictions",
    "text": "Predictions\n\nMake predictions on the test data using the augment function and the new_data argument.\n\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  61"
  },
  {
    "objectID": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual-2",
    "href": "labs/keys/lab6-key.html#model-evaluation-statistical-and-visual-2",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: statistical and visual",
    "text": "Model Evaluation: statistical and visual\nEvaluate the model using the metrics function and create a scatter plot of the observed vs predicted values, colored by aridity.\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.587\n2 rsq     standard       0.741\n3 mae     standard       0.363\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nAwesome! We just set up a completely new model and were able to utilize all of the things we had done for the linear model. This is the power of the tidymodels framework!\nThat said, we still can reduce some to the repetition. Further, we are not really able to compare these models to one another as they"
  },
  {
    "objectID": "labs/keys/lab6-key.html#a-workflowset-approach",
    "href": "labs/keys/lab6-key.html#a-workflowset-approach",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "A workflowset approach",
    "text": "A workflowset approach\nworkflow_set is a powerful tool for comparing multiple models on the same data. It allows you to define a set of workflows, fit them to the same data, and evaluate their performance using a common metric. Here, we are going to create a workflow_set object with the linear regression and random forest models, fit them to the training data, and compare their performance using the autoplot and rank_results functions.\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 √ó 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ rmse    0.563  0.0247    10 recipe       rand‚Ä¶     1\n2 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ rsq     0.771  0.0259    10 recipe       rand‚Ä¶     1\n3 recipe_linear_reg Prepro‚Ä¶ rmse    0.569  0.0260    10 recipe       line‚Ä¶     2\n4 recipe_linear_reg Prepro‚Ä¶ rsq     0.770  0.0223    10 recipe       line‚Ä¶     2\n\n\nOverall it seems the random forest model is outperforming the linear model. This is not surprising given the non-linear relationship between the predictors and the outcome :)"
  },
  {
    "objectID": "labs/keys/lab6-key.html#hyperparameter-tuning",
    "href": "labs/keys/lab6-key.html#hyperparameter-tuning",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Hyperparameter tuning",
    "text": "Hyperparameter tuning\n\nrf_tune &lt;- rand_forest(mtry = tune(), trees = tune()) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nset.seed(123)\n(rf_res &lt;- tune_grid(rf_tune, rec, resamples = camels_cv, grid = 5))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 √ó 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [482/54]&gt; Fold01 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 2 &lt;split [482/54]&gt; Fold02 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 3 &lt;split [482/54]&gt; Fold03 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 4 &lt;split [482/54]&gt; Fold04 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 5 &lt;split [482/54]&gt; Fold05 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 6 &lt;split [482/54]&gt; Fold06 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 7 &lt;split [483/53]&gt; Fold07 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 8 &lt;split [483/53]&gt; Fold08 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n 9 &lt;split [483/53]&gt; Fold09 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n10 &lt;split [483/53]&gt; Fold10 &lt;tibble [10 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt;\n\nshow_best(rf_res, metric = \"rsq\")\n\n# A tibble: 5 √ó 8\n   mtry trees .metric .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     3  1000 rsq     standard   0.772    10  0.0237 Preprocessor1_Model5\n2     2  2000 rsq     standard   0.772    10  0.0259 Preprocessor1_Model4\n3     1   500 rsq     standard   0.771    10  0.0262 Preprocessor1_Model1\n4     1  1500 rsq     standard   0.770    10  0.0265 Preprocessor1_Model2\n5     2     1 rsq     standard   0.678    10  0.0374 Preprocessor1_Model3"
  },
  {
    "objectID": "labs/keys/lab6-key.html#final-model",
    "href": "labs/keys/lab6-key.html#final-model",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Final Model",
    "text": "Final Model\n\nrf_fin &lt;- rand_forest(mtry = 3, trees = 1000) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nfinal &lt;- workflow() |&gt; \n  add_recipe(rec) |&gt; \n  add_model(rf_fin) |&gt; \n  fit(data = camels_train)"
  },
  {
    "objectID": "labs/keys/lab6-key.html#evaluation",
    "href": "labs/keys/lab6-key.html#evaluation",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Evaluation",
    "text": "Evaluation\nAs a last step, lets evaluate the Random Forest model‚Äôs performance in predicting streamflow using the vip, augment, and ggplot2. We‚Äôll starts by computing variable importance (vip::vip()) to understand which predictors most influence the model.\nNext, we‚Äôll apply the trained model (final) to the test dataset using augment to append predictions to the test data.\nModel performance is then assessed using metrics(), comparing the actual (logQmean) and predicted (.pred) log-transformed mean streamflow values.\nFinally, a scatter plot is generated , visualizing the observed vs.¬†predicted values, color-coded by aridity. The plot includes a 1:1 reference line (geom_abline()) to indicate perfect predictions and uses the viridis color scale to improve readability.\n\n# VIP: \nvip::vip(final)\n\n\n\n\n\n\n\n## Predcition\nrf_data &lt;- augment(final, new_data = camels_test)\n\n## Evaluation\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 √ó 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.619\n2 rsq     standard       0.716\n3 mae     standard       0.385\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  geom_smooth(method = \"lm\", col = 'red', lty = 2, se = FALSE) +\n  theme_linedraw() + \n  labs(title = \"Random Forest Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "labs/keys/lab6-key.html#data-spliting-15",
    "href": "labs/keys/lab6-key.html#data-spliting-15",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Data Spliting (15)",
    "text": "Data Spliting (15)\n\nSet a seed for reproducible\nCreate an initial split with 75% used for training and 25% for testing\nExtract your training and testing sets\nBuild a 10-fold CV dataset as well"
  },
  {
    "objectID": "labs/keys/lab6-key.html#recipe-15",
    "href": "labs/keys/lab6-key.html#recipe-15",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Recipe (15)",
    "text": "Recipe (15)\n\nDefine a formula you want to use to predict logQmean\nDescribe in words why you are choosing the formula you are. Consult the downloaded PDF for the data to help you make this decision.\nBuild a recipe that you feel handles the predictors chosen well"
  },
  {
    "objectID": "labs/keys/lab6-key.html#define-3-models-25",
    "href": "labs/keys/lab6-key.html#define-3-models-25",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Define 3 models (25)",
    "text": "Define 3 models (25)\n\nDefine a random forest model using the rand_forest function\nSet the engine to ranger and the mode to regression\nDefine two other models of your choice"
  },
  {
    "objectID": "labs/keys/lab6-key.html#workflow-set",
    "href": "labs/keys/lab6-key.html#workflow-set",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "workflow set ()",
    "text": "workflow set ()\nWith your preprocessing steps and models defined, you can now build a workflow_set object to fit and evaluate your models. This will allow you to compare the performance of different models on the same data.\n\nCreate a workflow object\nAdd the recipe\nAdd the model(s)\nFit the model to the resamples"
  },
  {
    "objectID": "labs/keys/lab6-key.html#evaluation-1",
    "href": "labs/keys/lab6-key.html#evaluation-1",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Evaluation",
    "text": "Evaluation\n\nUse autoplot and rank_results to compare the models.\nDescribe what model you think is best and why!\n\n\nTune the best model\n\nUse the tune_grid function to tune at least one of the model hyperparameters\nUse show_best to find the best hyperparameter values for the metric of your choic\nUse a workflow to fit your final, tuned, model\n\n\n\nLook at VIP\n\nUse the vip::vip package to visualize the variable importance of your final model\nDescribe what you think of the results and if they make sense\nIf the model you elect cant provide VIP, instead discuss the pros and cons of a less interpretable model"
  },
  {
    "objectID": "labs/keys/lab6-key.html#extact-and-evaluate",
    "href": "labs/keys/lab6-key.html#extact-and-evaluate",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Extact and Evaluate",
    "text": "Extact and Evaluate\n\nUse augment to make predictions on the test data\nUse metrics to evaluate the model performance on the test data\nCreate a plot of the observed vs predicted values with clear title, axis labels, and a compelling color scale\nDescribe what you think of the results!"
  },
  {
    "objectID": "slides/week-3.html#geometric-interiors-boundaries-and-exteriors",
    "href": "slides/week-3.html#geometric-interiors-boundaries-and-exteriors",
    "title": "Week 3",
    "section": "Geometric Interiors, Boundaries and Exteriors",
    "text": "Geometric Interiors, Boundaries and Exteriors\nAll geometries have interior, boundary and exterior regions.\nThe terms interior and boundary are used in the context of algebraic topology and manifold theory and not general topology\nThe OGC has define these states for the common geometry types in the simple features standard:\n\n\n\n\n\n\n\n\n\nDimension\nGeometry Type\nInterior (I)\nBoundary (B)\n\n\n\n\nPoint, MultiPoint\n0\nPoint, Points\nEmpty\n\n\nLineString, Line\n1\nPoints that are left when the boundary points are removed.\nTwo end points.\n\n\nPolygon\n2\nPoints within the rings.\nSet of rings."
  },
  {
    "objectID": "slides/week-3.html#interior-boundary-and-exterior-points",
    "href": "slides/week-3.html#interior-boundary-and-exterior-points",
    "title": "Week 3",
    "section": "Interior, Boundary and Exterior: POINTS",
    "text": "Interior, Boundary and Exterior: POINTS"
  },
  {
    "objectID": "slides/week-3.html#interior-boundary-and-exterior-linestring",
    "href": "slides/week-3.html#interior-boundary-and-exterior-linestring",
    "title": "Week 3",
    "section": "Interior, Boundary and Exterior: LINESTRING",
    "text": "Interior, Boundary and Exterior: LINESTRING"
  },
  {
    "objectID": "slides/week-3.html#predicates",
    "href": "slides/week-3.html#predicates",
    "title": "Week 3",
    "section": "Predicates",
    "text": "Predicates\nIn the following, we are interested in the resulting geometry that occurs when 2 geometries are overlaid‚Ä¶"
  },
  {
    "objectID": "slides/week-3.html#de-9im",
    "href": "slides/week-3.html#de-9im",
    "title": "Week 3",
    "section": "DE-9IM",
    "text": "DE-9IM\n\nDimensionally Extended 9-Intersection Model (DE-9IM)\nThe DE-9IM is a topological model and (standard) used to describe the spatial relations of two geometries\nUsed in geometry, point-set topology, geospatial topology\nThe DE-9IM matrix provides a way to classify geometry relations using the set {0,1,2,F} or {T,F}\nWith a {T,F} matrix domain, there are 512 possible relations that can be grouped into binary classification schemes.\nAbout 10 of these, have been given a common name such as intersects, touches, and within.\nWhen testing two geometries against a scheme, the result is a spatial predicate named by the scheme.\nThe model was developed by Clementini and others based on the seminal works of Egenhofer\nProvides the primary basis for queries and assertions in GIS and spatial databases (PostGIS)."
  },
  {
    "objectID": "slides/week-3.html#binary-logical-operations",
    "href": "slides/week-3.html#binary-logical-operations",
    "title": "Week 3",
    "section": "Binary logical operations",
    "text": "Binary logical operations\nReturns either a sparse matrix\n\nst_intersects(x,y)\n#&gt; Sparse geometry binary predicate list of length 3, where the predicate\n#&gt; was `intersects'\n#&gt;  1: 1, 3\n#&gt;  2: 2, 3\n#&gt;  3: 3\n\nor a dense matrix\n\nst_intersects(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2] [,3]  [,4]\n#&gt; [1,]  TRUE FALSE TRUE FALSE\n#&gt; [2,] FALSE  TRUE TRUE FALSE\n#&gt; [3,] FALSE FALSE TRUE FALSE\n\nst_disjoint(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3] [,4]\n#&gt; [1,] FALSE  TRUE FALSE TRUE\n#&gt; [2,]  TRUE FALSE FALSE TRUE\n#&gt; [3,]  TRUE  TRUE FALSE TRUE\n\nst_touches(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE\n\nst_within(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties",
    "href": "slides/week-3.html#intersecting-counties",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties-1",
    "href": "slides/week-3.html#intersecting-counties-1",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot() +\n  geom_sf(data = counties, lty = 3)"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties-2",
    "href": "slides/week-3.html#intersecting-counties-2",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot() +\n  geom_sf(data = counties, lty = 3) +\n  geom_sf(data = states, fill = NA, size = 1)"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties-3",
    "href": "slides/week-3.html#intersecting-counties-3",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot() +\n  geom_sf(data = counties, lty = 3) +\n  geom_sf(data = states, fill = NA, size = 1) +\n  geom_sf(data = misscount, fill = 'red', alpha = .5)"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties-4",
    "href": "slides/week-3.html#intersecting-counties-4",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot() +\n  geom_sf(data = counties, lty = 3) +\n  geom_sf(data = states, fill = NA, size = 1) +\n  geom_sf(data = misscount, fill = 'red', alpha = .5) +\n  geom_sf(data = miss, col = \"blue\")"
  },
  {
    "objectID": "slides/week-3.html#intersecting-counties-5",
    "href": "slides/week-3.html#intersecting-counties-5",
    "title": "Week 3",
    "section": "Intersecting Counties",
    "text": "Intersecting Counties\n\n\n\nggplot() +\n  geom_sf(data = counties, lty = 3) +\n  geom_sf(data = states, fill = NA, size = 1) +\n  geom_sf(data = misscount, fill = 'red', alpha = .5) +\n  geom_sf(data = miss, col = \"blue\") +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations",
    "href": "slides/week-3.html#intersecting-populations",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within)\n\n\n\n#&gt; Simple feature collection with 3576 features and 3 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112.6693 ymin: 29.2135 xmax: -77.6454 ymax: 48.952\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 3,576 √ó 4\n#&gt;    city        state_name   population           geometry\n#&gt;  * &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;        &lt;POINT [¬∞]&gt;\n#&gt;  1 Minneapolis Minnesota       2906807 (-93.2678 44.9635)\n#&gt;  2 St. Louis   Missouri        2127843 (-90.2451 38.6359)\n#&gt;  3 Pittsburgh  Pennsylvania    1712828 (-79.9763 40.4397)\n#&gt;  4 Cincinnati  Ohio            1704916  (-84.506 39.1413)\n#&gt;  5 Kansas City Missouri        1686807 (-94.5541 39.1238)\n#&gt;  6 Memphis     Tennessee       1033394 (-89.9663 35.1087)\n#&gt;  7 Louisville  Kentucky         965005 (-85.6485 38.1663)\n#&gt;  8 New Orleans Louisiana        918752 (-89.9288 30.0687)\n#&gt;  9 Omaha       Nebraska         826161 (-96.0529 41.2627)\n#&gt; 10 Tulsa       Oklahoma         740620 (-95.9042 36.1283)\n#&gt; # ‚Ñπ 3,566 more rows"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-1",
    "href": "slides/week-3.html#intersecting-populations-1",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name)\n\n\n\n#&gt; Simple feature collection with 3576 features and 3 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112.6693 ymin: 29.2135 xmax: -77.6454 ymax: 48.952\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 3,576 √ó 4\n#&gt; # Groups:   state_name [23]\n#&gt;    city        state_name   population           geometry\n#&gt;    &lt;chr&gt;       &lt;chr&gt;             &lt;dbl&gt;        &lt;POINT [¬∞]&gt;\n#&gt;  1 Minneapolis Minnesota       2906807 (-93.2678 44.9635)\n#&gt;  2 St. Louis   Missouri        2127843 (-90.2451 38.6359)\n#&gt;  3 Pittsburgh  Pennsylvania    1712828 (-79.9763 40.4397)\n#&gt;  4 Cincinnati  Ohio            1704916  (-84.506 39.1413)\n#&gt;  5 Kansas City Missouri        1686807 (-94.5541 39.1238)\n#&gt;  6 Memphis     Tennessee       1033394 (-89.9663 35.1087)\n#&gt;  7 Louisville  Kentucky         965005 (-85.6485 38.1663)\n#&gt;  8 New Orleans Louisiana        918752 (-89.9288 30.0687)\n#&gt;  9 Omaha       Nebraska         826161 (-96.0529 41.2627)\n#&gt; 10 Tulsa       Oklahoma         740620 (-95.9042 36.1283)\n#&gt; # ‚Ñπ 3,566 more rows"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-2",
    "href": "slides/week-3.html#intersecting-populations-2",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6)\n\n\n\n#&gt; Simple feature collection with 23 features and 2 fields\n#&gt; Geometry type: MULTIPOINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112.6693 ymin: 29.2135 xmax: -77.6454 ymax: 48.952\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 23 √ó 3\n#&gt;    state_name    tot                                                    geometry\n#&gt;    &lt;chr&gt;       &lt;dbl&gt;                                            &lt;MULTIPOINT [¬∞]&gt;\n#&gt;  1 Arkansas    1.16  ((-90.7867 34.4605), (-90.8533 34.3087), (-90.9445 34.2181‚Ä¶\n#&gt;  2 Colorado    0.286 ((-102.1247 38.0554), (-102.2217 38.1212), (-102.3115 38.0‚Ä¶\n#&gt;  3 Illinois    0.583 ((-90.0004 38.1306), (-90.0977 38.0816), (-90.2128 38.1644‚Ä¶\n#&gt;  4 Indiana     0.422 ((-84.8544 38.9531), (-84.9236 38.7837), (-84.8301 38.8352‚Ä¶\n#&gt;  5 Iowa        0.792 ((-95.6757 42.4651), (-95.7831 42.4775), (-95.8667 42.5437‚Ä¶\n#&gt;  6 Kansas      1.07  ((-101.7782 37.962), (-100.9936 37.9859), (-101.1332 37.98‚Ä¶\n#&gt;  7 Kentucky    1.87  ((-84.2636 38.9184), (-84.2481 38.89), (-83.8844 38.7563),‚Ä¶\n#&gt;  8 Louisiana   2.41  ((-90.0308 29.2135), (-90.1036 29.7495), (-90.1217 29.7092‚Ä¶\n#&gt;  9 Minnesota   5.90  ((-93.2657 47.1367), (-93.1376 47.1636), (-93.0828 47.4005‚Ä¶\n#&gt; 10 Mississippi 0.284 ((-91.2992 31.1029), (-91.4152 31.496), (-91.3867 31.5437)‚Ä¶\n#&gt; # ‚Ñπ 13 more rows"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-3",
    "href": "slides/week-3.html#intersecting-populations-3",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry()\n\n\n\n#&gt; # A tibble: 23 √ó 2\n#&gt;    state_name    tot\n#&gt;  * &lt;chr&gt;       &lt;dbl&gt;\n#&gt;  1 Arkansas    1.16 \n#&gt;  2 Colorado    0.286\n#&gt;  3 Illinois    0.583\n#&gt;  4 Indiana     0.422\n#&gt;  5 Iowa        0.792\n#&gt;  6 Kansas      1.07 \n#&gt;  7 Kentucky    1.87 \n#&gt;  8 Louisiana   2.41 \n#&gt;  9 Minnesota   5.90 \n#&gt; 10 Mississippi 0.284\n#&gt; # ‚Ñπ 13 more rows"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-4",
    "href": "slides/week-3.html#intersecting-populations-4",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot()"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-5",
    "href": "slides/week-3.html#intersecting-populations-5",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot() +\n  geom_col(aes(x = reorder(state_name, -tot), y = tot))"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-6",
    "href": "slides/week-3.html#intersecting-populations-6",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot() +\n  geom_col(aes(x = reorder(state_name, -tot), y = tot)) +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-7",
    "href": "slides/week-3.html#intersecting-populations-7",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot() +\n  geom_col(aes(x = reorder(state_name, -tot), y = tot)) +\n  theme_linedraw() +\n  theme(axis.text.x = element_text(angle = 90) )"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-8",
    "href": "slides/week-3.html#intersecting-populations-8",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot() +\n  geom_col(aes(x = reorder(state_name, -tot), y = tot)) +\n  theme_linedraw() +\n  theme(axis.text.x = element_text(angle = 90) ) +\n  labs(title = \"Population living along Mississippi River System\",\n       x = \"\",\n       y = \"Population (millions)\")"
  },
  {
    "objectID": "slides/week-3.html#intersecting-populations-9",
    "href": "slides/week-3.html#intersecting-populations-9",
    "title": "Week 3",
    "section": "Intersecting Populations",
    "text": "Intersecting Populations\n\n\n\nst_filter(cities, misscount, .predicate = st_within) |&gt;\n  group_by(state_name) |&gt;\n  summarize(tot = sum(population)/1e6) |&gt;\n  st_drop_geometry() |&gt;\n  ggplot() +\n  geom_col(aes(x = reorder(state_name, -tot), y = tot)) +\n  theme_linedraw() +\n  theme(axis.text.x = element_text(angle = 90) ) +\n  labs(title = \"Population living along Mississippi River System\",\n       x = \"\",\n       y = \"Population (millions)\")\n\nggsave(filename = \"images/lecture-12-pop-count.png\", height = 4)\n\n\n\n\n\n\n\n\n\n\n#&gt; Saving 10 x 4 in image"
  },
  {
    "objectID": "slides/week-3.html#section",
    "href": "slides/week-3.html#section",
    "title": "Week 3",
    "section": "",
    "text": "A simpler (binary) version of this matrix can be created by mapping all non-empty intersections {0,1,2} to TRUE.\n\nWhere II would state: ‚ÄúDoes the Interior of‚Äùa‚Äù overlaps with the Interior of ‚Äúb‚Äù in a way that produces a point (0), line (1), or polygon (2)‚Äù\nWhere IB would state: ‚ÄúDoes the Interior of‚Äùa‚Äù overlap with the Boundary of ‚Äúb‚Äù in a way that produces a point (0), line (1), or polygon (2)‚Äù\nBoth matrix forms: - dimensional {0,1,2,F} - Boolean {T,F}\n\nCan be serialize as a ‚ÄúDE-9IM string code‚Äù representing the matrix in a single string element (standardized format for data interchange)\nThe OGC has standardized the typical spatial predicates (Contains, Crosses, Intersects, Touches, etc.) as Boolean functions, and the DE-9IM model as a function that returns the DE-9IM code, with domain of {0,1,2,F}"
  },
  {
    "objectID": "slides/week-3.html#illustration",
    "href": "slides/week-3.html#illustration",
    "title": "Week 3",
    "section": "Illustration",
    "text": "Illustration\n\nReading from left-to-right and top-to-bottom, the DE-9IM(a,b) string code is ‚Äò212101212‚Äô"
  },
  {
    "objectID": "slides/week-3.html#example-dataset",
    "href": "slides/week-3.html#example-dataset",
    "title": "Week 3",
    "section": "Example Dataset",
    "text": "Example Dataset\n\nGeometry X is a 3 feature polygon colored in red\nGeometry Y is a 4 feature polygon colored in blue"
  },
  {
    "objectID": "slides/week-3.html#st_filter",
    "href": "slides/week-3.html#st_filter",
    "title": "Week 3",
    "section": "st_filter",
    "text": "st_filter\n\nst_filter is a generic function that can be used to filter geometries based on a predicate\nThe function is a wrapper for the st_intersects function and can be used to filter geometries based on a predicate\nThe function can be used to filter geometries based on a predicate and return the geometries that satisfy the predicate\n\nFor example, the following code will return all geometries in x that intersect with y:\n\n# filter x by those that intersect y\nst_filter(st_as_sf(x), st_as_sf(y), .predicate = st_intersects)\n#&gt; Simple feature collection with 3 features and 0 fields\n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1.2 ymin: -1 xmax: 3 ymax: 3\n#&gt; CRS:           NA\n#&gt;                                x\n#&gt; 1 POLYGON ((-1 -1, 1 -1, 1 1,...\n#&gt; 2 POLYGON ((1 1, 3 1, 3 3, 1 ...\n#&gt; 3 POLYGON ((-1.2 1, 0.8 1, 0....\nst_filter(st_as_sf(x), st_as_sf(y), .predicate = st_disjoint)\n#&gt; Simple feature collection with 3 features and 0 fields\n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -1.2 ymin: -1 xmax: 3 ymax: 3\n#&gt; CRS:           NA\n#&gt;                                x\n#&gt; 1 POLYGON ((-1 -1, 1 -1, 1 1,...\n#&gt; 2 POLYGON ((1 1, 3 1, 3 3, 1 ...\n#&gt; 3 POLYGON ((-1.2 1, 0.8 1, 0....\nst_filter(st_as_sf(x), st_as_sf(y), .predicate = st_touches)\n#&gt; Simple feature collection with 0 features and 0 fields\n#&gt; Bounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\n#&gt; CRS:           NA\n#&gt; [1] x\n#&gt; &lt;0 rows&gt; (or 0-length row.names)"
  },
  {
    "objectID": "slides/week-3.html#example",
    "href": "slides/week-3.html#example",
    "title": "Week 3",
    "section": "Example",
    "text": "Example\n\nYou have been tasked by the USACE of identify the population living along the Mississippi River systems\nYou are interested in the county level since most flood control measures and flood response efforts are enforced by county EMAs\nFederal funding however is administered at the state level so you need population counts aggregated to state‚Ä¶\n\n\n# Global River Shapefile filtered to the Mississippi System\nmiss = read_sf('data/majorrivers_0_0/MajorRivers.shp') |&gt; \n  filter(SYSTEM == \"Mississippi\") \n\n# Which counties intersect this system\nmisscount = st_filter(aoi_get(state = \"conus\", county = \"all\"), miss,  .predicate = st_intersects) \n\n# Find all counties in the intersecting states\ncounties =  filter(aoi_get(state = \"conus\", county = \"all\"), state_name %in% c(misscount$state_name) )\n\n# Find all impacted states\nstates   =  filter(aoi_get(state = \"conus\"), state_name %in% c(misscount$state_name))"
  },
  {
    "objectID": "slides/week-3.html#result",
    "href": "slides/week-3.html#result",
    "title": "Week 3",
    "section": "Result",
    "text": "Result\n\nggplot(states) + \n  geom_sf() + \n  geom_sf(data = wa, fill = \"blue\", alpha = .3) +\n  geom_sf(data = st_filter(states, wa, .predicate = st_touches), fill = \"red\", alpha = .5) + \n  theme_void()"
  },
  {
    "objectID": "slides/week-3.html#distance-example-additional-parameter",
    "href": "slides/week-3.html#distance-example-additional-parameter",
    "title": "Week 3",
    "section": "Distance Example (additional parameter)",
    "text": "Distance Example (additional parameter)\n\ncities = read_csv(\"../labs/data/uscities.csv\") |&gt; \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) |&gt; \n  select(city, population, state_name) |&gt; \n  st_transform(5070)\n\n\nst_filter(cities, \n          filter(cities, city == \"Fort Collins\"), \n          .predicate = st_is_within_distance, 10000) \n#&gt; Simple feature collection with 2 features and 3 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -760147.5 ymin: 1982249 xmax: -751658.3 ymax: 1984621\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; # A tibble: 2 √ó 4\n#&gt;   city         population state_name            geometry\n#&gt; * &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;              &lt;POINT [m]&gt;\n#&gt; 1 Fort Collins     339256 Colorado   (-760147.5 1984621)\n#&gt; 2 Timnath            8007 Colorado   (-751658.3 1982249)"
  },
  {
    "objectID": "slides/week-3.html#st_join",
    "href": "slides/week-3.html#st_join",
    "title": "Week 3",
    "section": "st_join",
    "text": "st_join\n\nIn sf st_join provides this joining capacity\nBy default, st_join performs a left join (Returns all records from x, and the matched records from y)\n\n\n\n\n\n\n\n\n\n\n\nIt can also do inner joins by setting left = FALSE.\n\n\n\n\n\n\n\n\n\n\n\nThe default predicate for st_join (and st_filter) is st_intersects\nThis can be changed with the join argument (see ?st_join for details)."
  },
  {
    "objectID": "slides/week-3.html#ramerdouglaspeucker",
    "href": "slides/week-3.html#ramerdouglaspeucker",
    "title": "Week 3",
    "section": "Ramer‚ÄìDouglas‚ÄìPeucker",
    "text": "Ramer‚ÄìDouglas‚ÄìPeucker\n\nMark the first and last points as kept\nFind the point, p that is the farthest from the first-last line segment. If there are no points between first and last we are done (the base case)\nIf p is closer than tolerance units to the line segment then everything between first and last can be discarded\nOtherwise, mark p as kept and repeat steps 1-4 using the points between first and p and between p and last (the call to recursion)"
  },
  {
    "objectID": "slides/week-3.html#st_simplify",
    "href": "slides/week-3.html#st_simplify",
    "title": "Week 3",
    "section": "st_simplify",
    "text": "st_simplify"
  },
  {
    "objectID": "slides/week-3.html#st_simplify-1",
    "href": "slides/week-3.html#st_simplify-1",
    "title": "Week 3",
    "section": "st_simplify",
    "text": "st_simplify\n\nsf provides st_simplify, which uses the GEOS implementation of the Douglas-Peucker algorithm to reduce the vertex count.\nst_simplify uses the dTolerance to control the level of generalization in map units (see Douglas and Peucker 1973 for details)."
  },
  {
    "objectID": "slides/week-3.html#section-1",
    "href": "slides/week-3.html#section-1",
    "title": "Week 3",
    "section": "",
    "text": "topSB &lt;- st_join(counties, starbucks) |&gt; \n  group_by(name, state_name) |&gt; \n  summarise(n = n()) |&gt; \n  group_by(state_name) |&gt; \n  slice_max(n, n = 1) |&gt; \n  ungroup()"
  },
  {
    "objectID": "slides/week-3.html#visvalingam",
    "href": "slides/week-3.html#visvalingam",
    "title": "Week 3",
    "section": "Visvalingam",
    "text": "Visvalingam\n\nThe Visvalingam algorithm overcomes some limitations of the Douglas-Peucker algorithm (Visvalingam and Whyatt 1993).\nit progressively removes points with the least-perceptible change.\nSimplification often allows the elimination of 95% or more points while retaining sufficient detail for visualization and often analysis"
  },
  {
    "objectID": "slides/week-3.html#section-2",
    "href": "slides/week-3.html#section-2",
    "title": "Week 3",
    "section": "",
    "text": "Neither joining nor filtering spatially alter the underlying geometry of the features\nIn cases where we seek to alter a geometry based on another, we need clipping methods"
  },
  {
    "objectID": "slides/week-3.html#section-3",
    "href": "slides/week-3.html#section-3",
    "title": "Week 3",
    "section": "",
    "text": "In cases where we want to reduce the complexity in a geometry we can use simplification algorithms\nThe most common algorithms are Ramer‚ÄìDouglas‚ÄìPeucker and Visvalingam-Whyatt."
  },
  {
    "objectID": "slides/week-3.html#section-4",
    "href": "slides/week-3.html#section-4",
    "title": "Week 3",
    "section": "",
    "text": "usa = aoi_get(state = \"conus\") |&gt; \n  st_union() |&gt; \n  st_transform(5070)\n\nusa1000   = st_simplify(usa, dTolerance = 10000)\nusa10000  = st_simplify(usa, dTolerance = 100000)\nusa100000 = st_simplify(usa, dTolerance = 1000000)"
  },
  {
    "objectID": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012",
    "href": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012",
    "title": "Week 3",
    "section": "Core Concepts of Spatial Data: (Kuhn 2012)",
    "text": "Core Concepts of Spatial Data: (Kuhn 2012)"
  },
  {
    "objectID": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012-1",
    "href": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012-1",
    "title": "Week 3",
    "section": "Core Concepts of Spatial Data: (Kuhn 2012)",
    "text": "Core Concepts of Spatial Data: (Kuhn 2012)\n\nOne Base Concept: Location\nFour Content Concepts: Field, Object, Network, Event\nTwo Quality Concepts: Granularity, Accuracy"
  },
  {
    "objectID": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012-2",
    "href": "slides/week-3.html#core-concepts-of-spatial-data-kuhn-2012-2",
    "title": "Week 3",
    "section": "Core Concepts of Spatial Data: (Kuhn 2012)",
    "text": "Core Concepts of Spatial Data: (Kuhn 2012)\n\nOne Base Concept: Location (coordinates)\nFour Content Concepts: Field (raster), Object (simple feature), Network, Event\nTwo Quality Concepts: Granularity (simplification), Accuracy (taken for granted)"
  },
  {
    "objectID": "slides/week-3.html#object-view",
    "href": "slides/week-3.html#object-view",
    "title": "Week 3",
    "section": "Object View",
    "text": "Object View\n\nObjects describe individuals that have an identity (id) as well as spatial, temporal, and thematic properties.\nAnswers questions about properties and relations of objects.\nResults from fixing theme, controlling time, and measuring space.\nFeatures, such as surfaces, depend on objects (but are also objects)"
  },
  {
    "objectID": "slides/week-3.html#object-view-1",
    "href": "slides/week-3.html#object-view-1",
    "title": "Week 3",
    "section": "Object View",
    "text": "Object View\n\nObject implies boundedness\n\nboundaries may not be known or even knowable, but have limits.\n\nCrude examples of such limits are the minimal bounding boxes used for indexing and querying objects in databases.\nMany objects (particularly natural ones) do not have crisp boundaries (watersheds)\nDifferences between spatial information from multiple sources are often caused by more or less arbitrary delineations through context-dependent boundaries.\nMany questions about objects and features can be answered without boundaries, using simple point representations (centroids) with thematic attributes."
  },
  {
    "objectID": "slides/week-3.html#field-view",
    "href": "slides/week-3.html#field-view",
    "title": "Week 3",
    "section": "Field View",
    "text": "Field View\n\nFields describe phenomena that have a scalar or vector attribute everywhere in a space of interest\n\nfor example, air temperatures, rainfall, elevation, land cover\n\nField information answers the question what is here?, where here can be anywhere in the space considered.\nField-based spatial information can also represent attributes that are computed rather than measured, such as probabilities or densities.\n\n\nTogether, fields and objects are the two fundamental ways of structuring spatial information."
  },
  {
    "objectID": "slides/week-3.html#objects-can-provide-coverage",
    "href": "slides/week-3.html#objects-can-provide-coverage",
    "title": "Week 3",
    "section": "Objects can provide coverage:",
    "text": "Objects can provide coverage:\n\nBoth objects and fields can cover space continuously - the primary difference is that objects prescribe bounds.\n\nCounties are one form of object that covers the USA seamlessly\nState objects are another ‚Ä¶"
  },
  {
    "objectID": "slides/week-3.html#landsat-path-row",
    "href": "slides/week-3.html#landsat-path-row",
    "title": "Week 3",
    "section": "LANDSAT Path Row",
    "text": "LANDSAT Path Row\n\nServes tiles based on a path/row index"
  },
  {
    "objectID": "slides/week-3.html#modis-sinisoial-grid",
    "href": "slides/week-3.html#modis-sinisoial-grid",
    "title": "Week 3",
    "section": "MODIS Sinisoial Grid",
    "text": "MODIS Sinisoial Grid\n\nServes tiles based on a path/row index"
  },
  {
    "objectID": "slides/week-3.html#uber-hex-addressing",
    "href": "slides/week-3.html#uber-hex-addressing",
    "title": "Week 3",
    "section": "Uber Hex Addressing",
    "text": "Uber Hex Addressing\n\nBreaks the world into Hexagons‚Ä¶"
  },
  {
    "objectID": "slides/week-3.html#what3word",
    "href": "slides/week-3.html#what3word",
    "title": "Week 3",
    "section": "what3word",
    "text": "what3word\n\nBreaks the world into 3m grids encoded with unique 3 word strings"
  },
  {
    "objectID": "slides/week-3.html#tesselation-plotting-function",
    "href": "slides/week-3.html#tesselation-plotting-function",
    "title": "Week 3",
    "section": "Tesselation plotting function",
    "text": "Tesselation plotting function\n\nplot_tess = function(data, title){\n  ggplot() + \n    geom_sf(data = data, fill = \"white\", col = \"navy\", size = .2) +   \n    theme_void() +\n    labs(title = title, caption = paste(\"This tesselation has:\", nrow(data), \"tiles\" )) +\n    theme(plot.title = element_text(hjust = .5, color =  \"navy\", face = \"bold\"))\n}"
  },
  {
    "objectID": "slides/week-3.html#section-5",
    "href": "slides/week-3.html#section-5",
    "title": "Week 3",
    "section": "",
    "text": "A limitation with Douglas-Peucker (therefore st_simplify) is that it simplifies objects on a per-geometry basis.\nThis means the ‚Äòtopology‚Äô is lost, resulting in overlapping and disconnected geometries.\n\n\nstates = st_transform(states, 5070)\nsimp_states   = st_simplify(states, dTolerance = 20000)\nplot(simp_states$geometry)"
  },
  {
    "objectID": "slides/week-3.html#hexagonal-grid",
    "href": "slides/week-3.html#hexagonal-grid",
    "title": "Week 3",
    "section": "Hexagonal Grid",
    "text": "Hexagonal Grid\n\nHexagonal tessellations (honey combs) offer an alternative to square grids\nThey are created in the same way but by setting square = FALSE\n\n\nhex_grid = st_make_grid(south_counties, n = c(70, 50), square = FALSE) |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())"
  },
  {
    "objectID": "slides/week-3.html#advantages-square-grids",
    "href": "slides/week-3.html#advantages-square-grids",
    "title": "Week 3",
    "section": "Advantages Square Grids",
    "text": "Advantages Square Grids\n\nSimple definition and data storage\n\nOnly need the origin (lower left), cell size (XY) and grid dimensions\n\nEasy to aggregate and dissaggregate (resample)\nAnalogous to raster data\nRelationship between cells is given\nCombining layers is easy with traditional matrix algebra"
  },
  {
    "objectID": "slides/week-3.html#triangulations",
    "href": "slides/week-3.html#triangulations",
    "title": "Week 3",
    "section": "Triangulations",
    "text": "Triangulations\n\nAn alternative to creating equal area tiles is to create triangulations from known anchor points\nTriangulation requires a set of input points and seeks to partition the interior into a partition of triangles.\nIn GIS contexts you‚Äôll hear:\n\nThiessen Polygon\nVoronoi Regions\nDelunay Triangulation\nTIN (Triangular irregular networks)\netc,.."
  },
  {
    "objectID": "slides/week-3.html#voronoi-polygons",
    "href": "slides/week-3.html#voronoi-polygons",
    "title": "Week 3",
    "section": "Voronoi Polygons",
    "text": "Voronoi Polygons\n\nVoronoi/Thiessen polygon boundaries define the area closest to each anchor point relative to all others\nThey are defined by the perpendicular bisectors of the lines between all points."
  },
  {
    "objectID": "slides/week-3.html#voronoi-polygons-1",
    "href": "slides/week-3.html#voronoi-polygons-1",
    "title": "Week 3",
    "section": "Voronoi Polygons",
    "text": "Voronoi Polygons"
  },
  {
    "objectID": "slides/week-3.html#voronoi-polygons-2",
    "href": "slides/week-3.html#voronoi-polygons-2",
    "title": "Week 3",
    "section": "Voronoi Polygons",
    "text": "Voronoi Polygons\n\nUsefull for tasks such as:\n\nnearest neighbor search,\nfacility location (optimization),\nlargest empty areas,\npath planning‚Ä¶\n\nAlso useful for simple interpolation of values such as rain gauges,"
  },
  {
    "objectID": "slides/week-3.html#often-used-in-numerical-models-and-simulations",
    "href": "slides/week-3.html#often-used-in-numerical-models-and-simulations",
    "title": "Week 3",
    "section": "Often used in numerical models and simulations",
    "text": "Often used in numerical models and simulations"
  },
  {
    "objectID": "slides/week-3.html#st_voronoi",
    "href": "slides/week-3.html#st_voronoi",
    "title": "Week 3",
    "section": "st_voronoi",
    "text": "st_voronoi\n\nst_voronoi creates voronoi tesselation in sf\nIt works over a MULTIPOINT collection\nShould always be simplified after creation (st_cast())\nIf to be treated as an object for analysis, should be id‚Äôd\n\n\nsouth_cent_u = st_union(south_cent)\n\nv_grid = st_voronoi(south_cent_u) |&gt; \n  st_cast() |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())"
  },
  {
    "objectID": "slides/week-3.html#delaunay-triangulation",
    "href": "slides/week-3.html#delaunay-triangulation",
    "title": "Week 3",
    "section": "Delaunay triangulation",
    "text": "Delaunay triangulation\n\nA Delaunay triangulation for a given set of points (P) in a plane, is a triangulation DT(P), where no point is inside the circumcircle of any triangle in DT(P)."
  },
  {
    "objectID": "slides/week-3.html#delaunay-triangulation-1",
    "href": "slides/week-3.html#delaunay-triangulation-1",
    "title": "Week 3",
    "section": "Delaunay triangulation",
    "text": "Delaunay triangulation\n\nThe Delaunay triangulation of a discrete POINT set corresponds to the dual graph of the Voronoi diagram.\nThe circumcenters (center of circles) of Delaunay triangles are the vertices of the Voronoi diagram."
  },
  {
    "objectID": "slides/week-3.html#used-in-landscape-evaluation-and-terrian-modeling",
    "href": "slides/week-3.html#used-in-landscape-evaluation-and-terrian-modeling",
    "title": "Week 3",
    "section": "Used in landscape evaluation and terrian modeling",
    "text": "Used in landscape evaluation and terrian modeling"
  },
  {
    "objectID": "slides/week-3.html#st_triangulate",
    "href": "slides/week-3.html#st_triangulate",
    "title": "Week 3",
    "section": "st_triangulate",
    "text": "st_triangulate\n\nst_triangulate creates Delaunay triangulation in sf\nIt works over a MULTIPOINT collection\nShould always be simplified after creation (st_cast())\nIf to be treated as an object for analysis, should be id‚Äôd\n\n\nt_grid = st_triangulate(south_cent_u) |&gt; \n  st_cast() |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())"
  },
  {
    "objectID": "slides/week-3.html#topologic-diminsion",
    "href": "slides/week-3.html#topologic-diminsion",
    "title": "Week 3",
    "section": "Topologic Diminsion",
    "text": "Topologic Diminsion\nA POINT is shape with a dimension of 0 that occupies a single location in coordinate space.\n\n# POINT defined as numeric vector\n(st_dimension(st_point(c(0,1))))\n#&gt; [1] 0\n\nA LINESTRING is shape that has a dimension of 1 (length)\n\n# LINESTRING defined by matrix\n(st_dimension(st_linestring(matrix(1:4, nrow = 2))))\n#&gt; [1] 1\n\nA POLYGON is surface stored as a list of its exterior and interior rings. It has a dimension of 2. (area)\n\n# POLYGON defined by LIST (interior and exterior rings)\n(st_dimension(st_polygon(list(matrix(c(1:4, 1,2), nrow = 3, byrow = TRUE)))))\n#&gt; [1] 2"
  },
  {
    "objectID": "slides/week-3.html#predicates-1",
    "href": "slides/week-3.html#predicates-1",
    "title": "Week 3",
    "section": "Predicates",
    "text": "Predicates\nIn the following, we are interested in the resulting geometry that occurs when 2 geometries are overlaid‚Ä¶"
  },
  {
    "objectID": "slides/week-3.html#overlap-is-a-point-0d",
    "href": "slides/week-3.html#overlap-is-a-point-0d",
    "title": "Week 3",
    "section": "Overlap is a POINT: 0D",
    "text": "Overlap is a POINT: 0D"
  },
  {
    "objectID": "slides/week-3.html#overlap-is-a-linestring-1d",
    "href": "slides/week-3.html#overlap-is-a-linestring-1d",
    "title": "Week 3",
    "section": "Overlap is a LINESTRING: 1D",
    "text": "Overlap is a LINESTRING: 1D"
  },
  {
    "objectID": "slides/week-3.html#overlap-is-a-polygon-2d",
    "href": "slides/week-3.html#overlap-is-a-polygon-2d",
    "title": "Week 3",
    "section": "Overlap is a POLYGON: 2D",
    "text": "Overlap is a POLYGON: 2D"
  },
  {
    "objectID": "slides/week-3.html#no-overlap-false",
    "href": "slides/week-3.html#no-overlap-false",
    "title": "Week 3",
    "section": "No Overlap = FALSE",
    "text": "No Overlap = FALSE"
  },
  {
    "objectID": "slides/week-3.html#dimensionally-extended-9-intersection-model-de-9im",
    "href": "slides/week-3.html#dimensionally-extended-9-intersection-model-de-9im",
    "title": "Week 3",
    "section": "Dimensionally Extended 9-Intersection Model (DE-9IM)",
    "text": "Dimensionally Extended 9-Intersection Model (DE-9IM)\n\nThe DE-9IM is a topological model and (standard) used to describe the spatial relations of two geometries\nUsed in geometry, point-set topology, geospatial topology\nThe DE-9IM matrix provides a way to classify geometry relations using the set {0,1,2,F} or {T,F}\nWith a {T,F} matrix domain, there are 512 possible relations that can be grouped into binary classification schemes.\nAbout 10 of these, have been given a common name such as intersects, touches, and within.\nWhen testing two geometries against a scheme, the result is a spatial predicate named by the scheme.\nProvides the primary basis for queries and assertions in GIS and spatial databases (PostGIS)."
  },
  {
    "objectID": "slides/week-3.html#the-matrix-model",
    "href": "slides/week-3.html#the-matrix-model",
    "title": "Week 3",
    "section": "The Matrix Model",
    "text": "The Matrix Model\nThe DE-9IM matrix is based on a 3x3 intersection matrix:\n\nWhere:\n\ndim is the dimension of the intersection and\nI is the interior\nB is the boundary\nE is the exterior\n\n\nEmpty sets are denoted as F\nnon-empty sets are denoted with the maximum dimension of the intersection {0,1,2}"
  },
  {
    "objectID": "slides/week-3.html#spatial-predicates",
    "href": "slides/week-3.html#spatial-predicates",
    "title": "Week 3",
    "section": "Spatial Predicates",
    "text": "Spatial Predicates\n\n‚Äúnamed spatial predicates‚Äù have been defined for some common relations.\nA few spatial predicate functions that can be derived (expressed by masks) from DE-9IM include (* = wildcard):\n\n\n\n\n\n\n\n\n\nPredicate\nDE-9IM String Code\nDescription\n\n\n\n\nIntersects\nT*F**FFF*\n‚ÄúTwo geometries intersect if they share any portion of space‚Äù\n\n\nOverlaps\nT*F**FFF*\n‚ÄúTwo geometries overlap if they share some but not all of the same space‚Äù\n\n\nEquals\nT*F**FFF*\n‚ÄúTwo geometries are topologically equal if their interiors intersect and no part of the interior or boundary of one geometry intersects the exterior of the other‚Äù\n\n\nDisjoint\nFF*FF*****\n‚ÄúTwo geometries are disjoint: they have no point in common. They form a set of disconnected geometries.‚Äù\n\n\nTouches\nFT*******\nF**T*****\n\n\nContains\nT*****FF**\n‚ÄúA contains B: geometry B lies in A, and the interiors intersect‚Äù\n\n\nCovers\nT*****FF*\n*T****FF*\n\n\nWithin\n*T*****FF*\n**T****FF*\n\n\nCovered by\n*T*****FF*\n**T****FF*"
  },
  {
    "objectID": "slides/week-3.html#spatial-predicates-in-r",
    "href": "slides/week-3.html#spatial-predicates-in-r",
    "title": "Week 3",
    "section": "Spatial Predicates in R",
    "text": "Spatial Predicates in R\n\nGeometry X is a 3 feature polygon colored in red\nGeometry Y is a 4 feature polygon colored in blue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nst_relate(x,y)\n#&gt;      [,1]        [,2]        [,3]        [,4]       \n#&gt; [1,] \"212FF1FF2\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\n#&gt; [2,] \"FF2FF1212\" \"212101212\" \"212101212\" \"FF2FF1212\"\n#&gt; [3,] \"FF2FF1212\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\nst_relate(x,x)\n#&gt;      [,1]        [,2]        [,3]       \n#&gt; [1,] \"2FFF1FFF2\" \"FF2F01212\" \"FF2F11212\"\n#&gt; [2,] \"FF2F01212\" \"2FFF1FFF2\" \"FF2FF1212\"\n#&gt; [3,] \"FF2F11212\" \"FF2FF1212\" \"2FFF1FFF2\"\nst_relate(y,y)\n#&gt;      [,1]        [,2]        [,3]        [,4]       \n#&gt; [1,] \"2FFF1FFF2\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\n#&gt; [2,] \"FF2FF1212\" \"2FFF1FFF2\" \"212101212\" \"FF2FF1212\"\n#&gt; [3,] \"212101212\" \"212101212\" \"2FFF1FFF2\" \"FF2FF1212\"\n#&gt; [4,] \"FF2FF1212\" \"FF2FF1212\" \"FF2FF1212\" \"2FFF1FFF2\"\n\n\nSpatial Predicates\n\n‚Äúnamed spatial predicates‚Äù have been defined for some common relations.\nA few spatial predicate functions that can be derived (expressed by masks) from DE-9IM include (* = wildcard):\n\n\n\n\n\n\n\n\n\nPredicate\nDE-9IM String Code\nDescription\n\n\n\n\nIntersects\nT*F**FFF*\n‚ÄúTwo geometries intersect if they share any portion of space‚Äù\n\n\nOverlaps\nT*F**FFF*\n‚ÄúTwo geometries overlap if they share some but not all of the same space‚Äù\n\n\nEquals\nT*F**FFF*\n‚ÄúTwo geometries are topologically equal if their interiors intersect and no part of the interior or boundary of one geometry intersects the exterior of the other‚Äù\n\n\nDisjoint\nFF*FF*****\n‚ÄúTwo geometries are disjoint: they have no point in common. They form a set of disconnected geometries.‚Äù\n\n\nTouches\nFT*******\nF**T*****\n\n\nContains\nT*****FF**\n‚ÄúA contains B: geometry B lies in A, and the interiors intersect‚Äù\n\n\nCovers\nT*****FF*\n*T****FF*\n\n\nWithin\n*T*****FF*\n**T****FF*\n\n\nCovered by\n*T*****FF*\n**T****FF*\n\n\n\n\nBinary logical operations\nReturns either a sparse matrix\n\nst_intersects(x,y)\n#&gt; Sparse geometry binary predicate list of length 3, where the predicate\n#&gt; was `intersects'\n#&gt;  1: 1, 3\n#&gt;  2: 2, 3\n#&gt;  3: 3\n\nor a dense matrix\n\nst_intersects(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2] [,3]  [,4]\n#&gt; [1,]  TRUE FALSE TRUE FALSE\n#&gt; [2,] FALSE  TRUE TRUE FALSE\n#&gt; [3,] FALSE FALSE TRUE FALSE\n\nst_disjoint(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3] [,4]\n#&gt; [1,] FALSE  TRUE FALSE TRUE\n#&gt; [2,]  TRUE FALSE FALSE TRUE\n#&gt; [3,]  TRUE  TRUE FALSE TRUE\n\nst_touches(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE\n\nst_within(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE\n\n\nst_realtes vs.¬†predicate calls‚Ä¶\nFT*******; F**T*****; F***T****\n\nstates = filter(aoi_get(state = \"all\"), state_abbr %in% c(\"WA\", \"OR\", \"MT\", \"ID\")) |&gt;\n  select(name)\n\nwa = filter(states, name == \"Washington\")\n\n\nplot(states$geometry, col = \"white\", border = \"black\")\n\n\n(mutate(states, \n        deim9 = st_relate(states, wa),\n        touch = st_touches(states, wa, sparse = F)))\n#&gt; Simple feature collection with 4 features and 3 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 41.98818 xmax: -104.0397 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry     deim9 touch\n#&gt; 1      Idaho MULTIPOLYGON (((-111.0455 4... FF2F11212  TRUE\n#&gt; 2    Montana MULTIPOLYGON (((-109.7985 4... FF2FF1212 FALSE\n#&gt; 3     Oregon MULTIPOLYGON (((-117.22 44.... FF2F11212  TRUE\n#&gt; 4 Washington MULTIPOLYGON (((-121.5237 4... 2FFF1FFF2 FALSE\n\n\nBinary Predicates\n\nCollectively, predicates define the type of relationship each 2D object has with another.\nOf the ~ 512 unique relationships offered by the DE-9IM models a selection of ~ 10 have been named.\nThese are include in PostGIS/GEOS and are made accessible via R sf\n\n\n\nSo‚Ä¶\n\nbinary predicates return conditional {T,F} relations based on predefined masks of the DE-9IM strings\nUp to this point in class we have been using Boolean {T,F} masks to filter data.frames by columns:\n\n\nfruits = c(\"apple\", \"orange\", \"lemon\", \"watermelon\")\n\n\nfruits == \"apple\"\n#&gt; [1]  TRUE FALSE FALSE FALSE\n\n\nfruits %in% c(\"apple\", \"lemon\")\n#&gt; [1]  TRUE FALSE  TRUE FALSE\n\n\n\nFiltering on data.frames\n\nWe have used dplyr::filter to subset a data frame, retaining all rows that satisfy a boolean condition.\n\n\n\n\nmutate(states, equalsWA = (name == \"Washington\")) |&gt; \n  st_drop_geometry()\n#&gt;         name equalsWA\n#&gt; 1      Idaho    FALSE\n#&gt; 2    Montana    FALSE\n#&gt; 3     Oregon    FALSE\n#&gt; 4 Washington     TRUE\n\n\n\nfilter(states, name == \"Washington\") |&gt; \n  st_drop_geometry()\n#&gt;         name\n#&gt; 1 Washington\n\n\n\n\n\nSpatial Filtering\n\nWe can filter spatially, using st_filter as the function call\nHere the boolean condition is not passed (e.g.¬†stusps == WA)\nBut instead, is defined by a spatial predicate\nThe default predicate is st_intersects but can be changed with the .predicate argument:\n\n\n\n\nmutate(states, \n       touch = st_touches(states, wa, sparse = FALSE)) \n#&gt; Simple feature collection with 4 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 41.98818 xmax: -104.0397 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry touch\n#&gt; 1      Idaho MULTIPOLYGON (((-111.0455 4...  TRUE\n#&gt; 2    Montana MULTIPOLYGON (((-109.7985 4... FALSE\n#&gt; 3     Oregon MULTIPOLYGON (((-117.22 44....  TRUE\n#&gt; 4 Washington MULTIPOLYGON (((-121.5237 4... FALSE\n\n\n\nst_filter(states, wa, .predicate = st_touches) \n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7035 ymin: 41.98818 xmax: -111.0435 ymax: 49.00085\n#&gt; Geodetic CRS:  WGS 84\n#&gt;     name                       geometry\n#&gt; 1  Idaho MULTIPOLYGON (((-111.0455 4...\n#&gt; 2 Oregon MULTIPOLYGON (((-117.22 44....\n\n\n\n\n\nResult\n\nggplot(states) + \n  geom_sf() + \n  geom_sf(data = wa, fill = \"blue\", alpha = .3) +\n  geom_sf(data = st_filter(states, wa, .predicate = st_touches), fill = \"red\", alpha = .5) + \n  theme_void()\n\n\n\n\nDistance Example (additional parameter)\n\ncities = read_csv(\"../labs/data/uscities.csv\") |&gt; \n  st_as_sf(coords = c(\"lng\", \"lat\"), crs = 4326) |&gt; \n  select(city, population, state_name) |&gt; \n  st_transform(5070)\n\n\nfoco = filter(cities, city == \"Fort Collins\")\n\n\nst_filter(cities, foco, .predicate = st_is_within_distance, 10000) \n#&gt; Simple feature collection with 2 features and 3 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -760147.5 ymin: 1982249 xmax: -751658.3 ymax: 1984621\n#&gt; Projected CRS: NAD83 / Conus Albers\n#&gt; # A tibble: 2 √ó 4\n#&gt;   city         population state_name            geometry\n#&gt; * &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;              &lt;POINT [m]&gt;\n#&gt; 1 Fort Collins     339256 Colorado   (-760147.5 1984621)\n#&gt; 2 Timnath            8007 Colorado   (-751658.3 1982249)\n\n\n\nThink back to week 1: Data Science\n\nFiltering is a nice way to reduce the dimensions of a single dataset\nOften ‚Äú‚Ä¶ one table is not enough‚Ä¶ ‚Äù\nIn these cases we want to combine - or join - data\n\n\n\nSpatial Joining\n\nJoining two non-spatial datasets relies on a shared key that uniquely identifies each record in a table\n\n\n\nSpatially joining data relies on shared geographic relations rather then a shared key\nLike filter, these relations can be defined by a predicate\nAs with tabular data, mutating joins add data to the target object (x) from a source object (y).\n\n\n\nst_join\n\nIn sf st_join provides this joining capacity\nBy default, st_join performs a left join (Returns all records from x, and the matched records from y)\n\n\n\n\n\n\n\n\n\n\n\nIt can also do inner joins by setting left = FALSE.\n\n\n\n\n\n\n\n\n\n\n\nThe default topological predicate st_join (and st_filter) is st_intersects\nThis can be changed with the join argument (see ?st_join for details).\n\n\n\nEvery Starbucks in the World\nWhat county has the most Starbucks in each state?\n\nstarbucks = readr::read_csv('../labs/data/directory.csv') |&gt; \n  filter(!is.na(Latitude), Country == \"US\") |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |&gt; \n  st_transform(5070)\n\n‚Äì\n\nnrow(starbucks)\n#&gt; [1] 13608\n\nnames(starbucks)\n#&gt;  [1] \"Brand\"          \"Store Number\"   \"Store Name\"     \"Ownership Type\"\n#&gt;  [5] \"Street Address\" \"City\"           \"State/Province\" \"Country\"       \n#&gt;  [9] \"Postcode\"       \"Phone Number\"   \"Timezone\"       \"geometry\"\n\n‚Äì\n\ncounties = aoi_get(state = \"conus\", county = \"all\") |&gt; \n  st_transform(5070) |&gt; \n  select(name, state_name)\n\n\n\ntopSB = st_join(counties, starbucks) |&gt; \n  group_by(name, state_name) |&gt; \n  summarise(n = n()) |&gt; \n  group_by(state_name) |&gt; \n  slice_max(n, n = 1) |&gt; \n  ungroup()\n\n\n\nNeither joining nor filtering spatially alter the underlying geometry of the features\nIn cases where we seek to alter a geometry bases on another, we need clipping methods\n\n\n\nClipping\n\nClipping is a form of subsetting that involves changing the geometry of at least some features.\nClipping can only apply to features more complex than points: (lines, polygons and their ‚Äòmulti‚Äô equivalents).\n\n\n\n\nSpatial Subsetting\n\nBy default the data.frame subsetting methods we‚Äôve seen (e.g [,]) implements st_intersection\n\n\nwa = st_transform(wa, 5070)\nwa_starbucks = starbucks[wa,] #&lt;&lt;\n\nggplot() + geom_sf(data = wa) + geom_sf(data = wa_starbucks) + theme_void()\n\n\n\n\nSimplification\n\n\n\nComputational Complexity\n\nIn all the cases we have looked at, the number of POINT (e.g geometries, nodes, or vertices) define the complexity of the predicate or the clip\nComputational needs increase with the number of POINTS / NODES / VERTICES\nSimplification is a process for generalization vector objects (lines and polygons)\nAnother reason for simplifying objects is to reduce the amount of memory, disk space and network bandwidth they consume\nOther times the level of detail captured in a geometry is either not needed, or, even counter productive the the scale/purpose of an analysis\nIf you are cropping features to a national border, how much detail do you need? The more points in your border, the long the clip operation will take.\nIn cases where we want to reduce th complexity in a geometry we can use simplification algorithms\n\n\n\nRamer‚ÄìDouglas‚ÄìPeucker\n\nMark the first and last points as kept\nFind the point, p that is the farthest from the first-last line segment. If there are no points between first and last we are done (the base case)\nIf p is closer than tolerance units to the line segment then everything between first and last can be discarded\nOtherwise, mark p as kept and repeat steps 1-4 using the points between first and p and between p and last (the call to recursion)\n\n\n\n\nst_simplify\n\n\n\nst_simplify\n\nsf provides st_simplify, which uses the GEOS implementation of the Douglas-Peucker algorithm to reduce the vertex count.\nst_simplify uses the dTolerance to control the level of generalization in map units (see Douglas and Peucker 1973 for details).\n\n\n\n\n\n\nusa = aoi_get(state = \"conus\") |&gt; \n  st_union() |&gt; \n  st_transform(5070)\n\nusa1000   = st_simplify(usa, dTolerance = 10000)\nusa10000  = st_simplify(usa, dTolerance = 100000)\nusa100000 = st_simplify(usa, dTolerance = 1000000)\n\n\n\n\n\n\n\n\n\n\n\nA limitation with Douglas-Peucker (therefore st_simplify) is that it simplifies objects on a per-geometry basis.\nThis means the ‚Äòtopology‚Äô is lost, resulting in overlapping and disconnected geometries.\n\n\nstates = st_transform(states, 5070)\nsimp_states   = st_simplify(states, dTolerance = 20000)\nplot(simp_states$geometry)\n\n\n\n\n\n\n\n\n\n\nVisvalingam\n\nThe Visvalingam algorithm overcomes some limitations of the Douglas-Peucker algorithm (Visvalingam and Whyatt 1993).\nit progressively removes points with the least-perceptible change.\nSimplification often allows the elimination of 95% or more points while retaining sufficient detail for visualization and often analysis\n\n\n\n\n\n\nlibrary(rmapshaper)\n\nusa10 = ms_simplify(usa, keep = .1)\nusa5  = ms_simplify(usa, keep = .05)\nusa1  = ms_simplify(usa, keep = .01)\n\n\n\n\n\n\nstates = st_transform(states, 5070)\nsimp_states   = ms_simplify(states, keep = .05)\nplot(simp_states$geometry)\n\n\n\n\n\nIn all cases, the number of points in a geometry can be calculated with mapview::npts()\n\nstates = st_transform(states, 5070)\nsimp_states_st   = st_simplify(states, dTolerance = 20000)\nsimp_states_ms   = ms_simplify(states, keep = .05)\n\nmapview::npts(states)\n#&gt; [1] 5930\nmapview::npts(simp_states_st)\n#&gt; [1] 53\nmapview::npts(simp_states_ms)\n#&gt; [1] 292\n\n\n\nTesselation\n\n\n\nSummary\n\nSo far we have spent the last two weeks looking at simple feature objects\nWhere a feature as a geometry define by a set of structured POINT(s)\nThese points have precision and define location ({X Y CRS})\nThe geometry defines a bounds: either 0D, 1D or 2D\nEach object is therefore bounded to those geometries implying a level of exactness.\n\n\n\nCore Concepts of Spatial Data: (Kuhn 2012)\n\n\n\nCore Concepts of Spatial Data: (Kuhn 2012)\n\nOne Base Concept: Location\nFour Content Concepts: Field, Object, Network, Event\nTwo Quality Concepts: Granularity, Accuracy\n\n\n\nCore Concepts of Spatial Data: (Kuhn 2012)\n\nOne Base Concept: Location (coordinates)\nFour Content Concepts: Field (raster), Object (simple feature), Network, Event\nTwo Quality Concepts: Granularity (simplification), Accuracy (taken for granted)\n\n\n\nObject View\n\nObjects describe individuals that have an identity (id) as well as spatial, temporal, and thematic properties.\nAnswers questions about properties and relations of objects.\nResults from fixing theme, controlling time, and measuring space.\nFeatures, such as surfaces, depend on objects (but are also objects)\n\n\n\nObject View\n\nObject implies boundedness\n\nboundaries may not be known or even knowable, but have limits.\n\nCrude examples of such limits are the minimal bounding boxes used for indexing and querying objects in databases.\nMany objects (particularly natural ones) do not have crisp boundaries (watersheds)\nDifferences between spatial information from multiple sources are often caused by more or less arbitrary delineations through context-dependent boundaries.\nMany questions about objects and features can be answered without boundaries, using simple point representations (centroids) with thematic attributes.\n\n\n\nField View\nFields describe phenomena that have a scalar or vector attribute everywhere in a space of interest\n\nfor example, air temperatures, rainfall, elevation, land cover\n\nField information answers the question what is here?, where here can be anywhere in the space considered.\nField-based spatial information can also represent attributes that are computed rather than measured, such as probabilities or densities.\n\nTogether, fields and objects are the two fundamental ways of structuring spatial information.\n\n\nObjects can provide coverage:\n\nBoth objects and fields can cover space continuously - the primary difference is that objects prescribe bounds.\n\nCounties are one form of object that covers the USA seamlessly\nState objects are another ‚Ä¶\n\n\n\n\nObject Coverages\n\n\n\nLANDSAT Path Row\n\nServes tiles based on a path/row index\n\n\n\n\nMODIS Sinisoial Grid\n\nServes tiles based on a path/row index\n\n\n\n\nUber Hex Addressing\n\nBreaks the world into Hexagons‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwhat3word\n\nBreaks the world into 3m grids encoded with unique 3 word strings\n\n\n\n\nMap Tiles / slippy maps / Pyramids\n\nUse XYZ where Z is a zoom level ‚Ä¶\n\n\n\n\nOur Data for today ‚Ä¶\n\n\nSouthern Counties\n\nsouth_counties = aoi_get(state = \"south\", county = \"all\") |&gt; \n  st_transform(st_crs(cities))\n\nUnioned to States using dplyr\n\nsouth_states = south_counties |&gt; \n  group_by(state_name) |&gt; \n  summarise()\n\nSouth County Centroids\n\nsouth_cent = st_centroid(south_counties)\n\n\n\n\n\n\n\n\n\n\n\nTesselation plotting function\n\nplot_tess = function(data, title){\n  ggplot() + \n    geom_sf(data = data, fill = \"white\", col = \"navy\", size = .2) +   \n    theme_void() +\n    labs(title = title, caption = paste(\"This tesselation has:\", nrow(data), \"tiles\" )) +\n    theme(plot.title = element_text(hjust = .5, color =  \"navy\", face = \"bold\"))\n}\n\n\n\n\n\nplot_tess(south_counties, \"Counties\")\n\n\n\n\nRegular Tiles\n\nOne way to tile a surface is into regions of equal area\nTiles can be either square (rectilinear) or hexagonal\nst_make_grid generates a square or hexagonal grid covering the geometry of an sf or sfc object\nThe return object of st_make_grid is a new sfc object\nGrids can be specified by cellsize or number of grid cells (n) in the X and Y direction\n\n\n# Create a grid over the south with 70 rows and 50 columns\nsq_grid = st_make_grid(south_counties, n = c(70, 50)) |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())\n\n\nplot_tess(sq_grid, \"Square Coverage\")\n\n\n\n\nHexagonal Grid\n\nHexagonal tessellations (honey combs) offer an alternative to square grids\nThey are created in the same way but by setting square = FALSE\n\n\nhex_grid = st_make_grid(south_counties, n = c(70, 50), square = FALSE) |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())\n\n\n\nplot_tess(hex_grid, \"Hexegonal Coverage\")\n\n\n\n\nAdvantages Square Grids\n\nSimple definition and data storage\n\nOnly need the origin (lower left), cell size (XY) and grid dimensions\n\nEasy to aggregate and dissaggregate (resample)\nAnalogous to raster data\nRelationship between cells is given\nCombining layers is easy with traditional matrix algebra\n\n#$ Advantages Square Grids\n\nReduced Edge Effects\n\nLower perimeter to area ratio\nminimizes the amount line length needed to create a lattice of cells with a given area\n\nAll neighbors are identical\n\nNo rook vs queen neighbors\n\nBetter fit to curve surfaces (e.g.¬†the earth)\n\n\n\n\n\n\n\nTriangulations\n\nAn alternative to creating equal area tiles is to create triangulations from known anchor points\nTriangulation requires a set of input points and seeks to partition the interior into a partition of triangles.\nIn GIS contexts you‚Äôll hear:\n\nThiessen Polygon\nVoronoi Regions\nDelunay Triangulation\nTIN (Triangular irregular networks)\netc,..\n\n\n\n\nVoronoi Polygons\n\nVoronoi/Thiessen polygon boundaries define the area closest to each anchor point relative to all others\nThey are defined by the perpendicular bisectors of the lines between all points.\n\n\n\n\nVoronoi Polygons\n\n\n\nVoronoi Polygons\n\nUsefull for tasks such as:\n\nnearest neighbor search,\nfacility location (optimization),\nlargest empty areas,\npath planning‚Ä¶\n\nAlso useful for simple interpolation of values such as rain gauges,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOften used in numerical models and simulations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nst_voronoi\n\nst_voronoi creates voronoi tesselation in sf\nIt works over a MULTIPOINT collection\nShould always be simplified after creation (st_cast())\nIf to be treated as an object for analysis, should be id‚Äôd\n\n\nsouth_cent_u = st_union(south_cent)\n\nv_grid = st_voronoi(south_cent_u) |&gt; \n  st_cast() |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())\n\n\nplot_tess(v_grid, \"Voronoi Coverage\")\n\n\n\n\n\n\n\n\n\nv_grid = st_intersection(v_grid, st_union(south_states))\nplot_tess(v_grid, \"Voroni Coverage\") + \n  geom_sf(data = south_cent, col = \"darkred\", size = .2)\n\n\n\n\n\n\n\n\n\n\nDelaunay triangulation\n\nA Delaunay triangulation for a given set of points (P) in a plane, is a triangulation DT(P), where no point is inside the circumcircle of any triangle in DT(P).\n\n\n\n\nDelaunay triangulation\n\nThe Delaunay triangulation of a discrete POINT set corresponds to the dual graph of the Voronoi diagram.\nThe circumcenters (center of circles) of Delaunay triangles are the vertices of the Voronoi diagram.\n\n\n\n\nUsed in landscape evaluation and terrian modeling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nst_triangulate\n\nst_triangulate creates Delaunay triangulation in sf\nIt works over a MULTIPOINT collection\nShould always be simplified after creation (st_cast())\nIf to be treated as an object for analysis, should be id‚Äôd\n\n\nt_grid = st_triangulate(south_cent_u) |&gt; \n  st_cast() |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())\n\n\nplot_tess(t_grid, \"Square Coverage\")\n\n\n\n\n\n\n\n\n\nt_grid = st_intersection(t_grid, st_union(south_states))\nplot_tess(t_grid, \"Voroni Coverage\") + \n  geom_sf(data = south_cent, col = \"darkred\", size = .3)\n\n\n\n\n\n\n\n\n\n\nDifference in object coverages:\n\n\n\nTesselation Characteristics\n\n\nType\nElements\nMean Area (km2)\nStandard Deviation Area (km2)\nCoverage Area\n\n\n\n\ntriangulation\n2,828\n832\n557\n2,352,288\n\n\nvoroni\n1,421\n1,688\n1,046\n2,398,383\n\n\ncounties\n1,421\n1,688\n1,216\n2,398,383\n\n\ngrid\n3,500\n1,470\n0\n5,144,369\n\n\nHexagon\n3,789\n1,425\n0\n5,398,416\n\n\n\n\n\n\n\n\n\nModifiable areal unit problem (MAUP)\n\nThe modifiable areal unit problem (MAUP) is a source of statistical bias that can significantly impact the results of statistical hypothesis tests.\nMAUP affects results when point-based measures are aggregated into districts.\nThe resulting summary values (e.g., totals or proportions) are influenced by both the shape and scale of the aggregation unit.\n\n\n\n\nSummary\n\nThe power of GIS is the ability to integrate different layers and types of information\nThe scale of information can impact the analysis as can the grouping and zoning schemes chosen\nThe Modifiable Areal Unit Problem (MAUP) is an important issue for those who conduct spatial analysis using units of analysis at aggregations higher than incident level.\nThe MAUP occurs when the aggregate units of analysis are arbitrarily produced or not directly related to the underlying phenomena. A classic example of this problem is Gerrymandering.\nGerrymandering involves shaping and re-shaping voting districts based on the political affiliations of the resident citizenry.\n\n\n\nExamples"
  },
  {
    "objectID": "slides/week-3.html#for-example",
    "href": "slides/week-3.html#for-example",
    "title": "Week 3",
    "section": "For example ‚Ä¶",
    "text": "For example ‚Ä¶\n\nusa &lt;- st_cast(st_union(aoi_get(state = \"conus\")), \"MULTILINESTRING\")\n\nnrow(cities)\n#&gt; [1] 31254\n\n\n\n# Great Circle Distance in GCS\nsystem.time({x &lt;- st_distance(usa, cities)})\n# user      system elapsed \n# 103.560   1.390  117.128 \n\n# Euclidean Distance on PCS\nsystem.time({x &lt;- st_distance(usa, cities, which = \"Euclidean\")})\n# user    system  elapsed \n# 2.422   0.019   2.494"
  },
  {
    "objectID": "slides/week-3.html#units",
    "href": "slides/week-3.html#units",
    "title": "Week 3",
    "section": "Units",
    "text": "Units\nWhen possible measure operations report results with a units appropriate for the CRS:\n\nco &lt;- st_read(\"data/co.shp\")\n#&gt; Reading layer `co' from data source \n#&gt;   `/Users/mikejohnson/github/csu-ess-523c/slides/data/co.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 64 features and 4 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\n#&gt; Geodetic CRS:  WGS 84\na &lt;- st_area(co[1,])\nattributes(a) |&gt; unlist()\n#&gt; units.numerator1 units.numerator2            class \n#&gt;              \"m\"              \"m\"          \"units\"\n\nThe units package can be used to convert between units:\n\nunits::set_units(a, km^2) # result in square kilometers\n#&gt; 3062.85 [km^2]\nunits::set_units(a, ha) # result in hectares\n#&gt; 306285 [ha]\n\nand the results can be stripped of their attributes for cases where numeric values are needed (e.g.¬†math operators and ggplot):\n\nas.numeric(a)\n#&gt; [1] 3062849758"
  },
  {
    "objectID": "slides/week-3.html#spatial-filtering",
    "href": "slides/week-3.html#spatial-filtering",
    "title": "Week 3",
    "section": "Spatial Filtering",
    "text": "Spatial Filtering\n\nWe can filter spatially, use st_filter as the function call\nHere the boolean condition is not passed (e.g.¬†name == WA)\nBut instead, is defined by a spatial predicate\nThe default is st_intersects but can be changed with the .predicate argument:\n\n\n\n\nmutate(states, \n       touch = st_touches(states, wa, sparse = FALSE)) \n#&gt; Simple feature collection with 4 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 41.98818 xmax: -104.0397 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry touch\n#&gt; 1      Idaho MULTIPOLYGON (((-111.0455 4...  TRUE\n#&gt; 2    Montana MULTIPOLYGON (((-109.7985 4... FALSE\n#&gt; 3     Oregon MULTIPOLYGON (((-117.22 44....  TRUE\n#&gt; 4 Washington MULTIPOLYGON (((-121.5237 4... FALSE\n\n\n\nst_filter(states, wa, .predicate = st_touches) \n#&gt; Simple feature collection with 2 features and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.7035 ymin: 41.98818 xmax: -111.0435 ymax: 49.00085\n#&gt; Geodetic CRS:  WGS 84\n#&gt;     name                       geometry\n#&gt; 1  Idaho MULTIPOLYGON (((-111.0455 4...\n#&gt; 2 Oregon MULTIPOLYGON (((-117.22 44...."
  },
  {
    "objectID": "slides/week-3.html#interior-boundary-and-exterior-polygon",
    "href": "slides/week-3.html#interior-boundary-and-exterior-polygon",
    "title": "Week 3",
    "section": "Interior, Boundary and Exterior: POLYGON",
    "text": "Interior, Boundary and Exterior: POLYGON"
  },
  {
    "objectID": "slides/week-3.html#summary",
    "href": "slides/week-3.html#summary",
    "title": "Week 3",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/week-3.html#dimensionally-extended-9-intersection-model",
    "href": "slides/week-3.html#dimensionally-extended-9-intersection-model",
    "title": "Week 3",
    "section": "Dimensionally Extended 9-Intersection Model",
    "text": "Dimensionally Extended 9-Intersection Model\n\nThe DE-9IM is a topological model and (standard) used to describe the spatial relations of two geometries\nUsed in geometry, point-set topology, geospatial topology\nThe DE-9IM matrix provides a way to classify geometry relations using the set {0,1,2,F} or {T,F}\nWith a {T,F} matrix domain, there are 512 possible relations that can be grouped into binary classification schemes.\nAbout 10 of these, have been given a common name such as intersects, touches, and within.\nWhen testing two geometries against a scheme, the result is a spatial predicate named by the scheme.\nProvides the primary basis for queries and assertions in GIS and spatial databases (PostGIS)."
  },
  {
    "objectID": "slides/week-3.html#st_realtes-vs.-predicate-calls",
    "href": "slides/week-3.html#st_realtes-vs.-predicate-calls",
    "title": "Week 3",
    "section": "st_realtes vs.¬†predicate calls‚Ä¶",
    "text": "st_realtes vs.¬†predicate calls‚Ä¶\n\nstates = filter(aoi_get(state = \"all\"), state_abbr %in% c(\"WA\", \"OR\", \"MT\", \"ID\")) |&gt;\n  select(name)\n\nwa = filter(states, name == \"Washington\")\n\n\n\n\nplot(states$geometry)\n\n\n\n\n\n\n\n\n\n\n(mutate(states, \n        deim9 = st_relate(states, wa),\n        touch = st_touches(states, wa, sparse = F)))\n#&gt; Simple feature collection with 4 features and 3 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 41.98818 xmax: -104.0397 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry     deim9 touch\n#&gt; 1      Idaho MULTIPOLYGON (((-111.0455 4... FF2F11212  TRUE\n#&gt; 2    Montana MULTIPOLYGON (((-109.7985 4... FF2FF1212 FALSE\n#&gt; 3     Oregon MULTIPOLYGON (((-117.22 44.... FF2F11212  TRUE\n#&gt; 4 Washington MULTIPOLYGON (((-121.5237 4... 2FFF1FFF2 FALSE"
  },
  {
    "objectID": "slides/week-3.html#binary-predicates",
    "href": "slides/week-3.html#binary-predicates",
    "title": "Week 3",
    "section": "Binary Predicates",
    "text": "Binary Predicates\n\nCollectively, predicates define the type of relationship each 2D object has with another.\nOf the ~ 512 unique relationships offered by the DE-9IM models a selection of ~ 10 have been named.\nThese are include in PostGIS/GEOS and are made accessible via R sf"
  },
  {
    "objectID": "slides/week-3.html#filtering-on-data.frames",
    "href": "slides/week-3.html#filtering-on-data.frames",
    "title": "Week 3",
    "section": "Filtering on data.frames",
    "text": "Filtering on data.frames\n\nWe have used dplyr::filter to subset a data frame, retaining all rows that satisfy a boolean condition.\n\n\n\n\nmutate(states, equalsWA = (name == \"Washington\")) |&gt; \n  st_drop_geometry()\n#&gt;         name equalsWA\n#&gt; 1      Idaho    FALSE\n#&gt; 2    Montana    FALSE\n#&gt; 3     Oregon    FALSE\n#&gt; 4 Washington     TRUE\n\n\n\nfilter(states, name == \"Washington\")\n#&gt; Simple feature collection with 1 feature and 1 field\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 45.54364 xmax: -116.9161 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry\n#&gt; 1 Washington MULTIPOLYGON (((-121.5237 4..."
  },
  {
    "objectID": "slides/week-3.html#spatial-relations-in-r",
    "href": "slides/week-3.html#spatial-relations-in-r",
    "title": "Week 3",
    "section": "Spatial Relations in R",
    "text": "Spatial Relations in R\n\nGeometry X is a 3 feature polygon colored in red\nGeometry Y is a 4 feature polygon colored in blue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nst_relate(x,y)\n#&gt;      [,1]        [,2]        [,3]        [,4]       \n#&gt; [1,] \"212FF1FF2\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\n#&gt; [2,] \"FF2FF1212\" \"212101212\" \"212101212\" \"FF2FF1212\"\n#&gt; [3,] \"FF2FF1212\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\nst_relate(x,x)\n#&gt;      [,1]        [,2]        [,3]       \n#&gt; [1,] \"2FFF1FFF2\" \"FF2F01212\" \"FF2F11212\"\n#&gt; [2,] \"FF2F01212\" \"2FFF1FFF2\" \"FF2FF1212\"\n#&gt; [3,] \"FF2F11212\" \"FF2FF1212\" \"2FFF1FFF2\"\nst_relate(y,y)\n#&gt;      [,1]        [,2]        [,3]        [,4]       \n#&gt; [1,] \"2FFF1FFF2\" \"FF2FF1212\" \"212101212\" \"FF2FF1212\"\n#&gt; [2,] \"FF2FF1212\" \"2FFF1FFF2\" \"212101212\" \"FF2FF1212\"\n#&gt; [3,] \"212101212\" \"212101212\" \"2FFF1FFF2\" \"FF2FF1212\"\n#&gt; [4,] \"FF2FF1212\" \"FF2FF1212\" \"FF2FF1212\" \"2FFF1FFF2\""
  },
  {
    "objectID": "slides/week-3.html#predicates-in-r",
    "href": "slides/week-3.html#predicates-in-r",
    "title": "Week 3",
    "section": "Predicates in R",
    "text": "Predicates in R\nReturns either a sparse matrix\n\nst_intersects(x,y)\n#&gt; Sparse geometry binary predicate list of length 3, where the predicate\n#&gt; was `intersects'\n#&gt;  1: 1, 3\n#&gt;  2: 2, 3\n#&gt;  3: 3\n\nor a dense matrix\n\nst_intersects(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2] [,3]  [,4]\n#&gt; [1,]  TRUE FALSE TRUE FALSE\n#&gt; [2,] FALSE  TRUE TRUE FALSE\n#&gt; [3,] FALSE FALSE TRUE FALSE\n\nst_disjoint(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3] [,4]\n#&gt; [1,] FALSE  TRUE FALSE TRUE\n#&gt; [2,]  TRUE FALSE FALSE TRUE\n#&gt; [3,]  TRUE  TRUE FALSE TRUE\n\nst_touches(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE\n\nst_within(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "slides/week-3.html#named-predicates",
    "href": "slides/week-3.html#named-predicates",
    "title": "Week 3",
    "section": "Named Predicates",
    "text": "Named Predicates\n\n‚Äúnamed spatial predicates‚Äù have been defined for some common relations.\nA few functions can be derived (expressed by masks) from DE-9IM include (* = wildcard):\n\n\n\n\n\n\n\n\n\nPredicate\nDE-9IM String Code\nDescription\n\n\n\n\nIntersects\nT*F**FFF*\n‚ÄúTwo geometries intersect if they share any portion of space‚Äù\n\n\nOverlaps\nT*F**FFF*\n‚ÄúTwo geometries overlap if they share some but not all of the same space‚Äù\n\n\nEquals\nT*F**FFF*\n‚ÄúTwo geometries are topologically equal if their interiors intersect and no part of the interior or boundary of one geometry intersects the exterior of the other‚Äù\n\n\nDisjoint\nFF*FF*****\n‚ÄúTwo geometries are disjoint: they have no point in common. They form a set of disconnected geometries.‚Äù\n\n\nTouches\nFT*******\nF**T*****\n\n\nContains\nT*****FF**\n‚ÄúA contains B: geometry B lies in A, and the interiors intersect‚Äù\n\n\nCovers\nT*****FF*\n*T****FF*\n\n\nWithin\n*T*****FF*\n**T****FF*\n\n\nCovered by\n*T*****FF*\n**T****FF*"
  },
  {
    "objectID": "slides/week-3.html#named-predicates-in-r",
    "href": "slides/week-3.html#named-predicates-in-r",
    "title": "Week 3",
    "section": "Named predicates in R",
    "text": "Named predicates in R\n\nsf provides a set of functions that implement the DE-9IM model and named predicates. Each of these can return either a sparse or dense matrix.\n\nsparse matrix\n\nst_intersects(x,y)\n#&gt; Sparse geometry binary predicate list of length 3, where the predicate\n#&gt; was `intersects'\n#&gt;  1: 1, 3\n#&gt;  2: 2, 3\n#&gt;  3: 3\n\ndense matrix\n\nst_intersects(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2] [,3]  [,4]\n#&gt; [1,]  TRUE FALSE TRUE FALSE\n#&gt; [2,] FALSE  TRUE TRUE FALSE\n#&gt; [3,] FALSE FALSE TRUE FALSE\n\nst_disjoint(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3] [,4]\n#&gt; [1,] FALSE  TRUE FALSE TRUE\n#&gt; [2,]  TRUE FALSE FALSE TRUE\n#&gt; [3,]  TRUE  TRUE FALSE TRUE\n\nst_touches(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE\n\nst_within(x, y, sparse = FALSE)\n#&gt;       [,1]  [,2]  [,3]  [,4]\n#&gt; [1,] FALSE FALSE FALSE FALSE\n#&gt; [2,] FALSE FALSE FALSE FALSE\n#&gt; [3,] FALSE FALSE FALSE FALSE"
  },
  {
    "objectID": "slides/week-3.html#clipping",
    "href": "slides/week-3.html#clipping",
    "title": "Week 3",
    "section": "Clipping",
    "text": "Clipping\n\nClipping is a form of subsetting that involves changing the geometry of at least some features.\nClipping can only apply to features more complex than points: (lines, polygons and their ‚Äòmulti‚Äô equivalents)."
  },
  {
    "objectID": "slides/week-3.html#spatial-subsetting",
    "href": "slides/week-3.html#spatial-subsetting",
    "title": "Week 3",
    "section": "Spatial Subsetting",
    "text": "Spatial Subsetting\n\nBy default the data.frame subsetting methods we‚Äôve seen (e.g [,]) implements st_intersection\n\n\nwa = st_transform(wa, 5070)\nwa_starbucks = starbucks[wa,] #&lt;&lt;\n\nggplot() + geom_sf(data = wa) + geom_sf(data = wa_starbucks) + theme_void()"
  },
  {
    "objectID": "slides/week-3.html#rmapshaper",
    "href": "slides/week-3.html#rmapshaper",
    "title": "Week 3",
    "section": "rmapshaper",
    "text": "rmapshaper\nIn R, the rmapshaper package implements the Visvalingam algorithm in the ms_simplify function.\n\nThe ms_simplify function is a wrapper around the mapshaper JavaScript library (created by lead viz experts at the NYT)\n\n\nlibrary(rmapshaper)\n\nusa10 = ms_simplify(usa, keep = .1)\nusa5  = ms_simplify(usa, keep = .05)\nusa1  = ms_simplify(usa, keep = .01)"
  },
  {
    "objectID": "slides/week-3.html#section-6",
    "href": "slides/week-3.html#section-6",
    "title": "Week 3",
    "section": "",
    "text": "states = st_transform(states, 5070)\nsimp_states   = ms_simplify(states, keep = .05)\nplot(simp_states$geometry)"
  },
  {
    "objectID": "slides/week-3.html#section-7",
    "href": "slides/week-3.html#section-7",
    "title": "Week 3",
    "section": "",
    "text": "In all cases, the number of points in a geometry can be calculated with mapview::npts()\n\nstates = st_transform(states, 5070)\nsimp_states_st   = st_simplify(states, dTolerance = 20000)\nsimp_states_ms   = ms_simplify(states, keep = .05)\n\nmapview::npts(states)\n#&gt; [1] 5930\nmapview::npts(simp_states_st)\n#&gt; [1] 53\nmapview::npts(simp_states_ms)\n#&gt; [1] 292"
  },
  {
    "objectID": "slides/week-3.html#section-8",
    "href": "slides/week-3.html#section-8",
    "title": "Week 3",
    "section": "",
    "text": "plot_tess(south_counties, \"Counties\")"
  },
  {
    "objectID": "slides/week-3.html#our-data-for-today",
    "href": "slides/week-3.html#our-data-for-today",
    "title": "Week 3",
    "section": "Our Data for today ‚Ä¶",
    "text": "Our Data for today ‚Ä¶\nSouthern Counties\n\nsouth_counties = aoi_get(state = \"south\", county = \"all\") |&gt; \n  st_transform(st_crs(cities))\n\n\nUnioned to States using dplyr\n\nsouth_states = south_counties |&gt; \n  group_by(state_name) |&gt; \n  summarise()\n\n\nSouth County Centroids\n\nsouth_cent = st_centroid(south_counties)"
  },
  {
    "objectID": "slides/week-3.html#advantages-square-grids-1",
    "href": "slides/week-3.html#advantages-square-grids-1",
    "title": "Week 3",
    "section": "Advantages Square Grids",
    "text": "Advantages Square Grids\n\nReduced Edge Effects\n\nLower perimeter to area ratio\nminimizes the amount line length needed to create a lattice of cells with a given area\n\nAll neighbors are identical\n\nNo rook vs queen neighbors\n\nBetter fit to curve surfaces (e.g.¬†the earth)"
  },
  {
    "objectID": "slides/week-3.html#difference-in-object-coverages",
    "href": "slides/week-3.html#difference-in-object-coverages",
    "title": "Week 3",
    "section": "Difference in object coverages:",
    "text": "Difference in object coverages:\n\n\n\nTesselation Characteristics\n\n\nType\nElements\nMean Area (km2)\nStandard Deviation Area (km2)\nCoverage Area\n\n\n\n\ntriangulation\n2,828\n832\n557\n2,352,288\n\n\nvoroni\n1,421\n1,688\n1,046\n2,398,383\n\n\ncounties\n1,421\n1,688\n1,216\n2,398,383\n\n\ngrid\n3,500\n1,470\n0\n5,144,369\n\n\nHexagon\n3,789\n1,425\n0\n5,398,416"
  },
  {
    "objectID": "slides/week-3.html#modifiable-areal-unit-problem-maup",
    "href": "slides/week-3.html#modifiable-areal-unit-problem-maup",
    "title": "Week 3",
    "section": "Modifiable areal unit problem (MAUP)",
    "text": "Modifiable areal unit problem (MAUP)\n\nThe modifiable areal unit problem (MAUP) is a source of statistical bias that can significantly impact the results of statistical hypothesis tests.\nMAUP affects results when point-based measures are aggregated into districts.\nThe resulting summary values (e.g., totals or proportions) are influenced by both the shape and scale of the aggregation unit."
  },
  {
    "objectID": "slides/week-3.html#regular-tiles",
    "href": "slides/week-3.html#regular-tiles",
    "title": "Week 3",
    "section": "Regular Tiles",
    "text": "Regular Tiles\n\nOne way to tile a surface is into regions of equal area\nTiles can be either square (rectilinear) or hexagonal\nst_make_grid generates a square or hexagonal grid covering the geometry of an sf or sfc object\nThe return object of st_make_grid is a new sfc object\nGrids can be specified by cellsize or number of grid cells (n) in the X and Y direction\n\n\n# Create a grid over the south with 70 rows and 50 columns\nsq_grid = st_make_grid(south_counties, n = c(70, 50)) |&gt; \n  st_as_sf() |&gt; \n  mutate(id = 1:n())"
  },
  {
    "objectID": "slides/week-3.html#map-tiles-slippy-maps-pyramids",
    "href": "slides/week-3.html#map-tiles-slippy-maps-pyramids",
    "title": "Week 3",
    "section": "Map Tiles / slippy maps / Pyramids",
    "text": "Map Tiles / slippy maps / Pyramids\n\nUse XYZ where Z is a zoom level ‚Ä¶"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-county",
    "href": "slides/week-3.html#southern-coverage-county",
    "title": "Week 3",
    "section": "Southern Coverage: County",
    "text": "Southern Coverage: County"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-square",
    "href": "slides/week-3.html#southern-coverage-square",
    "title": "Week 3",
    "section": "Southern Coverage: Square",
    "text": "Southern Coverage: Square"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-hexagon",
    "href": "slides/week-3.html#southern-coverage-hexagon",
    "title": "Week 3",
    "section": "Southern Coverage: Hexagon",
    "text": "Southern Coverage: Hexagon"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-voronoi",
    "href": "slides/week-3.html#southern-coverage-voronoi",
    "title": "Week 3",
    "section": "Southern Coverage: Voronoi",
    "text": "Southern Coverage: Voronoi"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-triangles",
    "href": "slides/week-3.html#southern-coverage-triangles",
    "title": "Week 3",
    "section": "Southern Coverage: Triangles",
    "text": "Southern Coverage: Triangles"
  },
  {
    "objectID": "slides/week-3.html#wrap-up",
    "href": "slides/week-3.html#wrap-up",
    "title": "Week 3",
    "section": "Wrap up",
    "text": "Wrap up\nToday we covered the following topics: - Spatial predicates and binary predicates - Spatial filtering and joining - Spatial simplification - Spatial tessellations / Coverages - Modifiable areal unit problem (MAUP)\nCombined with your understanding of\n\nGeometry and topology\nCoordinate Reference Systems\nTheir integration with R\n\nWe are well suited to move on to raster data (gridded coverage model!) next week\nCongrats!!"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-voronoi-1",
    "href": "slides/week-3.html#southern-coverage-voronoi-1",
    "title": "Week 3",
    "section": "Southern Coverage: Voronoi",
    "text": "Southern Coverage: Voronoi"
  },
  {
    "objectID": "slides/week-3.html#southern-coverage-triangles-1",
    "href": "slides/week-3.html#southern-coverage-triangles-1",
    "title": "Week 3",
    "section": "Southern Coverage: Triangles",
    "text": "Southern Coverage: Triangles\n\nt_grid = st_intersection(t_grid, st_union(south_states))"
  },
  {
    "objectID": "slides/week-3.html#st_relates-vs.-predicate-calls",
    "href": "slides/week-3.html#st_relates-vs.-predicate-calls",
    "title": "Week 3",
    "section": "st_relates vs.¬†predicate calls‚Ä¶",
    "text": "st_relates vs.¬†predicate calls‚Ä¶\n\nstates = filter(aoi_get(state = \"all\"), state_abbr %in% c(\"WA\", \"OR\", \"MT\", \"ID\")) |&gt;\n  select(name)\n\nwa = filter(states, name == \"Washington\")\n\n\n\n\nplot(states$geometry)\n\n\n\n\n\n\n\n\n\n\n(mutate(states, \n        deim9 = st_relate(states, wa),\n        touch = st_touches(states, wa, sparse = F)))\n#&gt; Simple feature collection with 4 features and 3 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 41.98818 xmax: -104.0397 ymax: 49.00244\n#&gt; Geodetic CRS:  WGS 84\n#&gt;         name                       geometry     deim9 touch\n#&gt; 1      Idaho MULTIPOLYGON (((-111.0455 4... FF2F11212  TRUE\n#&gt; 2    Montana MULTIPOLYGON (((-109.7985 4... FF2FF1212 FALSE\n#&gt; 3     Oregon MULTIPOLYGON (((-117.22 44.... FF2F11212  TRUE\n#&gt; 4 Washington MULTIPOLYGON (((-121.5237 4... 2FFF1FFF2 FALSE"
  },
  {
    "objectID": "labs/Untitled.html",
    "href": "labs/Untitled.html",
    "title": "Lab 2: Distances and Projections",
    "section": "",
    "text": "Question 1:\n\nMaking Spatial Objects & Coordinate Transformation\nSpatial objects (sf) can be built from a vector of X and Y values in addition to a coordinate reference system (CRS). For example:\n\n\n\nQuestion 2:\n\nst_distance review\nThere are two notable things about this result:\n\nIt has units\nIt is returned as a matrix, even though foco only had one row\n\nThis second point highlights a useful feature of st_distance, namley, its ability to return distance matrices between all combinations of features in x and y.\n\n\nunits review\nWhile units are useful, they are not always the preferred units. By default, the units measurement is defined by the projection. For example:\nUnits can be converted using units::set_units. For example, ‚Äòm‚Äô can be converted to ‚Äòkm‚Äô:\nYou might have noticed the data type of the st_distance objects are an S3 class of units. Sometimes, this class can cause problems when trying to using it with other classes or methods:\nIn these cases, the units class can be dropped with units::drop_units\nAs with all functions, these steps can be nested:\n\n\n\nGeometry review\nThere are a few ways to manipulate existing geometries, here we discuss st_union, st_combine and st_cast\n\nst_combine returns a single, combined geometry, with no resolved boundaries.\nst_union() returns a single geometry with resolved boundaries\nst_cast() casts one geometry type to another\n\n\n\n\nQuestion 3:\nIn this section you will extend your growing ggplot skills to handle spatial data using ggrepl to label significant features; gghighlight to emphasize important criteria; and scaled color/fill to create chloropleth represnetations of variables. Below is some example code to provide an example of these tools in action:\n\nGet some data (review)\n\n\nMap"
  }
]