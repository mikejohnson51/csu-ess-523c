[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Welcome!",
    "text": "Welcome!\nWelcome to Ecosystem Science and Sustainability 523c: Environmental Data Science Applications: Water Resources! This class is meant to build on the technical skills you learned in ESS 523a, with a focus on water resource examples. We will cover a range of topics, including data science tools, working with vector and raster data, and machine learning."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nThis website, including all slides, are made with Quarto. Please submit an issue on the GitHub repo for this course if you find something that could be fixed or improved.\nWe borrow significant content from the amazing R community and do our best to curate and design course content for students."
  },
  {
    "objectID": "index.html#reuse-and-licensing",
    "href": "index.html#reuse-and-licensing",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Reuse and licensing",
    "text": "Reuse and licensing\n\nUnless otherwise noted (i.e.¬†not an original creation and reused from another source), these educational materials are licensed under Apache 2."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Schedule",
    "text": "Schedule\n\nComponent 1: Data Science Tools\n Week 01: Level Setting\n Tech Talk 01: Quarto/Flextable\n Lab 01: Lab 1: COVID Trends\n\n\n\nComponent 2: Working with Vector Data\n Week 02: Projections & Measures\n Tech Talk 02: R as a GIS\n Lab 02: Lab 2: Border summaries\n\n Week 03: Predicates & Tesselations\n Tech Talk 03: Interactive Mapping\n Lab 03: Lab 3: Dams in the US\n\n\n\nComponent 3: Working with Raster Data\n Week 04: Raster‚Äôs in R\n Tech Talk 04: STAC\nLab 04: Lab 4: Remote Sensing\n\n Week 05: Terrain Modeling\n Tech Talk 01:OSM HAND\n Lab 05: Lab 5: Terrain & Flood Modeling\n\n\n\nComponent 3: Machine Learning\n Week 06: Feature Engineering & Model Workflows\n Tech Talk 08: Model Options\n Lab 06: Lab 6: CAMELS Data Part 1\n\n Week 07: Model Evaluation & Tuning\n Tech Talk 07: Wrap up\n Lab 07: Lab 6: CAMELS Data Part 2"
  },
  {
    "objectID": "index.html#component-1-data-science-tools",
    "href": "index.html#component-1-data-science-tools",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 1: Data Science Tools",
    "text": "Component 1: Data Science Tools\n Week 01: Level Setting  Lab 01: COVID Trends"
  },
  {
    "objectID": "index.html#component-2-working-with-vector-data",
    "href": "index.html#component-2-working-with-vector-data",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 2: Working with Vector Data",
    "text": "Component 2: Working with Vector Data\n Week 02: Projections & Measures  Lab 02: 100 mile border zone\n Week 03: Predicates & Tesselations  Lab 03: Dams in the US"
  },
  {
    "objectID": "index.html#component-3-working-with-raster-data",
    "href": "index.html#component-3-working-with-raster-data",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 3: Working with Raster Data",
    "text": "Component 3: Working with Raster Data\n Week 04: Raster‚Äôs in R  Lab 04: Remote Sensing\n Week 05: Terrain Mapping  Lab 05: Terrain & Flood Modeling"
  },
  {
    "objectID": "index.html#component-3-machine-learning",
    "href": "index.html#component-3-machine-learning",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Component 3: Machine Learning",
    "text": "Component 3: Machine Learning\nBuild confidence in wrangling, visualizing, and analyzing data. This section covers importing and cleaning data sets, working with joins, and creating effective visualizations. You‚Äôll also delve into study design, hypothesis testing, and statistical analyses spanning uni-variate, bivariate, and multivariate techniques.\n Week 06: Feature Engineering & Model Setup  Lab 06: \n Week 07:   Lab 07:"
  },
  {
    "objectID": "slides/week-1.html#getting-started-with-r-for-data-science",
    "href": "slides/week-1.html#getting-started-with-r-for-data-science",
    "title": "Week 1",
    "section": "üöÄ Getting Started with R for Data Science",
    "text": "üöÄ Getting Started with R for Data Science\n\nWelcome to 523C: Environmental Data Science Applications: Water Resources!\nThis first lecture will introduce essential, high-level topics to help you build a strong foundation in R for environmental data science.\nThroughout the lecture, you will be asked to assess your comfort level with various topics via a Google survey.\nThe survey results will help tailor the course focus, ensuring that we reinforce challenging concepts while avoiding unnecessary review of familiar topics."
  },
  {
    "objectID": "slides/week-1.html#google-survey",
    "href": "slides/week-1.html#google-survey",
    "title": "Week 1",
    "section": "Google Survey",
    "text": "Google Survey\n\nPlease open this survey and answer the questions as we work through this lecture.\nYour responses will provide valuable insights into areas where additional explanations or hands-on exercises may be beneficial.\n\nGoogle Survey"
  },
  {
    "objectID": "slides/week-1.html#data-types",
    "href": "slides/week-1.html#data-types",
    "title": "Week 1",
    "section": "Data Types",
    "text": "Data Types\nR has five principal data types (excluding raw and complex):\n\nCharacter: A string of text, represented with quotes (e.g., ‚Äúhello‚Äù).\n\nUsed to store words, phrases, and categorical data.\n\nInteger: A whole number, explicitly defined with an L suffix (e.g., 42L).\n\nStored more efficiently than numeric values when decimals are not needed.\n\nNumeric: A floating-point number, used for decimal values (e.g., 3.1415).\n\nThis is the default type for numbers in R.\n\nBoolean (Logical): A logical value that represents TRUE or FALSE.\n\nCommonly used in logical operations and conditional statements.\n\n\n\ncharacter &lt;- \"a\"\ninteger &lt;- 1L\nnumeric &lt;- 3.3\nboolean &lt;- TRUE"
  },
  {
    "objectID": "slides/week-1.html#data-structures",
    "href": "slides/week-1.html#data-structures",
    "title": "Week 1",
    "section": "Data Structures",
    "text": "Data Structures\n\nWhen working with multiple values, we need data structures to store and manipulate data efficiently.\nR provides several types of data structures, each suited for different use cases.\n\nVector\n\nA vector is the most basic data structure in R and contains elements of the same type.\nVectors are created using the c() function.\n\n\nchar.vec &lt;- c(\"a\", \"b\", \"c\")\nboolean.vec &lt;- c(TRUE, FALSE, TRUE)\n\n\nLists allow for heterogeneous data types.\n\n\nlist &lt;- list(a = c(1,2,3),\n            b = c(TRUE, FALSE),\n            c = \"test\")"
  },
  {
    "objectID": "slides/week-1.html#installing-packages",
    "href": "slides/week-1.html#installing-packages",
    "title": "Week 1",
    "section": "üì¶ Installing Packages",
    "text": "üì¶ Installing Packages\n\nR has a vast ecosystem of packages that extend its capabilities both on CRAN and github\nTo install a package from CRAN, use install.packages().\nTo install a package from Github, use remotes::install_github()`.\nWe‚Äôll start by installing palmerpenguins, which contains a dataset on penguins.\n\n\ninstall.packages('palmerpenguins')"
  },
  {
    "objectID": "slides/week-1.html#attachingloading-packages",
    "href": "slides/week-1.html#attachingloading-packages",
    "title": "Week 1",
    "section": "Attaching/Loading Packages",
    "text": "Attaching/Loading Packages\n\nTo use an installed package, you need to load it in your current working session using library().\nHere, we load palmerpenguins for dataset exploration and tidyverse for data science workflows.\n\n\nlibrary(palmerpenguins) # üêß Fun dataset about penguins!\nlibrary(tidyverse)      # üõ† Essential for data science in R"
  },
  {
    "objectID": "slides/week-1.html#help-documentation",
    "href": "slides/week-1.html#help-documentation",
    "title": "Week 1",
    "section": "Help & Documentation",
    "text": "Help & Documentation\n\nR has built-in documentation that provides information about functions and datasets.\nTo access documentation, use ?function_name.\nExample: Viewing the help page for the penguins dataset.\n\n\n?penguins\n\n\nYou can also use help.search(\"keyword\") to look up topics of interest.\nFor vignettes (detailed guides), use vignette(\"package_name\")."
  },
  {
    "objectID": "slides/week-1.html#quarto-communication",
    "href": "slides/week-1.html#quarto-communication",
    "title": "Week 1",
    "section": "Quarto: Communication",
    "text": "Quarto: Communication\n\nIn this class we will use Quarto, a more modern, cross langauge version of Rmarkdown\nIf you are comfortable with Rmd, you‚Äôll quickly be able to transition to Qmd\nIf you are new to Rmd, you‚Äôll be able to learn the latest and greatest"
  },
  {
    "objectID": "slides/week-1.html#tidyverse-a-swiss-army-knife-for-data-science-r",
    "href": "slides/week-1.html#tidyverse-a-swiss-army-knife-for-data-science-r",
    "title": "Week 1",
    "section": "üåü Tidyverse: A Swiss Army Knife for Data Science R ",
    "text": "üåü Tidyverse: A Swiss Army Knife for Data Science R \n\nThe tidyverse is a collection of packages designed for data science.\nWe can see what it includes using the tidyverse_packages function:\n\n\ntidyverse_packages()\n#&gt;  [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n#&gt;  [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n#&gt;  [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n#&gt; [13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n#&gt; [17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n#&gt; [21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n#&gt; [25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n#&gt; [29] \"tidyr\"         \"xml2\"          \"tidyverse\""
  },
  {
    "objectID": "slides/week-1.html#glimpse",
    "href": "slides/week-1.html#glimpse",
    "title": "Week 1",
    "section": "glimpse ",
    "text": "glimpse \n\nThe glimpse() function provides a concise summary of a dataset.\n\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "slides/week-1.html#readr",
    "href": "slides/week-1.html#readr",
    "title": "Week 1",
    "section": "readr ",
    "text": "readr \n\nThe readr package provides functions for reading data into R.\nThe read_csv() function reads comma-separated files.\nThe read_tsv() function reads tab-separated files.\nThe read_delim() function reads files with custom delimiters.\nIn all cases, more intellegent parsing is done than with base R equivalents.\n\nread_csv \n\npath = 'https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv'\n\n# base R\nread.csv(path) |&gt; \n  head()\n#&gt;    fips        LON      LAT\n#&gt; 1  1061  -85.83575 31.09404\n#&gt; 2  8125 -102.42587 40.00307\n#&gt; 3 17177  -89.66239 42.35138\n#&gt; 4 28153  -88.69577 31.64132\n#&gt; 5 34041  -74.99570 40.85940\n#&gt; 6 46051  -96.76981 45.17255\n\n# More inutitive readr\nread_csv(path) |&gt; \n  head()\n#&gt; # A tibble: 6 √ó 3\n#&gt;   fips     LON   LAT\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 01061  -85.8  31.1\n#&gt; 2 08125 -102.   40.0\n#&gt; 3 17177  -89.7  42.4\n#&gt; 4 28153  -88.7  31.6\n#&gt; 5 34041  -75.0  40.9\n#&gt; 6 46051  -96.8  45.2"
  },
  {
    "objectID": "slides/week-1.html#dplyr",
    "href": "slides/week-1.html#dplyr",
    "title": "Week 1",
    "section": "dplyr ",
    "text": "dplyr \n\nThe dplyr package provides functions for data manipulation throuhg ‚Äòa grammar for data manipulation‚Äô.\nIt provides capabilities similar to SQL for data manipulation.\nIt includes functions for viewing, filtering, selecting, mutating, summarizing, and joining data."
  },
  {
    "objectID": "slides/week-1.html#left_join",
    "href": "slides/week-1.html#left_join",
    "title": "Week 1",
    "section": "left_join ",
    "text": "left_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  left_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#right_join",
    "href": "slides/week-1.html#right_join",
    "title": "Week 1",
    "section": "right_join ",
    "text": "right_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#inner_join",
    "href": "slides/week-1.html#inner_join",
    "title": "Week 1",
    "section": "inner_join ",
    "text": "inner_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#full_join",
    "href": "slides/week-1.html#full_join",
    "title": "Week 1",
    "section": "full_join ",
    "text": "full_join \n\nselect(penguins, species, contains('bill')) |&gt; \n  right_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species bill_length_mm bill_depth_mm species_id\n#&gt;    &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7          1\n#&gt;  2 Adelie            39.5          17.4          1\n#&gt;  3 Adelie            40.3          18            1\n#&gt;  4 Adelie            NA            NA            1\n#&gt;  5 Adelie            36.7          19.3          1\n#&gt;  6 Adelie            39.3          20.6          1\n#&gt;  7 Adelie            38.9          17.8          1\n#&gt;  8 Adelie            39.2          19.6          1\n#&gt;  9 Adelie            34.1          18.1          1\n#&gt; 10 Adelie            42            20.2          1\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#ggplot2-visualization",
    "href": "slides/week-1.html#ggplot2-visualization",
    "title": "Week 1",
    "section": "ggplot2: Visualization ",
    "text": "ggplot2: Visualization \n\nThe ggplot2 package is used for data visualization.\nIt is based on the ‚Äúgrammar of graphics‚Äù, which allows for a high level of customization.\nggplot2 is built on the concept of layers, where each layer adds a different element to the plot."
  },
  {
    "objectID": "slides/week-1.html#tidyr",
    "href": "slides/week-1.html#tidyr",
    "title": "Week 1",
    "section": "tidyr ",
    "text": "tidyr \n\nThe tidyr package provides functions for data reshaping.\nIt includes functions for pivoting and nesting data."
  },
  {
    "objectID": "slides/week-1.html#drop_na",
    "href": "slides/week-1.html#drop_na",
    "title": "Week 1",
    "section": "drop_na",
    "text": "drop_na\n\nThe drop_na() function is used to remove rows with missing values.\n\n\npenguins |&gt; \n  drop_na()\n#&gt; # A tibble: 333 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  5 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  6 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  7 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  8 Adelie  Torgersen           41.1          17.6               182        3200\n#&gt;  9 Adelie  Torgersen           38.6          21.2               191        3800\n#&gt; 10 Adelie  Torgersen           34.6          21.1               198        4400\n#&gt; # ‚Ñπ 323 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nnest / unnest\n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;"
  },
  {
    "objectID": "slides/week-1.html#broom",
    "href": "slides/week-1.html#broom",
    "title": "Week 1",
    "section": "broom ",
    "text": "broom \n\nThe broom package is used to tidy model outputs.\nIt provides functions to convert model outputs into tidy data frames.\nExample: Tidying the model output."
  },
  {
    "objectID": "slides/week-1.html#purr",
    "href": "slides/week-1.html#purr",
    "title": "Week 1",
    "section": "purr",
    "text": "purr\n\nThe purrr package is used for functional programming.\nIt provides functions for working with lists and vectors.\n\nmap\n\nThe map() function is used to apply a function to each element of a list.\nIt is useful when you want to iterate over a list.\nExample: Fitting a linear model to each species in the penguins dataset.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)))\n#&gt; # A tibble: 3 √ó 3\n#&gt;   species   data               lm    \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;\n\nmap_*\n\nThe map_*() functions are used to extract specific outputs from a list.\nThey are useful when you want to extract specific outputs from a list.\nExample: Extracting the R-squared values (doubles) from the linear models.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm, ~summary(.x)$r.squared))\n#&gt; # A tibble: 3 √ó 4\n#&gt;   species   data               lm        r2\n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;   0.219\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;   0.494\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412\n\nmap2\n\nThe map2() function is used to iterate over two lists in parallel.\nIt is useful when you want to apply a function to two lists simultaneously.\nExample: Augmenting the linear models with the original data.\n\n\npenguins |&gt; \n  drop_na() |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm_mod = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm_mod, ~summary(.x)$r.squared),\n         a  = map2(lm_mod, data, ~broom::augment(.x, .y))) \n#&gt; # A tibble: 3 √ó 5\n#&gt;   species   data               lm_mod    r2 a                  \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt; &lt;list&gt;             \n#&gt; 1 Adelie    &lt;tibble [146 √ó 7]&gt; &lt;lm&gt;   0.216 &lt;tibble [146 √ó 13]&gt;\n#&gt; 2 Gentoo    &lt;tibble [119 √ó 7]&gt; &lt;lm&gt;   0.506 &lt;tibble [119 √ó 13]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412 &lt;tibble [68 √ó 13]&gt;"
  },
  {
    "objectID": "slides/week-1.html#unit-3-machine-learning",
    "href": "slides/week-1.html#unit-3-machine-learning",
    "title": "Week 1",
    "section": "Unit 3: Machine Learning",
    "text": "Unit 3: Machine Learning\n\nlibrary(tidymodels)\ntidymodels_packages()\n#&gt;  [1] \"broom\"        \"cli\"          \"conflicted\"   \"dials\"        \"dplyr\"       \n#&gt;  [6] \"ggplot2\"      \"hardhat\"      \"infer\"        \"modeldata\"    \"parsnip\"     \n#&gt; [11] \"purrr\"        \"recipes\"      \"rlang\"        \"rsample\"      \"rstudioapi\"  \n#&gt; [16] \"tibble\"       \"tidyr\"        \"tune\"         \"workflows\"    \"workflowsets\"\n#&gt; [21] \"yardstick\"    \"tidymodels\""
  },
  {
    "objectID": "slides/week-1.html#seeds-for-reproducability",
    "href": "slides/week-1.html#seeds-for-reproducability",
    "title": "Week 1",
    "section": "Seeds for reproducability",
    "text": "Seeds for reproducability"
  },
  {
    "objectID": "slides/week-1.html#rsamples-for-resampling-and-cross-validation",
    "href": "slides/week-1.html#rsamples-for-resampling-and-cross-validation",
    "title": "Week 1",
    "section": "rsamples for resampling and cross-validation",
    "text": "rsamples for resampling and cross-validation\n\nThe rsample package is used for resampling and cross-validation.\nIt provides functions for creating resamples and cross-validation folds.\nExample: Creating a 5-fold cross-validation object for the penguins dataset.\n\n\nset.seed(123)\n\n(penguins_split &lt;- initial_split(drop_na(penguins), prop = 0.8, strata = species))\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;265/68/333&gt;\npenguins_train  &lt;- training(penguins_split)\npenguins_test   &lt;- testing(penguins_split)\n\npenguin_folds &lt;- vfold_cv(penguins_train, v = 5)"
  },
  {
    "objectID": "slides/week-1.html#recipes-for-feature-engineering",
    "href": "slides/week-1.html#recipes-for-feature-engineering",
    "title": "Week 1",
    "section": "recipes for feature engineering ",
    "text": "recipes for feature engineering \n\nThe recipes package is used for feature engineering.\nIt provides functions for preprocessing data before modeling.\nExample: Defining a recipe for feature engineering the penguins dataset.\n\n\n# Define recipe for feature engineering\npenguin_recipe &lt;- recipe(species ~ ., data = penguins_train) |&gt;\n  step_impute_knn(all_predictors()) |&gt;         # Impute missing values\n  step_normalize(all_numeric_predictors())     # Normalize numeric features"
  },
  {
    "objectID": "slides/week-1.html#parsnip-for-model-selection",
    "href": "slides/week-1.html#parsnip-for-model-selection",
    "title": "Week 1",
    "section": "Parsnip for model selection ",
    "text": "Parsnip for model selection \n\nThe parsnip package is used for model implementation\nIt provides functions for defining models types, engines, and modes.\nExample: Defining models for logistic regression, random forest, and decision tree.\n\n\n# Define models\nlog_reg_model &lt;- multinom_reg() |&gt; \n  set_engine(\"nnet\")  |&gt; \n  set_mode(\"classification\")\n\nrf_model &lt;- rand_forest(trees = 500) |&gt; \n  set_engine(\"ranger\") |&gt; \n  set_mode(\"classification\")\n\ndt_model &lt;- decision_tree() |&gt; \n  set_mode(\"classification\")"
  },
  {
    "objectID": "slides/week-1.html#workflows-for-model-execution",
    "href": "slides/week-1.html#workflows-for-model-execution",
    "title": "Week 1",
    "section": "Workflows for model execution ",
    "text": "Workflows for model execution \n\nThe workflows package is used for model execution.\nIt provides functions for defining and executing workflows.\nExample: Creating a workflow for logistic regression.\n\n\n# Create workflow\nlog_reg_workflow &lt;- workflow() |&gt;\n  add_model(log_reg_model) |&gt;\n  add_recipe(penguin_recipe) |&gt; \n  fit_resamples(resamples = penguin_folds, \n                metrics = metric_set(roc_auc, accuracy))"
  },
  {
    "objectID": "slides/week-1.html#yardstick-for-model-evaluation",
    "href": "slides/week-1.html#yardstick-for-model-evaluation",
    "title": "Week 1",
    "section": "yardstick for model evaluation ",
    "text": "yardstick for model evaluation \n\ncollect_metrics(log_reg_workflow)\n#&gt; # A tibble: 2 √ó 6\n#&gt;   .metric  .estimator  mean     n std_err .config             \n#&gt;   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n#&gt; 1 accuracy multiclass     1     5       0 Preprocessor1_Model1\n#&gt; 2 roc_auc  hand_till      1     5       0 Preprocessor1_Model1"
  },
  {
    "objectID": "slides/week-1.html#workflowsets-for-model-comparison",
    "href": "slides/week-1.html#workflowsets-for-model-comparison",
    "title": "Week 1",
    "section": "workflowsets for model comparison ",
    "text": "workflowsets for model comparison \n\nThe workflowsets package is used for model comparison.\nIt provides functions for comparing multiple models usingthe purrr mapping paradigm\nExample: Comparing logistic regression, random forest, and decision tree models.\n\n\n(workflowset &lt;- workflow_set(list(penguin_recipe), \n                             list(log_reg_model, rf_model, dt_model)) |&gt; \n  workflow_map(\"fit_resamples\", \n               resamples = penguin_folds, \n               metrics = metric_set(roc_auc, accuracy)))\n#&gt; # A workflow set/tibble: 3 √ó 4\n#&gt;   wflow_id             info             option    result   \n#&gt;   &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;   \n#&gt; 1 recipe_multinom_reg  &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n#&gt; 2 recipe_rand_forest   &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;\n#&gt; 3 recipe_decision_tree &lt;tibble [1 √ó 4]&gt; &lt;opts[2]&gt; &lt;rsmp[+]&gt;"
  },
  {
    "objectID": "slides/week-1.html#model-validation",
    "href": "slides/week-1.html#model-validation",
    "title": "Week 1",
    "section": "Model Validation  ",
    "text": "Model Validation  \n\nFinally, we can validate the model on the test set\nThe augment() function is used to add model predictions and residuals to the dataset.\nThe conf_mat() function is used to create a confusion matrix.\nExample: Validating the logistic regression model on the test set.\n\n\nworkflow() |&gt; \n  # Add model and recipe\n  add_model(log_reg_model) |&gt;\n  add_recipe(penguin_recipe) |&gt;\n  # Train model\n  fit(data = penguins_train) |&gt; \n  # Fit trained model to test set\n  fit(data = penguins_test) |&gt;  \n  # Extract Predictions\n  augment(penguins_test) |&gt; \n  conf_mat(truth = species, estimate = .pred_class) \n#&gt;            Truth\n#&gt; Prediction  Adelie Chinstrap Gentoo\n#&gt;   Adelie        30         0      0\n#&gt;   Chinstrap      0        14      0\n#&gt;   Gentoo         0         0     24"
  },
  {
    "objectID": "slides/week-1.html#io",
    "href": "slides/week-1.html#io",
    "title": "Week 1",
    "section": "I/O ",
    "text": "I/O \n\nThe st_read() function is used to read spatial data.\nIt is useful when you want to import spatial data into R for local or remote files.\nExample: Reading a Major Global Rivers."
  },
  {
    "objectID": "slides/week-1.html#geometries",
    "href": "slides/week-1.html#geometries",
    "title": "Week 1",
    "section": "Geometries ",
    "text": "Geometries \n\nThe geometry column contains the spatial information.\nIt is stored as a list-column of sfc objects.\nExample: Accessing the first geometry in the rivers dataset.\n\n\nrivers$geometry[1]\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 144.8258 ymin: 61.40833 xmax: 160.7636 ymax: 68.8008\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#data-manipulation",
    "href": "slides/week-1.html#data-manipulation",
    "title": "Week 1",
    "section": "Data Manipulation ",
    "text": "Data Manipulation \n\nAll dplyr verbs work with sf objects.\nExample: Filtering the rivers dataset to include only the Mississippi River.\n\n\nmississippi &lt;- filter(rivers, SYSTEM == \"Mississippi\")\nlarimer     &lt;- filter(counties, name == \"Larimer\")"
  },
  {
    "objectID": "slides/week-1.html#measures",
    "href": "slides/week-1.html#measures",
    "title": "Week 1",
    "section": "Measures ",
    "text": "Measures \n\nThe st_length() function is used to calculate the length of a geometry.\nThe st_area() function is used to calculate the area of a geometry.\nThe st_distance() function is used to calculate the distance between two geometries.\nExample: Calculating the length of the Mississippi River and the area of Larimer County.\n\n\nst_length(mississippi)\n#&gt; Units: [m]\n#&gt; [1] 1912869 3147943 3331900 1785519\n\nst_area(larimer)\n#&gt; 6813621254 [m^2]\n\nst_distance(larimer, mississippi)\n#&gt; Units: [m]\n#&gt;          [,1]    [,2]   [,3]    [,4]\n#&gt; [1,] 116016.6 1009375 526454 1413983"
  },
  {
    "objectID": "slides/week-1.html#predicates",
    "href": "slides/week-1.html#predicates",
    "title": "Week 1",
    "section": "Predicates ",
    "text": "Predicates \n\nSpatial predicates are used to check relationships between geometries using the DE-9IM model.\nThe st_intersects() function is used to check if geometries intersect.\nThe st_filter() function is used to filter geometries based on a predicate.\n\n\n\n\nst_intersects(counties, mississippi)\n#&gt; Sparse geometry binary predicate list of length 3108, where the\n#&gt; predicate was `intersects'\n#&gt; first 10 elements:\n#&gt;  1: (empty)\n#&gt;  2: (empty)\n#&gt;  3: (empty)\n#&gt;  4: (empty)\n#&gt;  5: (empty)\n#&gt;  6: (empty)\n#&gt;  7: (empty)\n#&gt;  8: (empty)\n#&gt;  9: (empty)\n#&gt;  10: (empty)\n\n\n\nints &lt;- st_filter(counties, mississippi, .predicate = st_intersects)\n\nggplot() + \n  geom_sf(data = ints) +\n  geom_sf(data = mississippi, col = \"blue\") + \n  theme_bw()"
  },
  {
    "objectID": "slides/week-1.html#io-1",
    "href": "slides/week-1.html#io-1",
    "title": "Week 1",
    "section": "I/O ",
    "text": "I/O \n\nAny raster format that GDAL can read, can be read with rast().\nThe package loads the native GDAL src library (like sf)\nrast reads data headers, not data itself, until needed.\nExample: Reading a GeoTIF of Colorado elevation.\n\n\n(elev = terra::rast('data/colorado_elevation.tif'))\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 16893, 21395, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -1146465, -504615, 1566915, 2073705  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source      : colorado_elevation.tif \n#&gt; name        : CONUS_dem \n#&gt; min value   :     98679 \n#&gt; max value   :    439481"
  },
  {
    "objectID": "slides/week-1.html#cropmask",
    "href": "slides/week-1.html#cropmask",
    "title": "Week 1",
    "section": "Crop/Mask ",
    "text": "Crop/Mask \n\nThe crop() function is used to crop a raster to a specific extent.\nIt is useful when you want to work with a subset of the data.\ncrop extracts data (whether from a remote or local source)\nThe mask() function is used to mask a raster using a vector or other extent, keeping only the data within the mask.\nInput extents must match the CRS of the raster data\nExample: Cropping then masking the elevation raster to Larimer County.\n\n\n\n\nlarimer_5070 &lt;- st_transform(larimer, crs(elev))\n\nlarimer_elev = crop(elev, larimer_5070)\n\nplot(larimer_elev)\n\n\n\n\n\n\n\n\n\n\nlarimer_mask &lt;- mask(larimer_elev, larimer_5070)\nplot(larimer_mask)"
  },
  {
    "objectID": "slides/week-1.html#summary-algebra",
    "href": "slides/week-1.html#summary-algebra",
    "title": "Week 1",
    "section": "Summary / Algebra ",
    "text": "Summary / Algebra \n\nRasters can be added, subtracted, multiplied, and divided\nAny form of map algebra can be done with rasters\nFor example, multiplying the Larimer mask by 2\n\n\n\nraw\n\nlarimer_mask\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        : CONUS_dem \n#&gt; min value   :    145787 \n#&gt; max value   :    412773\n\n\nData Operation\n\nelev2 &lt;- larimer_mask^2\n\n\nrast modified by rast\n\nlarimer_mask / elev2\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        :    CONUS_dem \n#&gt; min value   : 2.422639e-06 \n#&gt; max value   : 6.859322e-06\n\n\nstatistical methods\n\n(scaled = scale(larimer_mask))\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 3054, 3469, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 30, 30  (x, y)\n#&gt; extent      : -849255, -745185, 1952655, 2044275  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; varname     : colorado_elevation \n#&gt; name        : CONUS_dem \n#&gt; min value   : -1.562331 \n#&gt; max value   :  3.053412"
  },
  {
    "objectID": "slides/week-1.html#raster-data-store",
    "href": "slides/week-1.html#raster-data-store",
    "title": "Week 1",
    "section": "Raster data store",
    "text": "Raster data store\n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#focal",
    "href": "slides/week-1.html#focal",
    "title": "Week 1",
    "section": "Focal ",
    "text": "Focal \n\nThe focal() function is used to calculate focal statistics.\nIt is useful when you want to calculate statistics for each cell based on its neighbors.\nExample: Calculating the mean elevation within a 30-cell window to remove the NAs we just created\n\n\nxx = terra::focal(larimer_elev, win = 30, fun  = \"mean\", na.policy=\"only\")\nplot(xx)"
  },
  {
    "objectID": "slides/week-1.html#drop_na-na.omit",
    "href": "slides/week-1.html#drop_na-na.omit",
    "title": "Week 1",
    "section": "drop_na / na.omit ",
    "text": "drop_na / na.omit \n\nThe drop_na() function is used to remove rows with missing values.\n\n\npenguins |&gt; \n  drop_na()\n#&gt; # A tibble: 333 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  5 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  6 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  7 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  8 Adelie  Torgersen           41.1          17.6               182        3200\n#&gt;  9 Adelie  Torgersen           38.6          21.2               191        3800\n#&gt; 10 Adelie  Torgersen           34.6          21.1               198        4400\n#&gt; # ‚Ñπ 323 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nnest / unnest \n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;"
  },
  {
    "objectID": "slides/week-1.html#unions-combines",
    "href": "slides/week-1.html#unions-combines",
    "title": "Week 1",
    "section": "Unions / Combines ",
    "text": "Unions / Combines \n\nThe st_union() function is used to combine geometries.\nIt is useful when you want to merge geometries.\n\n\nmississippi\n#&gt; Simple feature collection with 4 features and 4 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112 ymin: 28.92983 xmax: -77.86168 ymax: 48.16158\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 4 √ó 5\n#&gt;   NAME        SYSTEM      MILES KILOMETERS                              geometry\n#&gt; * &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;                 &lt;MULTILINESTRING [¬∞]&gt;\n#&gt; 1 Arkansas    Mississippi 1446.      2327. ((-106.3789 39.36165, -106.3295 39.3‚Ä¶\n#&gt; 2 Mississippi Mississippi 2385.      3838. ((-95.02364 47.15609, -94.98973 47.3‚Ä¶\n#&gt; 3 Missouri    Mississippi 2739.      4408. ((-110.5545 44.76081, -110.6122 44.7‚Ä¶\n#&gt; 4 Ohio        Mississippi 1368.      2202. ((-89.12166 36.97756, -89.17502 37.0‚Ä¶\n\nst_union(mississippi)\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -112 ymin: 28.92983 xmax: -77.86168 ymax: 48.16158\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#terra",
    "href": "slides/week-1.html#terra",
    "title": "Week 1",
    "section": "terra ",
    "text": "terra \n\nThe terra package is used for working with raster data.\nIt provides functions for reading, writing, and manipulating raster data.\n\n\nlibrary(terra)\ngdal()\n#&gt; [1] \"3.10.1\""
  },
  {
    "objectID": "slides/week-1.html#dplyr-1",
    "href": "slides/week-1.html#dplyr-1",
    "title": "Week 1",
    "section": "dplyr ",
    "text": "dplyr \n\nThe dplyr package provides functions for data manipulation.\nIt includes functions for filtering, selecting, mutating, summarizing, and joining data.\n\nselect \n\nThe select() function is used to select columns from a dataset.\nIt is useful when you want to work with specific columns.\nExample: Selecting the species column from the penguins dataset.\n\n\nselect(penguins, species)\n#&gt; # A tibble: 344 √ó 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ‚Ñπ 334 more rows\n\nfilter \n\nThe filter() function is used to filter rows based on a condition.\nIt is useful when you want to work with specific rows.\nExample: Filtering the penguins dataset to include only Adelie penguins.\n\n\nfilter(penguins, species == \"Adelie\")\n#&gt; # A tibble: 152 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 142 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\nmutate \n\nThe mutate() function is used to create new columns or modify existing ones.\nIt is useful when you want to add new information to your dataset.\nExample: Creating a new column bill_length_cm from bill_length_mm.\n\nNote the use of the tidy_select helper starts_with\n\nmutate(penguins, bill_length_cm = bill_length_mm / 100) |&gt; \n  select(starts_with(\"bill\"))\n#&gt; # A tibble: 344 √ó 3\n#&gt;    bill_length_mm bill_depth_mm bill_length_cm\n#&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt;  1           39.1          18.7          0.391\n#&gt;  2           39.5          17.4          0.395\n#&gt;  3           40.3          18            0.403\n#&gt;  4           NA            NA           NA    \n#&gt;  5           36.7          19.3          0.367\n#&gt;  6           39.3          20.6          0.393\n#&gt;  7           38.9          17.8          0.389\n#&gt;  8           39.2          19.6          0.392\n#&gt;  9           34.1          18.1          0.341\n#&gt; 10           42            20.2          0.42 \n#&gt; # ‚Ñπ 334 more rows\n\nsummarize \n\nThe summarize() function is used to aggregate data.\nIt is useful when you want to calculate summary statistics.\nIt always produces a one-row output.\nExample: Calculating the mean bill_length_mm for all penguins\n\n\nsummarize(penguins, bill_length_mm = mean(bill_length_mm, na.rm = TRUE))\n#&gt; # A tibble: 1 √ó 1\n#&gt;   bill_length_mm\n#&gt;            &lt;dbl&gt;\n#&gt; 1           43.9\n\ngroup_by / ungroup \n\nThe group_by() function is used to group data by one or more columns.\nIt is useful when you want to perform operations on groups.\nIt does this by adding a grouped_df class to the dataset.\nThe ungroup() function removes grouping from a dataset.\n\n\ngroups &lt;- group_by(penguins, species)\n\ndplyr::group_keys(groups)\n#&gt; # A tibble: 3 √ó 1\n#&gt;   species  \n#&gt;   &lt;fct&gt;    \n#&gt; 1 Adelie   \n#&gt; 2 Chinstrap\n#&gt; 3 Gentoo\ndplyr::group_indices(groups)[1:5]\n#&gt; [1] 1 1 1 1 1\n\nGroup operations\n\nExample: Grouping the penguins dataset by species and calculating the mean bill_length_mm.\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(bill_length_mm = mean(bill_length_mm, na.rm = TRUE)) |&gt; \n  ungroup()\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   bill_length_mm\n#&gt;   &lt;fct&gt;              &lt;dbl&gt;\n#&gt; 1 Adelie              38.8\n#&gt; 2 Chinstrap           48.8\n#&gt; 3 Gentoo              47.5\n\nJoins \n\nThe dplyr package provides functions for joining datasets.\nCommon join functions include inner_join(), left_join(), right_join(), and full_join().\nJoins are used to combine datasets based on shared keys (primary and foreign).\n\nMutating joins \n\nMutating joins add columns from one dataset to another based on a shared key.\nExample: Adding species information to the penguins dataset based on the species_id.\n\n\nspecies &lt;- tribble(\n  ~species_id, ~species,\n  1, \"Adelie\",\n  2, \"Chinstrap\",\n  3, \"Gentoo\"\n)"
  },
  {
    "objectID": "slides/week-1.html#section",
    "href": "slides/week-1.html#section",
    "title": "Week 1",
    "section": "%>% / |> ",
    "text": "%&gt;% / |&gt; \n\nThe pipe operator %&gt;% is used to chain operations in R.\nThe pipe operator |&gt; is a base R version of %&gt;% introduced in R 4.1.\nThe pipe passes what on the ‚Äúleft hand‚Äù side to the function on the ‚Äúright hand‚Äù side as the first argument.\n\n\npenguins |&gt; \n  glimpse()\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶"
  },
  {
    "objectID": "slides/week-1.html#select",
    "href": "slides/week-1.html#select",
    "title": "Week 1",
    "section": "select ",
    "text": "select \n\nThe select() function is used to select columns from a dataset.\nIt is useful when you want to work with specific columns.\nExample: Selecting the species column from the penguins dataset.\n\n\nselect(penguins, species)\n#&gt; # A tibble: 344 √ó 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#filter",
    "href": "slides/week-1.html#filter",
    "title": "Week 1",
    "section": "filter ",
    "text": "filter \n\nThe filter() function is used to filter rows based on a condition.\nIt is useful when you want to work with specific rows.\nExample: Filtering the penguins dataset to include only Adelie penguins.\n\n\nfilter(penguins, species == \"Adelie\")\n#&gt; # A tibble: 152 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 142 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#mutate",
    "href": "slides/week-1.html#mutate",
    "title": "Week 1",
    "section": "mutate ",
    "text": "mutate \n\nThe mutate() function is used to create new columns or modify existing ones.\nIt is useful when you want to add new information to your dataset.\nExample: Creating a new column bill_length_cm from bill_length_mm.\n\nNote the use of the tidy_select helper starts_with\n\nmutate(penguins, bill_length_cm = bill_length_mm / 100) |&gt; \n  select(starts_with(\"bill\"))\n#&gt; # A tibble: 344 √ó 3\n#&gt;    bill_length_mm bill_depth_mm bill_length_cm\n#&gt;             &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt;  1           39.1          18.7          0.391\n#&gt;  2           39.5          17.4          0.395\n#&gt;  3           40.3          18            0.403\n#&gt;  4           NA            NA           NA    \n#&gt;  5           36.7          19.3          0.367\n#&gt;  6           39.3          20.6          0.393\n#&gt;  7           38.9          17.8          0.389\n#&gt;  8           39.2          19.6          0.392\n#&gt;  9           34.1          18.1          0.341\n#&gt; 10           42            20.2          0.42 \n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#summarize",
    "href": "slides/week-1.html#summarize",
    "title": "Week 1",
    "section": "summarize ",
    "text": "summarize \n\nThe summarize() function is used to aggregate data.\nIt is useful when you want to calculate summary statistics.\nIt always produces a one-row output.\nExample: Calculating the mean bill_length_mm for all penguins\n\n\nsummarize(penguins, bill_length_mm = mean(bill_length_mm, na.rm = TRUE))\n#&gt; # A tibble: 1 √ó 1\n#&gt;   bill_length_mm\n#&gt;            &lt;dbl&gt;\n#&gt; 1           43.9"
  },
  {
    "objectID": "slides/week-1.html#group_by-ungroup",
    "href": "slides/week-1.html#group_by-ungroup",
    "title": "Week 1",
    "section": "group_by / ungroup ",
    "text": "group_by / ungroup \n\nThe group_by() function is used to group data by one or more columns.\nIt is useful when you want to perform operations on groups.\nIt does this by adding a grouped_df class to the dataset.\nThe ungroup() function removes grouping from a dataset.\n\n\ngroups &lt;- group_by(penguins, species)\n\ndplyr::group_keys(groups)\n#&gt; # A tibble: 3 √ó 1\n#&gt;   species  \n#&gt;   &lt;fct&gt;    \n#&gt; 1 Adelie   \n#&gt; 2 Chinstrap\n#&gt; 3 Gentoo\ndplyr::group_indices(groups)[1:5]\n#&gt; [1] 1 1 1 1 1"
  },
  {
    "objectID": "slides/week-1.html#group-operations",
    "href": "slides/week-1.html#group-operations",
    "title": "Week 1",
    "section": "Group operations ",
    "text": "Group operations \n\nExample: Grouping the penguins dataset by species and calculating the mean bill_length_mm.\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(bill_length_mm = mean(bill_length_mm, na.rm = TRUE)) |&gt; \n  ungroup()\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   bill_length_mm\n#&gt;   &lt;fct&gt;              &lt;dbl&gt;\n#&gt; 1 Adelie              38.8\n#&gt; 2 Chinstrap           48.8\n#&gt; 3 Gentoo              47.5"
  },
  {
    "objectID": "slides/week-1.html#joins",
    "href": "slides/week-1.html#joins",
    "title": "Week 1",
    "section": "Joins ",
    "text": "Joins \n\nThe dplyr package provides functions for joining datasets.\nCommon join functions include inner_join(), left_join(), right_join(), and full_join().\nJoins are used to combine datasets based on shared keys (primary and foreign)."
  },
  {
    "objectID": "slides/week-1.html#mutating-joins",
    "href": "slides/week-1.html#mutating-joins",
    "title": "Week 1",
    "section": "Mutating joins ",
    "text": "Mutating joins \n\nMutating joins add columns from one dataset to another based on a shared key.\nExample: Adding species information to the penguins dataset based on the species_id.\n\n\nspecies &lt;- tribble(\n  ~species_id, ~species,\n  1, \"Adelie\",\n  2, \"Chinstrap\",\n  3, \"Gentoo\"\n)"
  },
  {
    "objectID": "slides/week-1.html#filtering-joins",
    "href": "slides/week-1.html#filtering-joins",
    "title": "Week 1",
    "section": "Filtering Joins ",
    "text": "Filtering Joins \n\nFiltering joins retain only rows that match between datasets.\nExample: Filtering the penguins dataset to include only rows with matching species_id.\n\n\nselect(penguins, species, contains('bill')) |&gt; \n  semi_join(species, by = \"species\")\n#&gt; # A tibble: 344 √ó 3\n#&gt;    species bill_length_mm bill_depth_mm\n#&gt;    &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n#&gt;  1 Adelie            39.1          18.7\n#&gt;  2 Adelie            39.5          17.4\n#&gt;  3 Adelie            40.3          18  \n#&gt;  4 Adelie            NA            NA  \n#&gt;  5 Adelie            36.7          19.3\n#&gt;  6 Adelie            39.3          20.6\n#&gt;  7 Adelie            38.9          17.8\n#&gt;  8 Adelie            39.2          19.6\n#&gt;  9 Adelie            34.1          18.1\n#&gt; 10 Adelie            42            20.2\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#ggplot",
    "href": "slides/week-1.html#ggplot",
    "title": "Week 1",
    "section": "ggplot ",
    "text": "ggplot \n\nThe ggplot() function initializes a plot.\nIt provides a blank canvas to which layers can be added.\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-1.html#geom_",
    "href": "slides/week-1.html#geom_",
    "title": "Week 1",
    "section": "geom_* ",
    "text": "geom_* \n\nThe geom_*() functions add geometric objects to the plot.\nThey describe how to render the mapping created in aes\nExample: Adding points to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point()"
  },
  {
    "objectID": "slides/week-1.html#labs",
    "href": "slides/week-1.html#labs",
    "title": "Week 1",
    "section": "labs ",
    "text": "labs \n\nThe labs() function is used to add titles, subtitles, and axis labels to the plot.\nIt is useful for providing context and making the plot more informative.\nExample: Adding titles and axis labels to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species) + \n  theme_linedraw() + \n  labs(title = \"Penguins Weight by Bill Size\", \n       x = \"Body Mass\",\n       y = \"Bill Length\", \n       subtitle = \"Made for 523c\")"
  },
  {
    "objectID": "slides/week-1.html#raster-structure",
    "href": "slides/week-1.html#raster-structure",
    "title": "Week 1",
    "section": "Raster Structure ",
    "text": "Raster Structure \nRaster data is stored as an multi-dimensional array of values. - Remember this is atomic vector with diminisions - The same way we looked\n\nv &lt;- values(elev)\nhead(v)\n#&gt;      CONUS_dem\n#&gt; [1,]    242037\n#&gt; [2,]    243793\n#&gt; [3,]    244464\n#&gt; [4,]    244302\n#&gt; [5,]    244060\n#&gt; [6,]    243888\nclass(v[,1])\n#&gt; [1] \"integer\"\n\ndim(v)\n#&gt; [1] 361425735         1\ndim(elev)\n#&gt; [1] 16893 21395     1\nnrow(elev)\n#&gt; [1] 16893"
  },
  {
    "objectID": "slides/week-1.html#purrr",
    "href": "slides/week-1.html#purrr",
    "title": "Week 1",
    "section": "purrr ",
    "text": "purrr \n\nThe purrr package is used for functional programming.\nIt provides functions for working with lists and vectors."
  },
  {
    "objectID": "slides/week-1.html#machine-learning",
    "href": "slides/week-1.html#machine-learning",
    "title": "Week 1",
    "section": "Machine Learning ",
    "text": "Machine Learning \n\nlibrary(tidymodels)\ntidymodels_packages()\n#&gt;  [1] \"broom\"        \"cli\"          \"conflicted\"   \"dials\"        \"dplyr\"       \n#&gt;  [6] \"ggplot2\"      \"hardhat\"      \"infer\"        \"modeldata\"    \"parsnip\"     \n#&gt; [11] \"purrr\"        \"recipes\"      \"rlang\"        \"rsample\"      \"rstudioapi\"  \n#&gt; [16] \"tibble\"       \"tidyr\"        \"tune\"         \"workflows\"    \"workflowsets\"\n#&gt; [21] \"yardstick\"    \"tidymodels\""
  },
  {
    "objectID": "slides/week-1.html#linear-modeling-lm",
    "href": "slides/week-1.html#linear-modeling-lm",
    "title": "Week 1",
    "section": "linear modeling: lm",
    "text": "linear modeling: lm\n\nThe lm() function is used to fit linear models.\nIt is useful when you want to model the relationship between two variables.\nExample: Fitting a linear model to predict body_mass_g from flipper_length_mm.\n\n\nmodel &lt;- lm(body_mass_g ~ flipper_length_mm, data = drop_na(penguins))\n\nsummary(model)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass_g ~ flipper_length_mm, data = drop_na(penguins))\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1057.33  -259.79   -12.24   242.97  1293.89 \n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)       -5872.09     310.29  -18.93   &lt;2e-16 ***\n#&gt; flipper_length_mm    50.15       1.54   32.56   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 393.3 on 331 degrees of freedom\n#&gt; Multiple R-squared:  0.7621, Adjusted R-squared:  0.7614 \n#&gt; F-statistic:  1060 on 1 and 331 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "slides/week-1.html#tidy",
    "href": "slides/week-1.html#tidy",
    "title": "Week 1",
    "section": "tidy ",
    "text": "tidy \n\nThe tidy() function is used to tidy model coefficients.\nIt is useful when you want to extract model coefficients.\nExample: Tidying the model output.\n\n\ntidy(model)\n#&gt; # A tibble: 2 √ó 5\n#&gt;   term              estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)        -5872.     310.       -18.9 1.18e- 54\n#&gt; 2 flipper_length_mm     50.2      1.54      32.6 3.13e-105"
  },
  {
    "objectID": "slides/week-1.html#glance",
    "href": "slides/week-1.html#glance",
    "title": "Week 1",
    "section": "glance ",
    "text": "glance \n\nThe glance() function is used to provide a summary of model fit.\nIt is useful when you want to assess model performance.\nExample: Glancing at the model output.\n\n\nglance(model)\n#&gt; # A tibble: 1 √ó 12\n#&gt;   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC\n#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     0.762         0.761  393.     1060. 3.13e-105     1 -2461. 4928. 4940.\n#&gt; # ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#augment",
    "href": "slides/week-1.html#augment",
    "title": "Week 1",
    "section": "augment ",
    "text": "augment \n\nThe augment() function is used to add model predictions and residuals to the dataset.\nIt is useful when you want to visualize model performance.\nExample: Augmenting the model output.\n\n\n\n\na &lt;- augment(model)\n\nggplot(a, aes(x = .fitted, y = body_mass_g)) +\n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\nggplot(a, aes(x = .resid)) +\n  geom_histogram()"
  },
  {
    "objectID": "slides/week-1.html#map",
    "href": "slides/week-1.html#map",
    "title": "Week 1",
    "section": "map ",
    "text": "map \n\nThe map() function is used to apply a function to each element of a list.\nIt is useful when you want to iterate over a list.\nExample: Fitting a linear model to each species in the penguins dataset.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)))\n#&gt; # A tibble: 3 √ó 3\n#&gt;   species   data               lm    \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;  \n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;"
  },
  {
    "objectID": "slides/week-1.html#map_",
    "href": "slides/week-1.html#map_",
    "title": "Week 1",
    "section": "map_* ",
    "text": "map_* \n\nThe map_*() functions are used to extract specific outputs from a list.\nThey are useful when you want to extract specific outputs from a list.\nExample: Extracting the R-squared values (doubles) from the linear models.\n\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm, ~summary(.x)$r.squared))\n#&gt; # A tibble: 3 √ó 4\n#&gt;   species   data               lm        r2\n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt;\n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt; &lt;lm&gt;   0.219\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt; &lt;lm&gt;   0.494\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412"
  },
  {
    "objectID": "slides/week-1.html#map2",
    "href": "slides/week-1.html#map2",
    "title": "Week 1",
    "section": "map2 ",
    "text": "map2 \n\nThe map2() function is used to iterate over two lists in parallel.\nIt is useful when you want to apply a function to two lists simultaneously.\nExample: Augmenting the linear models with the original data.\n\n\npenguins |&gt; \n  drop_na() |&gt; \n  nest(data = -species) |&gt; \n  mutate(lm_mod = map(data, ~lm(body_mass_g ~ flipper_length_mm, data = .x)),\n         r2 = map_dbl(lm_mod, ~summary(.x)$r.squared),\n         a  = map2(lm_mod, data, ~broom::augment(.x, .y))) \n#&gt; # A tibble: 3 √ó 5\n#&gt;   species   data               lm_mod    r2 a                  \n#&gt;   &lt;fct&gt;     &lt;list&gt;             &lt;list&gt; &lt;dbl&gt; &lt;list&gt;             \n#&gt; 1 Adelie    &lt;tibble [146 √ó 7]&gt; &lt;lm&gt;   0.216 &lt;tibble [146 √ó 13]&gt;\n#&gt; 2 Gentoo    &lt;tibble [119 √ó 7]&gt; &lt;lm&gt;   0.506 &lt;tibble [119 √ó 13]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;  &lt;lm&gt;   0.412 &lt;tibble [68 √ó 13]&gt;"
  },
  {
    "objectID": "slides/week-1.html#geometry-list-columns",
    "href": "slides/week-1.html#geometry-list-columns",
    "title": "Week 1",
    "section": "Geometry list columns ",
    "text": "Geometry list columns \n\nThe geometry column contains the spatial information.\nIt is stored as a list-column of sfc objects.\nExample: Accessing the first geometry in the rivers dataset.\n\n\nrivers$geometry[1]\n#&gt; Geometry set for 1 feature \n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 144.8258 ymin: 61.40833 xmax: 160.7636 ymax: 68.8008\n#&gt; Geodetic CRS:  WGS 84"
  },
  {
    "objectID": "slides/week-1.html#projections",
    "href": "slides/week-1.html#projections",
    "title": "Week 1",
    "section": "Projections ",
    "text": "Projections \n\nCRS (Coordinate Reference System) is used to define the spatial reference.\nThe st_crs() function is used to get the CRS of a dataset.\nThe st_transform() function is used to transform the CRS of a dataset.\nExample: Transforming the rivers dataset to EPSG:5070.\n\n\nst_crs(rivers) |&gt; sf::st_is_longlat()\n#&gt; [1] TRUE\nst_crs(rivers)$units\n#&gt; NULL\n\nriv_5070  &lt;- st_transform(rivers, 5070)\n\nst_crs(riv_5070) |&gt; sf::st_is_longlat()\n#&gt; [1] FALSE\n\nst_crs(riv_5070)$units\n#&gt; [1] \"m\""
  },
  {
    "objectID": "slides/week-1.html#data-aesthetics",
    "href": "slides/week-1.html#data-aesthetics",
    "title": "Week 1",
    "section": "data / aesthetics ",
    "text": "data / aesthetics \n\nData must be provided to ggplot()\nThe aes() function is used to map variables to aesthetics (e.g., x and y axes).\naes arguments provided in ggplot are inherited by all layers.\nExample: Creating a plot of body_mass_g vs.¬†bill_length_mm.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm))"
  },
  {
    "objectID": "slides/week-1.html#facet_wrap-facet_grid",
    "href": "slides/week-1.html#facet_wrap-facet_grid",
    "title": "Week 1",
    "section": "facet_wrap / facet_grid ",
    "text": "facet_wrap / facet_grid \n\nThe facet_wrap() function is used to create small multiples of a plot.\nIt is useful when you want to compare subsets of data.\nThe facet_grid() function is used to create a grid of plots.\nExample: Faceting the plot by species.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species)"
  },
  {
    "objectID": "slides/week-1.html#theme_",
    "href": "slides/week-1.html#theme_",
    "title": "Week 1",
    "section": "theme_* ",
    "text": "theme_* \n\nThe theme_*() functions are used to customize the appearance of the plot.\nThey allow you to modify the plot‚Äôs background, gridlines, and text.\nExample: Applying the theme_linedraw() theme to the plot.\n\n\nggplot(penguins, aes(x = body_mass_g, y = bill_length_mm)) + \n  geom_point() + \n  facet_wrap(~species) + \n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-1.html#pivot_longer",
    "href": "slides/week-1.html#pivot_longer",
    "title": "Week 1",
    "section": "pivot_longer ",
    "text": "pivot_longer \n\nThe pivot_longer() function is used to convert wide data to long data.\nIt is useful when you want to work with data in a tidy format.\nExample: Converting the penguins dataset from wide to long format.\n\n\n(data.long = penguins |&gt; \n  select(species, bill_length_mm, body_mass_g) |&gt; \n  mutate(penguin_id = 1:n()) |&gt; \n  pivot_longer(-c(penguin_id, species), \n               names_to = \"Measure\", \n               values_to = \"value\"))\n#&gt; # A tibble: 688 √ó 4\n#&gt;    species penguin_id Measure         value\n#&gt;    &lt;fct&gt;        &lt;int&gt; &lt;chr&gt;           &lt;dbl&gt;\n#&gt;  1 Adelie           1 bill_length_mm   39.1\n#&gt;  2 Adelie           1 body_mass_g    3750  \n#&gt;  3 Adelie           2 bill_length_mm   39.5\n#&gt;  4 Adelie           2 body_mass_g    3800  \n#&gt;  5 Adelie           3 bill_length_mm   40.3\n#&gt;  6 Adelie           3 body_mass_g    3250  \n#&gt;  7 Adelie           4 bill_length_mm   NA  \n#&gt;  8 Adelie           4 body_mass_g      NA  \n#&gt;  9 Adelie           5 bill_length_mm   36.7\n#&gt; 10 Adelie           5 body_mass_g    3450  \n#&gt; # ‚Ñπ 678 more rows"
  },
  {
    "objectID": "slides/week-1.html#pivot_wider",
    "href": "slides/week-1.html#pivot_wider",
    "title": "Week 1",
    "section": "pivot_wider ",
    "text": "pivot_wider \n\nThe pivot_wider() function is used to convert long data to wide data.\nIt is useful when you want to work with data in a wide format.\nExample: Converting the data.long dataset from long to wide format.\n\n\ndata.long |&gt; \n  pivot_wider(names_from = \"Measure\", \n              values_from = \"value\")\n#&gt; # A tibble: 344 √ó 4\n#&gt;    species penguin_id bill_length_mm body_mass_g\n#&gt;    &lt;fct&gt;        &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1 Adelie           1           39.1        3750\n#&gt;  2 Adelie           2           39.5        3800\n#&gt;  3 Adelie           3           40.3        3250\n#&gt;  4 Adelie           4           NA            NA\n#&gt;  5 Adelie           5           36.7        3450\n#&gt;  6 Adelie           6           39.3        3650\n#&gt;  7 Adelie           7           38.9        3625\n#&gt;  8 Adelie           8           39.2        4675\n#&gt;  9 Adelie           9           34.1        3475\n#&gt; 10 Adelie          10           42          4250\n#&gt; # ‚Ñπ 334 more rows"
  },
  {
    "objectID": "slides/week-1.html#nest-unnest",
    "href": "slides/week-1.html#nest-unnest",
    "title": "Week 1",
    "section": "nest / unnest ",
    "text": "nest / unnest \n\nThe nest() function is used to nest data into a list-column.\nIt is useful when you want to group data together.\nExample: Nesting the penguins dataset by species.\n\n\npenguins |&gt; \n  nest(data = -species)\n#&gt; # A tibble: 3 √ó 2\n#&gt;   species   data              \n#&gt;   &lt;fct&gt;     &lt;list&gt;            \n#&gt; 1 Adelie    &lt;tibble [152 √ó 7]&gt;\n#&gt; 2 Gentoo    &lt;tibble [124 √ó 7]&gt;\n#&gt; 3 Chinstrap &lt;tibble [68 √ó 7]&gt;\n\npenguins |&gt; \n  nest(data = -species) |&gt; \n  unnest(data)\n#&gt; # A tibble: 344 √ó 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ‚Ñπ 334 more rows\n#&gt; # ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/week-1.html#from-package",
    "href": "slides/week-1.html#from-package",
    "title": "Week 1",
    "section": "From package ",
    "text": "From package \n\n# via packages\n(counties &lt;- AOI::aoi_get(state = \"conus\", county = \"all\"))\n#&gt; Simple feature collection with 3108 features and 14 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -124.8485 ymin: 24.39631 xmax: -66.88544 ymax: 49.38448\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    state_region state_division feature_code state_name state_abbr     name\n#&gt; 1             3              6      0161526    Alabama         AL  Autauga\n#&gt; 2             3              6      0161527    Alabama         AL  Baldwin\n#&gt; 3             3              6      0161528    Alabama         AL  Barbour\n#&gt; 4             3              6      0161529    Alabama         AL     Bibb\n#&gt; 5             3              6      0161530    Alabama         AL   Blount\n#&gt; 6             3              6      0161531    Alabama         AL  Bullock\n#&gt; 7             3              6      0161532    Alabama         AL   Butler\n#&gt; 8             3              6      0161533    Alabama         AL  Calhoun\n#&gt; 9             3              6      0161534    Alabama         AL Chambers\n#&gt; 10            3              6      0161535    Alabama         AL Cherokee\n#&gt;    fip_class tiger_class combined_area_code metropolitan_area_code\n#&gt; 1         H1       G4020                388                   &lt;NA&gt;\n#&gt; 2         H1       G4020                380                   &lt;NA&gt;\n#&gt; 3         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 4         H1       G4020                142                   &lt;NA&gt;\n#&gt; 5         H1       G4020                142                   &lt;NA&gt;\n#&gt; 6         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 7         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 8         H1       G4020                 NA                   &lt;NA&gt;\n#&gt; 9         H1       G4020                122                   &lt;NA&gt;\n#&gt; 10        H1       G4020                 NA                   &lt;NA&gt;\n#&gt;    functional_status  land_area water_area fip_code\n#&gt; 1                  A 1539634184   25674812    01001\n#&gt; 2                  A 4117656514 1132955729    01003\n#&gt; 3                  A 2292160149   50523213    01005\n#&gt; 4                  A 1612188717    9572303    01007\n#&gt; 5                  A 1670259090   14860281    01009\n#&gt; 6                  A 1613083467    6030667    01011\n#&gt; 7                  A 2012002546    2701199    01013\n#&gt; 8                  A 1569246126   16536293    01015\n#&gt; 9                  A 1545085601   16971700    01017\n#&gt; 10                 A 1433620850  120310807    01019\n#&gt;                          geometry\n#&gt; 1  MULTIPOLYGON (((-86.81491 3...\n#&gt; 2  MULTIPOLYGON (((-87.59883 3...\n#&gt; 3  MULTIPOLYGON (((-85.41644 3...\n#&gt; 4  MULTIPOLYGON (((-87.01916 3...\n#&gt; 5  MULTIPOLYGON (((-86.5778 33...\n#&gt; 6  MULTIPOLYGON (((-85.65767 3...\n#&gt; 7  MULTIPOLYGON (((-86.4482 31...\n#&gt; 8  MULTIPOLYGON (((-85.79605 3...\n#&gt; 9  MULTIPOLYGON (((-85.59315 3...\n#&gt; 10 MULTIPOLYGON (((-85.51361 3..."
  },
  {
    "objectID": "slides/week-1.html#from-file",
    "href": "slides/week-1.html#from-file",
    "title": "Week 1",
    "section": "From file ",
    "text": "From file \n\n(rivers &lt;- sf::read_sf('data/majorrivers_0_0/MajorRivers.shp'))\n#&gt; Simple feature collection with 98 features and 4 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -164.8874 ymin: -36.96945 xmax: 160.7636 ymax: 71.39249\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 98 √ó 5\n#&gt;    NAME          SYSTEM MILES KILOMETERS                                geometry\n#&gt;    &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;                   &lt;MULTILINESTRING [¬∞]&gt;\n#&gt;  1 Kolyma        &lt;NA&gt;   2552.      4106. ((144.8419 61.75915, 144.8258 61.8036,‚Ä¶\n#&gt;  2 Parana        Parana 1616.      2601. ((-51.0064 -20.07941, -51.02972 -20.22‚Ä¶\n#&gt;  3 San Francisco &lt;NA&gt;   1494.      2404. ((-46.43639 -20.25807, -46.49835 -20.2‚Ä¶\n#&gt;  4 Japura        Amazon 1223.      1968. ((-76.71056 1.624166, -76.70029 1.6883‚Ä¶\n#&gt;  5 Putumayo      Amazon  890.      1432. ((-76.86806 1.300553, -76.86695 1.295,‚Ä¶\n#&gt;  6 Rio Maranon   Amazon  889.      1431. ((-73.5079 -4.459834, -73.79197 -4.621‚Ä¶\n#&gt;  7 Ucayali       Amazon 1298.      2089. ((-73.5079 -4.459834, -73.51585 -4.506‚Ä¶\n#&gt;  8 Guapore       Amazon  394.       634. ((-65.39585 -10.39333, -65.39578 -10.3‚Ä¶\n#&gt;  9 Madre de Dios Amazon  568.       914. ((-65.39585 -10.39333, -65.45279 -10.4‚Ä¶\n#&gt; 10 Amazon        Amazon 1890.      3042. ((-73.5079 -4.459834, -73.45141 -4.427‚Ä¶\n#&gt; # ‚Ñπ 88 more rows"
  },
  {
    "objectID": "slides/week-1.html#via-url",
    "href": "slides/week-1.html#via-url",
    "title": "Week 1",
    "section": "via url ",
    "text": "via url \n\n# via url\n(gage &lt;- sf::read_sf(\"https://reference.geoconnex.us/collections/gages/items/1000001\"))\n#&gt; Simple feature collection with 1 feature and 17 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -107.2826 ymin: 35.94568 xmax: -107.2826 ymax: 35.94568\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 1 √ó 18\n#&gt;     fid nhdpv2_reach_measure cluster   uri   nhdpv2_comid name  nhdpv2_totdasqkm\n#&gt;   &lt;int&gt;                &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1     1                 80.3 https://‚Ä¶ http‚Ä¶     17789327 PENI‚Ä¶             57.4\n#&gt; # ‚Ñπ 11 more variables: description &lt;chr&gt;, nhdpv2_link_source &lt;chr&gt;,\n#&gt; #   subjectof &lt;chr&gt;, nhdpv2_offset_m &lt;dbl&gt;, provider &lt;chr&gt;,\n#&gt; #   gage_totdasqkm &lt;dbl&gt;, provider_id &lt;chr&gt;, dasqkm_diff &lt;dbl&gt;,\n#&gt; #   nhdpv2_reachcode &lt;chr&gt;, mainstem_uri &lt;chr&gt;, geometry &lt;POINT [¬∞]&gt;\n\n# write out data\n# write_sf(counties, \"data/counties.shp\")"
  },
  {
    "objectID": "slides/week-1.html#additonal-structure",
    "href": "slides/week-1.html#additonal-structure",
    "title": "Week 1",
    "section": "Additonal Structure",
    "text": "Additonal Structure\nIn addition to the values and diminsions, rasters have: - Extent: The spatial extent of the raster. - Resolution: The spatial resolution of the raster pixels. - CRS: The coordinate reference system of the raster.\n\ncrs(elev)\n#&gt; [1] \"PROJCRS[\\\"unnamed\\\",\\n    BASEGEOGCRS[\\\"NAD83\\\",\\n        DATUM[\\\"North American Datum 1983\\\",\\n            ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101004,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4269]],\\n    CONVERSION[\\\"Albers Equal Area\\\",\\n        METHOD[\\\"Albers Equal Area\\\",\\n            ID[\\\"EPSG\\\",9822]],\\n        PARAMETER[\\\"Latitude of false origin\\\",23,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8821]],\\n        PARAMETER[\\\"Longitude of false origin\\\",-96,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8822]],\\n        PARAMETER[\\\"Latitude of 1st standard parallel\\\",29.5,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8823]],\\n        PARAMETER[\\\"Latitude of 2nd standard parallel\\\",45.5,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8824]],\\n        PARAMETER[\\\"Easting at false origin\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8826]],\\n        PARAMETER[\\\"Northing at false origin\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8827]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"easting\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]],\\n        AXIS[\\\"northing\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1,\\n                ID[\\\"EPSG\\\",9001]]]]\"\next(elev)\n#&gt; SpatExtent : -1146465, -504615, 1566915, 2073705 (xmin, xmax, ymin, ymax)\nres(elev)\n#&gt; [1] 30 30"
  },
  {
    "objectID": "slides/week-1.html#raster-structure-1",
    "href": "slides/week-1.html#raster-structure-1",
    "title": "Week 1",
    "section": "Raster Structure ",
    "text": "Raster Structure \n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#value-supersetting",
    "href": "slides/week-1.html#value-supersetting",
    "title": "Week 1",
    "section": "Value Supersetting ",
    "text": "Value Supersetting \n\nRasters are matrices or arrays of values, and can be manipulated as such\nFor example, setting 35% of the raster to NA\n\n\nlarimer_elev[sample(ncell(larimer_elev), .35*ncell(larimer_elev))] &lt;-  NA\n\nplot(larimer_elev)"
  },
  {
    "objectID": "slides/week-1.html#autoplot-rank_results",
    "href": "slides/week-1.html#autoplot-rank_results",
    "title": "Week 1",
    "section": "autoplot / rank_results  ",
    "text": "autoplot / rank_results  \n\nThe autoplot() function is used to visualize model performance.\nThe rank_results() function is used to rank models based on a metric.\nExample: Visualizing and ranking the model results based on the roc_auc (area under the curve) metric.\n\n\n\n\nautoplot(workflowset)\n\n\n\n\n\n\n\n\n\n\nrank_results(workflowset, rank_metric = \"roc_auc\")\n#&gt; # A tibble: 6 √ó 9\n#&gt;   wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n#&gt;   &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n#&gt; 1 recipe_multinom_‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 1     0           5 recipe       mult‚Ä¶     1\n#&gt; 2 recipe_multinom_‚Ä¶ Prepro‚Ä¶ roc_auc 1     0           5 recipe       mult‚Ä¶     1\n#&gt; 3 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 0.981 5.97e-3     5 recipe       rand‚Ä¶     2\n#&gt; 4 recipe_rand_fore‚Ä¶ Prepro‚Ä¶ roc_auc 1.00  3.60e-4     5 recipe       rand‚Ä¶     2\n#&gt; 5 recipe_decision_‚Ä¶ Prepro‚Ä¶ accura‚Ä¶ 0.955 1.28e-2     5 recipe       deci‚Ä¶     3\n#&gt; 6 recipe_decision_‚Ä¶ Prepro‚Ä¶ roc_auc 0.953 1.39e-2     5 recipe       deci‚Ä¶     3"
  },
  {
    "objectID": "index.html#structure",
    "href": "index.html#structure",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Structure",
    "text": "Structure\nIn general ‚Ä¶\n\nMondays will be a lecture,with a mix of slides and discussion.\nWednesdays will be a lab with a introductory ~30 min technical demo, followed by a hands-on lab due the following week.\nGroup work is encouraged, but all assignments should be submitted individually."
  },
  {
    "objectID": "index.html#grades",
    "href": "index.html#grades",
    "title": "Ecosystem Science and Sustainability 523c",
    "section": "Grades",
    "text": "Grades\n\n6 labs will be worth 150 points each.\nThey will be assigned on Wednesdays and due the following Wednesdays before class.\nA final project will be optional and worth 150 extra credit points. It will build on your personal website built in ESS 523a.\n\nThe total points possible is 1050, with the percentage being taken out of 900 using the traditional 90/80/70/60 scales"
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Lab 1: Data Science Tools",
    "section": "",
    "text": "In this lab you will practice data wrangling and visualization skills using COVID-19 data curated by the New York Times. This data is a large dataset measuring the cases and deaths per US county across the lifespan of COVID from its early beginnings to just past the peak. The data stored in daily cummulative counts, is a great example of data that needs to be wrangled and cleaned before any analysis can be done."
  },
  {
    "objectID": "labs/lab1.html#libraries",
    "href": "labs/lab1.html#libraries",
    "title": "Lab 1: Data Science Tools",
    "section": "Libraries",
    "text": "Libraries\nYou will need a few libraries for this lab. Make sure they are installed and loaded in your Qmd:\n\ntidyverse (data wrangling and visualization)\nflextable (make nice tables)\nzoo (rolling averages)"
  },
  {
    "objectID": "labs/lab1.html#data",
    "href": "labs/lab1.html#data",
    "title": "Lab 1: Data Science Tools",
    "section": "Data",
    "text": "Data\nWe are going to practice some data wrangling skills using a real-world dataset about COVID cases curated and maintained by the New York Times. The data was used in the peak of the pandemic to create reports and data visualizations like this, and are archived on a GitHub repo here. A history of the importance can be found here.\nLets pretend it in Feb 1st, 2022. You are a data scientist for the state of Colorado Department of Public Health (this is actually a task I did in California!). You‚Äôve been tasked with giving a report to Governor Polis each morning about the most current COVID-19 conditions at the county level.\nAs it stands, the Colorado Department of Public Health maintains a watch list of counties that are being monitored for worsening corona virus trends. There are six criteria used to place counties on the watch list:\n\nDoing fewer than 150 tests per 100,000 residents daily (over a 7-day average)\nMore than 100 new cases per 100,000 residents over the past 14 days‚Ä¶\n25 new cases per 100,000 residents and an 8% test positivity rate\n10% or greater increase in COVID-19 hospitalized patients over the past 3 days\nFewer than 20% of ICU beds available\nFewer than 25% ventilators available\n\nOf these 6 conditions, you are in charge of monitoring condition number 2."
  },
  {
    "objectID": "labs/lab1.html#steps",
    "href": "labs/lab1.html#steps",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nStart by reading in the data from the NY-Times URL with read_csv (make sure to attach the tidyverse). The data read from Github is considered our ‚Äúraw data‚Äù. Remember to always leave ‚Äúraw-data-raw‚Äù and to generate meaningful subsets as you go.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(flextable)\ndata &lt;- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\n\n\n\nCreate an object called my.date and set it as ‚Äú2022-02-01‚Äù - ensure this is a date object.\nCreate a object called my.state and set it to ‚ÄúColorado‚Äù.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIn R, as.Date() is a function used to convert character strings, numeric values, or other date-related objects into Date objects. It ensures that dates are stored in the correct format for date-based calculations and manipulations.\n\n\nCode\ntxt &lt;- \"2025-02-15\"\nclass(txt)\n\n\n[1] \"character\"\n\n\nCode\ndate_example &lt;- as.Date(txt)\nclass(date_example)\n\n\n[1] \"Date\"\n\n\n\n\n\n\n\nCode\nmy.date  &lt;- as.Date(\"2022-02-01\")\nmy.state &lt;- \"Colorado\"\n\n\n\nStart by making a subset that limits the data to Colorado (filter), and add a new column (mutate) with the daily new cases using diff/lag by county (group_by). Do the same for new deaths. If lag is new to you, lag is a function that shifts a vector by a specified number of positions. The help file can be found with ?lag.\n\n(Hint: you will need some combination of filter, group_by, arrange, mutate, diff/lag, and ungroup)\n\nUsing your subset, generate (2) tables. The first should show the 5 counties with the most CUMULATIVE cases on you date of interest, and the second should show the 5 counties with the most NEW cases on that same date. Remember to use your my.date object as a proxy for today‚Äôs date:\n\nYour tables should have clear column names and descriptive captions.\n(Hint: Use flextable::flextable() and flextable::set_caption())"
  },
  {
    "objectID": "labs/lab1.html#steps-1",
    "href": "labs/lab1.html#steps-1",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nGiven the above URL, and guidelines on string concatenation, read in the population data and (1) create a five digit FIP variable and only keep columns that contain ‚ÄúNAME‚Äù or ‚Äú2021‚Äù (remember the tidyselect option found with ?dplyr::select). Additionally, remove all state level rows (e.g.¬†COUNTY FIP == ‚Äú000‚Äù)\n\n\nNow, explore the data ‚Ä¶ what attributes does it have, what are the names of the columns? Do any match the COVID data we have? What are the dimensions‚Ä¶ In a few sentences describe the data obtained after modification:\n\n(Hint: names(), dim(), nrow(), str(), glimpse(), skimr,‚Ä¶))"
  },
  {
    "objectID": "labs/lab1.html#steps-2",
    "href": "labs/lab1.html#steps-2",
    "title": "Lab 1: Data Science Tools",
    "section": "Steps:",
    "text": "Steps:\n\nFirst, we need to group/summarize our county level data to the state level, filter it to the four states of interest, and calculate the number of daily new cases (diff/lag) and the 7-day rolling mean.\n\n\n\n\n\n\n\nRolling Averages\n\n\n\n\n\nThe rollmean function from the zoo package in R is used to compute the rolling (moving) mean of a numeric vector, matrix, or zoo/ts object.\nrollmean(x, k, fill = NA, align = \"center\", na.pad = FALSE)\n- x: Numeric vector, matrix, or time series.\n- k: Window size (number of observations).\n- fill: Values to pad missing results (default NA).\n- align: Position of the rolling window (‚Äúcenter‚Äù, ‚Äúleft‚Äù, ‚Äúright‚Äù).\n- na.pad: If TRUE, pads missing values with NA.\n\n\nExamples\n\nRolling Mean on a Numeric Vector Since align = \"center\" by default, values at the start and end are dropped.\n\n\n\nCode\nlibrary(zoo)\n\n# Sample data\nx &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n# Rolling mean with a window size of 3\nrollmean(x, k = 3)\n\n\n[1] 2 3 4 5 6 7 8 9\n\n\n\nRolling Mean with Padding Missing values are filled at the start and end.\n\n\n\nCode\nrollmean(x, k = 3, fill = NA)\n\n\n [1] NA  2  3  4  5  6  7  8  9 NA\n\n\n\nAligning Left or Right The rolling mean is calculated with values aligned to the left or right\n\n\n\nCode\nrollmean(x, k = 3, fill = NA, align = \"left\")\n\n\n [1]  2  3  4  5  6  7  8  9 NA NA\n\n\nCode\nrollmean(x, k = 3, fill = NA, align = \"right\")\n\n\n [1] NA NA  2  3  4  5  6  7  8  9\n\n\n\n\n\n\nHint: You will need two group_by calls and the zoo::rollmean function.\n\nUsing the modified data, make a facet plot of the daily new cases and the 7-day rolling mean. Your plot should use compelling geoms, labels, colors, and themes.\n\n\nThe story of raw case counts can be misleading. To understand why, lets explore the cases per capita of each state. To do this, join the state COVID data to the population estimates and calculate the \\(new cases / total population\\). Additionally, calculate the 7-day rolling mean of the new cases per capita counts. This is a tricky task and will take some thought, time, and modification to existing code (most likely)!\n\nHint: You may need to modify the columns you kept in your original population data. Be creative with how you join data (inner vs outer vs full)!\n\nUsing the per capita data, plot the 7-day rolling averages overlying each other (one plot) with compelling labels, colors, and theme.\n\n\nBriefly describe the influence scaling by population had on the analysis? Does it make some states look better? Some worse? How so?\n\n\n‚Ä¶"
  },
  {
    "objectID": "labs/lab1.html#data-preparation",
    "href": "labs/lab1.html#data-preparation",
    "title": "Lab 1: Data Science Tools",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLet‚Äôs start with the raw COVID dataset, and compute county level daily new cases and deaths (lag). Then, join it to the census data in order to use population data in the model.\nWe are aware there was a strong seasonal component to the spread of COVID-19. To account for this, lets add a new column to the data for year (lubridate::year()), month (lubridate::month()), and season (dplyr::case_when()) which will be one of four values: ‚ÄúSpring‚Äù (Mar-May), ‚ÄúSummer‚Äù (Jun-Aug), ‚ÄúFall‚Äù (Sep-Nov), or ‚ÄúWinter‚Äù (Dec - Jan) based on the computed Month.\nNext, lets group the data by state, year, and season and summarize the total population, new cases, and new deaths per grouping.\nGiven the case/death counts are not scaled by population, we expect that each will exhibit a right skew behavior (you can confirm this with density plots, shapiro.test, or histrograms). Given an assumption of linear models is normality in the data, let‚Äôs apply a log transformation to cases, deaths, and population to normalize them.\n\n\n\n\n\n\n\nNote\n\n\n\nWe know there are 0‚Äôs in the data (cases/deaths), so we can add 1 to the data before taking the log. As the log of 0 is undefined, adding 1 ensures that the log of 0 is -Inf.\n\n\nCode\nlog(0)\n\n\n[1] -Inf"
  },
  {
    "objectID": "labs/lab1.html#model-building",
    "href": "labs/lab1.html#model-building",
    "title": "Lab 1: Data Science Tools",
    "section": "Model Building",
    "text": "Model Building\n\nOnce the data has been prepared, build a linear model (lm) to predict the log of cases using the log of deaths the log of population, and the season. Be sure to add an interaction term for population and deaths since they per capita realtionship is significant!\nOnce the model is built, summarize it (summary) and report the R-squared value and the p-value of the model. What does this mean for the value of its application?"
  },
  {
    "objectID": "slides/week-1.html",
    "href": "slides/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to 523C: Environmental Data Science Applications: Water Resources!\nThis first lecture will introduce essential, high-level topics to help you build a strong foundation in R for environmental data science.\nThroughout the lecture, you will be asked to assess your comfort level with various topics via a Google survey.\nThe survey results will help tailor the course focus, ensuring that we reinforce challenging concepts while avoiding unnecessary review of familiar topics."
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Lab 2: Distances and Projections",
    "section": "",
    "text": "In this lab we will explore the properties of sf, sfc, and sfg features & objects; how they are stored; and issues related to distance calculation and coordinate transformation.\nWe will continue to build on our data wrangling and data visualization skills; as well as document preparation via Quarto and GitHub.\n\n\nSet-up\n\nNavigage to your csu-523c repository\nCreate a new Quarto (.qmd) file called lab-02.qmd\nPopulate its YML with a title, author, subtitle, output type and theme. For example:\n\n\n\nCode\n---\ntitle: \"Lab 02: Distances and the Border Zone\"\nsubtitle: 'Ecosystem Science and Sustainability 523c'\nauthor:\n  - name: ...\n    email: ...\nformat: html\n---\n\n\n\n\n\nLibraries\n\n\nCode\n# spatial data science\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(units)\n\n# Data\nlibrary(USAboundaries)\nlibrary(rnaturalearth)\n\n# Visualization\nlibrary(gghighlight)\nlibrary(ggrepel)\nlibrary(knitr)\n\n\n\n\n\nBackground\nIn this lab, 4 main skills are covered:\n\nIngesting / building sf objects from R packages and CSVs. (Q1)\nManipulating geometries and coordinate systems (Q2)\nCalculating distances (Q2)\nBuilding maps using ggplot (Q3)\n\nHints and Tricks for this lab are available here\n\n\n\nQuestion 1:\nFor this lab we need three (3) datasets.\n\nSpatial boundaries of continental USA states (1.1)\nBoundaries of Canada, Mexico and the United States (1.2)\nAll USA cites (1.3)\n\n\n1.1 Define a Projection\nFor this lab we want to calculate distances between features, therefore we need a projection that preserves distance at the scale of CONUS. For this, we will use the North America Equidistant Conic:\n\n\nCode\neqdc &lt;- '+proj=eqdc +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs'\n\n\nUnfortunately, this projection does not have a EPSG code to reference so we must use the PROJ4 string above. Take a moment and describe this proection based on the parameters:\n\n\n1.2 - Get USA state boundaries\nIn R, USA boundaries are stored in the USAboundaries package. In case this package and data are not installed:\n\n\nCode\nremotes::install_github(\"ropensci/USAboundaries\")\nremotes::install_github(\"ropensci/USAboundariesData\")\n\n\nOnce installed:\n\nUSA state boundaries can be accessed with USAboundaries::us_states(resolution = \"low\"). Given the precision needed for this analysis we are ok with the low resolution.\nMake sure you only have the states in the continental United States (CONUS) (Hint use filter)\nMake sure the data is in a projected coordinate system suitable for distance measurements at the national scale (eqdc).\n\n\n\n\n1.3 - Get country boundaries for Mexico, the United States of America, and Canada\nIn R, country boundaries are stored in the rnaturalearth package. In case this package is not installed:\n\n\nCode\nremotes::install_github(\"ropenscilabs/rnaturalearthdata\")\n\n\nOnce installed:\n\nWorld boundaries can be accessed with rnaturalearth::countries110.\nMake sure the data is in simple features (sf) format (Hint use the st_as_sf variable).\nMake sure you only have the countries you want (Hint filter on the admin variable)\nMake sure the data is in a projected coordinate system suitable for distance measurements at the national scale (eqdc).\n\n\n\n\n1.4 - Get city locations from the CSV file\nThe process of finding, downloading and accessing data is the first step of every analysis. Here we will go through these steps (minus finding the data).\nFirst go to this site and download the appropriate (free) dataset into the data directory of this project.\nOnce downloaded, read it into your working session using readr::read_csv() and explore the dataset until you are comfortable with the information it contains.\nWhile this data has everything we want, it is not yet spatial. Convert the data.frame to a spatial object using st_as_sf and prescribing the coordinate variables and CRS (Hint what projection are the raw coordinates in?)\nFinally, remove cities in states not wanted and make sure the data is in a projected coordinate system suitable for distance measurements at the national scale:\nCongratulations! You now have three real-world, large datasets ready for analysis.\n\n\n\nQuestion 2:\nHere we will focus on calculating the distance of each USA city to (1) the national border (2) the nearest state border (3) the Mexican border and (4) the Canadian border. You will need to manipulate you existing spatial geometries to do this using either st_union or st_combine depending on the situation. In all cases, since we are after distances to borders, we will need to cast (st_cast) our MULTIPPOLYGON geometries to MULTILINESTRING geometries. To perform these distance calculations we will use st_distance().\n\n2.1 - Distance to USA Border (coastline or national) (km)\nFor 2.2 we are interested in calculating the distance of each USA city to the USA border (coastline or national border). To do this we need all states to act as single unit. Convert the USA state boundaries to a MULTILINESTRING geometry in which the state boundaries are resolved. Please do this starting with the states object and NOT with a filtered country object. In addition to storing this distance data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.2 - Distance to States (km)\nFor 2.1 we are interested in calculating the distance of each city to the nearest state boundary. To do this we need all states to act as single unit. Convert the USA state boundaries to a MULTILINESTRING geometry in which the state boundaries are preserved (not resolved). In addition to storing this distance data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.3 - Distance to Mexico (km)\nFor 2.3 we are interested in calculating the distance of each city to the Mexican border. To do this we need to isolate Mexico from the country objects. In addition to storing this data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n2.4 - Distance to Canada (km)\nFor 2.4 we are interested in calculating the distance of each city to the Canadian border. To do this we need to isolate Canada from the country objects. In addition to storing this data as part of the cities data.frame, produce a table (flextable) documenting the five cities farthest from a state border. Include only the city name, state, and distance.\n\n\n\nQuestion 3:\nIn this section we will focus on visualizing the distance data you calculated above. You will be using ggplot to make your maps, ggrepl to label significant features, and gghighlight to emphasize important criteria.\n\n3.1 Data\nShow the 3 continents, CONUS outline, state boundaries, and 10 largest USA cities (by population) on a single map\n\nUse geom_sf to plot your layers\nUse lty to change the line type and size to change line width\nUse ggrepel::geom_label_repel to label your cities\n\n\n\n3.2 City Distance from the Border\nCreate a map that colors USA cities by their distance from the national border. In addition, re-draw and label the 5 cities that are farthest from the border.\n\n\n3.3 City Distance from Nearest State\nCreate a map that colors USA cities by their distance from the nearest state border. In addition, re-draw and label the 5 cities that are farthest from any border.\n\n\n3.4 Equidistance boundary from Mexico and Canada\nHere we provide a little more challenge. Use gghighlight to identify the cities that are equal distance from the Canadian AND Mexican border \\(\\pm\\) 100 km.\nIn addition, label the five (5) most populous cites in this zone.\nHint: (create a new variable that finds the absolute difference between the distance to Mexico and the distance to Canada)\n\n\n\nQuestion 4:\n\nReal World Application\nRecently, Federal Agencies have claimed basic constitutional rights protected by the Fourth Amendment (protecting Americans from random and arbitrary stops and searches) do not apply fully at our borders (see Portland). For example, federal authorities do not need a warrant or suspicion of wrongdoing to justify conducting what courts have called a ‚Äúroutine search,‚Äù such as searching luggage or a vehicle. Specifically, federal regulations give U.S. Customs and Border Protection (CBP) authority to operate within 100 miles of any U.S. ‚Äúexternal boundary‚Äù. Further information can be found at this ACLU article.\n\n\n4.1 Quantifing Border Zone\n\nHow many cities are in this 100 mile zone? (100 miles ~ 160 kilometers)\nHow many people live in a city within 100 miles of the border?\nWhat percentage of the total population is in this zone?\nDoes it match the ACLU estimate in the link above?\n\nReport this information as a table.\n\n\n4.2 Mapping Border Zone\n\nMake a map highlighting the cites within the 100 mile zone using gghighlight.\nUse a color gradient from ‚Äòorange‚Äô to ‚Äòdarkred‚Äô.\nLabel the 10 most populous cities in the Danger Zone\n\nExtra Credit (10): Instead of labeling the 10 most populous cites, label the most populous city in each state within the Danger Zone.\n\n\n\n\nRubric\n\nQuestion 1 (10)\nQuestion 2 (35)\nQuestion 3 (25)\nQuestion 4 (20)\nExtra Credit (10)\nWell Structured and appealing Rmd deployed as web page (10)\n\nTotal: 100 points (110 points total)\n\n\nSubmission\nFor this lab you will submit a URL to a webpage deployed with GitHub pages.\nTo do this:\n\nKnit your lab document\nStage/commit/push your files\nIf you followed the naming conventions in the ‚ÄúSet Up‚Äù, your lab 3 link will be available at:\n\n`https://USERNAME.github.io/csu-523c/lab-02.html``\nSubmit this URL in the appropriate Gauchospace dropbox. Also take a moment to update your personal webpage with this link and some bullet points of what you learned. While not graded as part of this lab, it will be your final!"
  },
  {
    "objectID": "slides/week-2.html",
    "href": "slides/week-2.html",
    "title": "week-2",
    "section": "",
    "text": "Projections & Measures\nLecture 10, Lecture 11, Lecture 13 (centroids/buffers forward)\n\n\nPredicates & Tesselations\nLecture 12, 15"
  },
  {
    "objectID": "labs/lab2-hints.html",
    "href": "labs/lab2-hints.html",
    "title": "Lab 2: Distances and Projections",
    "section": "",
    "text": "Question 1:\n\nMaking Spatial Objects & Coordinate Transformation\nSpatial objects (sf) can be built from a vector of X and Y values in addition to a coordinate reference system (CRS). For example:\n\n\nCode\ndf &lt;- data.frame(name = state.name, \n                X = state.center$x, \n                Y = state.center$y)\nhead(df)\n\n\n        name         X       Y\n1    Alabama  -86.7509 32.5901\n2     Alaska -127.2500 49.2500\n3    Arizona -111.6250 34.2192\n4   Arkansas  -92.2992 34.7336\n5 California -119.7730 36.5341\n6   Colorado -105.5130 38.6777\n\n\nCode\n# Geographic Coordinate System (GCS)\n(df_sf_gcs &lt;- st_as_sf(df, \n                      coords = c(\"X\", \"Y\"), \n                      crs = 4269))\n\n\nSimple feature collection with 50 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -127.25 ymin: 27.8744 xmax: -68.9801 ymax: 49.25\nGeodetic CRS:  NAD83\nFirst 10 features:\n          name                 geometry\n1      Alabama POINT (-86.7509 32.5901)\n2       Alaska    POINT (-127.25 49.25)\n3      Arizona POINT (-111.625 34.2192)\n4     Arkansas POINT (-92.2992 34.7336)\n5   California POINT (-119.773 36.5341)\n6     Colorado POINT (-105.513 38.6777)\n7  Connecticut POINT (-72.3573 41.5928)\n8     Delaware POINT (-74.9841 38.6777)\n9      Florida  POINT (-81.685 27.8744)\n10     Georgia POINT (-83.3736 32.3329)\n\n\nCode\nggplot() + \n  geom_sf(data = df_sf_gcs) + \n  coord_sf(datum = st_crs(df_sf_gcs)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nCode\n# Projected Coordinate System (PCS)\n# st_transforms converts from one reference system to another\n(df_sf_pcs = st_transform(df_sf_gcs, 5070))\n\n\nSimple feature collection with 50 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -2805703 ymin: 640477 xmax: 2079664 ymax: 3291437\nProjected CRS: NAD83 / Conus Albers\nFirst 10 features:\n          name                  geometry\n1      Alabama  POINT (862043.5 1099545)\n2       Alaska  POINT (-2264853 3291437)\n3      Arizona  POINT (-1422260 1356663)\n4     Arkansas  POINT (336061.5 1303543)\n5   California  POINT (-2086972 1760961)\n6     Colorado POINT (-818480.9 1779785)\n7  Connecticut   POINT (1936213 2307450)\n8     Delaware   POINT (1796466 1938236)\n9      Florida    POINT (1409814 640477)\n10     Georgia   POINT (1179012 1107322)\n\n\nCode\nggplot() + \n  geom_sf(data = df_sf_pcs) + \n  coord_sf(datum = st_crs(df_sf_pcs)) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2:\n\nst_distance review\n\n\nCode\n# Three most populous cities in the USA\n(big3 = cities |&gt; \n   select(city, population) |&gt; \n   slice_max(population, n = 3))\n\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -2032604 ymin: 1468468 xmax: 1833394 ymax: 2178657\nProjected CRS: NAD83 / Conus Albers\n# A tibble: 3 √ó 3\n  city        population           geometry\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;POINT [m]&gt;\n1 New York      18832416  (1833394 2178657)\n2 Los Angeles   11885717 (-2032604 1468468)\n3 Chicago        8489066 (684628.5 2122697)\n\n\nCode\n# Fort Collins\n(fc = filter(cities, city == \"Fort Collins\") |&gt; \n    select(city, population))\n\n\nSimple feature collection with 1 feature and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -760147.5 ymin: 1984621 xmax: -760147.5 ymax: 1984621\nProjected CRS: NAD83 / Conus Albers\n# A tibble: 1 √ó 3\n  city         population            geometry\n  &lt;chr&gt;             &lt;dbl&gt;         &lt;POINT [m]&gt;\n1 Fort Collins     339256 (-760147.5 1984621)\n\n\nCode\n# Distance from FC to population centers\nst_distance(big3, fc)\n\n\nUnits: [m]\n        [,1]\n[1,] 2600790\n[2,] 1373156\n[3,] 1451359\n\n\nThere are two notable things about this result:\n\nIt has units\nIt is returned as a matrix, even though SB only had one row\n\nThis second point highlights a useful feature of st_distance, namley, its ability to return distance matrices between all combinations of features in x and y.\n\n\nunits review\nWhile units are useful, they are not always the preferred units. By default, the units measurement is defined by the projection. For example:\n\n\nCode\nst_crs(big3)$units\n\n\n[1] \"m\"\n\n\nUnits can be converted using units::set_units. For example, ‚Äòm‚Äô can be converted to ‚Äòkm‚Äô:\n\n\nCode\nbig3 = mutate(big3, \n              dist_to_fc = st_distance(big3, fc),\n              dist_to_fc = set_units(dist_to_fc, \"km\")) \n\n(big3$dist_to_fc)\n\n\nUnits: [km]\n         [,1]\n[1,] 2600.790\n[2,] 1373.156\n[3,] 1451.359\n\n\nYou might have noticed the data type of the st_distance objects are an S3 class of units. Sometimes, this class can cause problems when trying to using it with other classes or methods:\n\n\nCode\nbig3$dist_to_fc + 4\n\n\nError in Ops.units(big3$dist_to_fc, 4): both operands of the expression should be \"units\" objects\n\n\nCode\nggplot(data = big3) + \n  geom_col(aes(x = city, y = dist_to_fc))\n\n\nWarning: The `scale_name` argument of `continuous_scale()` is deprecated as of ggplot2\n3.5.0.\n\n\n\n\n\n\n\n\n\nIn these cases, the units class can be dropped with units::drop_units\n\n\nCode\nbig3 &lt;- mutate(big3, \n              dist_to_fc = st_distance(big3, fc),\n              dist_to_fc = set_units(dist_to_fc, \"km\"),\n              dist_to_fc = drop_units(dist_to_fc))\n\nbig3$dist_to_fc + 4\n\n\n         [,1]\n[1,] 2604.790\n[2,] 1377.156\n[3,] 1455.359\n\n\nCode\nggplot(data = big3) + \n  geom_col(aes(x = reorder(city, -dist_to_fc), y = dist_to_fc)) + \n    labs(title = \"Distance to Santa Barbara (km)\") + \n  ggthemes::theme_fivethirtyeight() + \n  theme( axis.text.x = element_text(face = \"bold\", size = 14))\n\n\n\n\n\n\n\n\n\nAs with all functions, these steps can be nested:\n\n\nCode\nbig3 = mutate(big3, \n              dist_to_fc = drop_units(set_units(st_distance(big3, fc), \"km\")))\n\n\n\n\n\nGeometry review\nThere are a few ways to manipulate existing geometries, here we discuss st_union(), st_combine() and st_cast()\n\nst_combine() returns a single, combined geometry, with no resolved boundaries.\nst_union() returns a single geometry with resolved boundaries\nst_cast() casts one geometry type to another\n\n\n\nCode\n(rockies = USAboundaries::us_states() |&gt; \n  filter(name %in% c('Montana', 'Wyoming', 'Colorado', \"New Mexico\")) |&gt; \n  select(name, geometry))\n\n\nSimple feature collection with 4 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n        name                       geometry\n1    Montana MULTIPOLYGON (((-116.0492 4...\n2   Colorado MULTIPOLYGON (((-109.06 38....\n3    Wyoming MULTIPOLYGON (((-111.0569 4...\n4 New Mexico MULTIPOLYGON (((-109.0492 3...\n\n\nCode\nplot(rockies['name'], key.pos = 1)\n\n\n\n\n\n\n\n\n\nCode\n# Combine Geometries\n(combined_rk = st_combine(rockies))\n\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n\n\nMULTIPOLYGON (((-116.0492 49.00091, -115.501 49...\n\n\nCode\nplot(combined_rk, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\n# Unioned Geometries\n(unioned_rk = st_union(rockies))\n\n\nGeometry set for 1 feature \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -116.0492 ymin: 31.33232 xmax: -102.0419 ymax: 49.00139\nGeodetic CRS:  WGS 84\n\n\nPOLYGON ((-109.0601 38.27549, -109.0418 38.1646...\n\n\nCode\nplot(unioned_rk, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\n# Combine Geometries\nline_rk = st_cast(unioned_rk, \"MULTILINESTRING\")\nplot(line_rk, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 3:\nIn this section you will extend your growing ggplot skills to handle spatial data using ggrepl to label significant features; gghighlight to emphasize important criteria; and scaled color/fill to create chloropleth represnetations of variables. Below is some example code to provide an example of these tools in action:\n\nGet some data (review)\n\n\nCode\n# Define a state/region classifier and select the southern states\nstate.of.interest = data.frame(state = state.name, region = state.region) |&gt; \n  filter(region == \"South\") |&gt; \n  pull(state)\n\n# Get USA states in the southern region and transform to EPSG:5070\nstate = USAboundaries::us_states() |&gt; \n  filter(name %in% state.of.interest) |&gt; \n  st_transform(5070)\n\n# Get USA congressional districts in the southern region and transform to EPSG:5070\ndistricts =  USAboundaries::us_congressional() |&gt; \n  filter(state_name %in% state.of.interest) |&gt; \n  st_transform(5070)\n\n# Get the 10 most populous cities in the southern region and transform to EPSG:5070\nsub_cities = cities |&gt; \n  filter(state_name %in% state.of.interest) |&gt; \n  slice_max(population, n = 10) |&gt; \n  st_transform(5070)\n\n\n\n\nMap\n\n\nCode\nggplot() + \n  # Add districts with a dashed line (lty = 3), \n  # a color gradient from blue to red based on aland, \n  # and a fill aplha of 0.5\n  geom_sf(data = districts, aes(fill = aland), lty = 3, alpha = .5) + \n  scale_fill_gradient(low = 'blue', high = \"red\") +\n  # Highlight (keep blue) only those districts witn a land area &gt; 5e10\n  gghighlight(aland &gt; 5e10) +\n  # Add the state borders with a thicker line and no fill\n  geom_sf(data = state, size = 1, fill = \"NA\") +\n  # Add the cities\n  geom_sf(data = sub_cities, size= 2, color = \"red\") +\n  # Add labels to the cities\n  ggrepel::geom_label_repel(\n    data = sub_cities,\n    aes(label = city, geometry = geometry),\n    stat = \"sf_coordinates\",\n    size = 3) +\n  labs(caption = \"Disticts with &gt; 5e10 Area Land are highlighted\",\n       fill = \"Area Land\") + \n  ggthemes::theme_map()"
  },
  {
    "objectID": "slides/week-2.html#simple-features",
    "href": "slides/week-2.html#simple-features",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features"
  },
  {
    "objectID": "slides/week-2.html#todays-data",
    "href": "slides/week-2.html#todays-data",
    "title": "Week 2",
    "section": "Todays Data:",
    "text": "Todays Data:\n\nSimple feature collection with 64 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   geoid       name      aland state_nm                       geometry\n1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3..."
  },
  {
    "objectID": "slides/week-2.html#simple-features-1",
    "href": "slides/week-2.html#simple-features-1",
    "title": "Week 2",
    "section": "Simple Features",
    "text": "Simple Features\n\nSimple feature geometries describe the geometries of features.\nThe main application of simple feature geometries is to describe 2D geometries as points, lines, or polygons.\n‚Äúsimple‚Äù refers to the fact that line or polygon geometries are represented by set of points connected with straight lines.\nSimple features access is a standard (Herring 2011, Herring (2010), ISO (2004)) for describing simple feature geometries via:\n\na class hierarchy\na set of operations\nbinary and text encodings"
  },
  {
    "objectID": "slides/week-2.html#simple-features-access",
    "href": "slides/week-2.html#simple-features-access",
    "title": "Week 2",
    "section": "Simple Features Access",
    "text": "Simple Features Access\n\nSimple features or simple feature access refers to the formal standard (ISO 19125-1:2004) describing how objects in the real world can be represented in computers, with emphasis on the spatial geometry of these objects.\nIt also describes how objects can be stored in and retrieved from databases, and which geometrical operations should/can be defined for them.\nThe standard is widely implemented in spatial databases (such as PostGIS), commercial GIS (e.g., ESRI ArcGIS) and forms the vector data basis for libraries such as GDAL.\nA subset of simple features (e.g.¬†the big 7) forms the GeoJSON specification.\nR has well-supported classes for storing spatial data (sp) and interfacing to the above mentioned environments (rgdal, rgeos), but has so far lacked a complete implementation of simple features, making conversions at times convoluted, inefficient or incomplete.\nsf is seeking to fill this gap and has/will succeed sp"
  },
  {
    "objectID": "slides/week-2.html#so-what-is-a-feature",
    "href": "slides/week-2.html#so-what-is-a-feature",
    "title": "Week 2",
    "section": "So what is a feature?",
    "text": "So what is a feature?\n\nA feature is a thing (object) in the real world, such as a building or a river\nThey often consist of other objects.\n\nA river system can be a feature, a river can be a feature, a river outlet can be a feature.\nA image pixel can be a feature, and the image can be a feature‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#spatial-features",
    "href": "slides/week-2.html#spatial-features",
    "title": "Week 2",
    "section": "Spatial Features",
    "text": "Spatial Features\n\nThe standard says: ‚ÄúA simple feature is defined by the OpenGIS Abstract specification to have both spatial and non-spatial attributes. Spatial attributes are geometry valued, and simple features are based on 2D geometry with linear interpolation between vertices.‚Äù - standard.\nSpatial Features have a geometry describing where the feature is located and how it is represented.\n\n\nstr(co$geometry)\nsfc_MULTIPOLYGON of length 64; first list element: List of 1\n $ :List of 1\n  ..$ : num [1:132, 1:2] -105 -105 -105 -105 -105 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n\n\nThe geometry of a river can be its watershed, of its mainstem, or the point it drains to (see the OGC HY_Feature standard)\nFeatures can have attributes describing other properties of the feature\nOther properties may include its length, slope, stream order or average flowrate"
  },
  {
    "objectID": "slides/week-2.html#geometry-types",
    "href": "slides/week-2.html#geometry-types",
    "title": "Week 2",
    "section": "Geometry types",
    "text": "Geometry types\nThe following 7 simple feature types are the most common, and are the only ones used for GeoJSON:"
  },
  {
    "objectID": "slides/week-2.html#dimensions",
    "href": "slides/week-2.html#dimensions",
    "title": "Week 2",
    "section": "Dimensions",
    "text": "Dimensions\nAll geometries are composed of points\n\nPoints are defined by coordinates in a 2-, 3- or 4-D space.\nIn addition to XY coordinates, there are two optional dimensions:\na Z coordinate, denoting altitude\nan M coordinate (rarely used), denoting some measure\nThe M describes a property of the vertex that is independent of the feature.\nIt sounds attractive to encode a time as M, however these quickly become invalid once the path self-intersects.\nBoth Z and M are found relatively rarely, and software support to do something useful with them is rarer still."
  },
  {
    "objectID": "slides/week-2.html#valid-geometries",
    "href": "slides/week-2.html#valid-geometries",
    "title": "Week 2",
    "section": "Valid geometries",
    "text": "Valid geometries\nValid geometries obey the following properties:\n\nLINESTRINGS shall not self-intersect\nPOLYGON rings shall be closed (last point = first point)\nPOLYGON holes (inner rings) shall be inside their exterior ring\nPOLYGON inner rings shall maximally touch the exterior ring in single points, not over a line\nPOLYGON rings shall not repeat their own path\n\nIf any of the above is not the case, the geometry is not valid."
  },
  {
    "objectID": "slides/week-2.html#non-simple-and-non-valid-geometries",
    "href": "slides/week-2.html#non-simple-and-non-valid-geometries",
    "title": "Week 2",
    "section": "Non-simple and non-valid geometries",
    "text": "Non-simple and non-valid geometries\nst_is_simple and st_is_valid provide methods to help detect non-simple and non-valid geometries:\n\nAn example of a non-simple geometries is a self-intersecting lines;\n\n\n(x1 &lt;- st_linestring(cbind(c(0,1,0,1),c(0,1,1,0))))\nLINESTRING (0 0, 1 1, 0 1, 1 0)\nst_is_simple(x1)\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\n\nAn example of a non-valid geometry are would be a polygon with slivers or self-intersections.\n\n\n(x2 &lt;- st_polygon(list(cbind(c(0,1,1,1,0,0),c(0,0,1,0.6,1,0)))))\nPOLYGON ((0 0, 1 0, 1 1, 1 0.6, 0 1, 0 0))\n(x3 &lt;- st_polygon(list(cbind(c(0,1,0,1,0),c(0,1,1,0,0)))))\nPOLYGON ((0 0, 1 1, 0 1, 1 0, 0 0))\n\nst_is_valid(c(x2,x3))\n[1] FALSE"
  },
  {
    "objectID": "slides/week-2.html#empty-geometries",
    "href": "slides/week-2.html#empty-geometries",
    "title": "Week 2",
    "section": "Empty Geometries",
    "text": "Empty Geometries\n\nAn important concept in the feature geometry framework is the empty geometry.\nempty geometries serve similar purposes as NA values in vectors (placeholder)\nEmpty geometries arise naturally from geometrical operations, for instance:\n\n\n(e = st_intersection(st_point(c(0,0)), st_point(c(1,1))))\nGEOMETRYCOLLECTION EMPTY\n\n\nIt is not entirely clear what the benefit is of having typed empty geometries, but according to the simple feature standard they are type so the sf package abides by that.\nEmpty geometries can be detected by:\n\n\nst_is_empty(e)\n[1] TRUE"
  },
  {
    "objectID": "slides/week-2.html#so",
    "href": "slides/week-2.html#so",
    "title": "Week 2",
    "section": "So:",
    "text": "So:\n\nThere are 17 typed geometries supported by the simple feature standard\nAll geometries are made up of points\npoints can exist in 2,3,4 Dinimsonal space\nLINESTRING and POLYGON geometries have rules that define validity\nGeometries can be empty (but are still typed)"
  },
  {
    "objectID": "slides/week-2.html#wkt-and-wkb",
    "href": "slides/week-2.html#wkt-and-wkb",
    "title": "Week 2",
    "section": "WKT and WKB",
    "text": "WKT and WKB\nThe simple feature standard includes two encodings:\nWell-known text (WKT) & well-known binary (WKB)\nWell Known Text is human-readable:\n\nx &lt;- st_linestring(matrix(10:1,5))\nst_as_text(x)\n[1] \"LINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\"\n\nIn this example,\nThe word LINESTRING provides the geometry type which is followed by a parentheses, inside the parentheses are the points that make up the geometry.\nSeparate points are separated by a ‚Äúcomma‚Äù, while the point coordinates are separated by a ‚Äúspace.‚Äù\nCoordinates are usually floating point numbers, and moving large amounts of information as text is slow and imprecise.\nFor that reason, we use well-known binary (WKB) encoding\n\nx\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\nst_as_binary(x)\n [1] 01 02 00 00 00 05 00 00 00 00 00 00 00 00 00 24 40 00 00 00 00 00 00 14 40\n[26] 00 00 00 00 00 00 22 40 00 00 00 00 00 00 10 40 00 00 00 00 00 00 20 40 00\n[51] 00 00 00 00 00 08 40 00 00 00 00 00 00 1c 40 00 00 00 00 00 00 00 40 00 00\n[76] 00 00 00 00 18 40 00 00 00 00 00 00 f0 3f\n\n\nBinary conversion is used to communicate geometries to external libraries (GDAL, GEOS, liblwgeom) and spatial databases because it is fast and lossless.\nWKT and WKB can both be transformed back into R native objects by\n\n\nst_as_sfc(\"LINESTRING(10 5, 9 4, 8 3, 7 2, 6 1)\")[[1]]\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\nst_as_sfc(structure(list(st_as_binary(x)), class = \"WKB\"))[[1]]\nLINESTRING (10 5, 9 4, 8 3, 7 2, 6 1)\n\nConversion between R native objects and WKB is done by package sf in compiled (C++/Rcpp) code, making this a reusable and fast route for I/O of simple feature geometries in R."
  },
  {
    "objectID": "slides/week-2.html#how-simple-features-are-organized-in-r",
    "href": "slides/week-2.html#how-simple-features-are-organized-in-r",
    "title": "Week 2",
    "section": "How simple features are organized in R?",
    "text": "How simple features are organized in R?\n\nSimple Features is a standard that is implemented in R (not limited to R)\nSo far we have discusses simple features the standard, rather then simple features the implementation\nIn R, simple features are implemented using standard data structures (S3 classes, lists, matrix, vector).\nAttributes are stored in data.frames (or tbl_df)\nFeature geometries are stored in a data.frame column.\nSince geometries are not single-valued, they are put in a list-column\nThis means each observation (element) is a list itself!\n\nRemember our nested lists?\n\nlist(list(c(1:5)))\n[[1]]\n[[1]][[1]]\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "slides/week-2.html#sf-sfc-sfg",
    "href": "slides/week-2.html#sf-sfc-sfg",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\nThe three classes are used to represent simple feature obejcts are:\n\nsf: data.frame with feature attributes and geometries\n\nwhich is composed of\n\nsfc: the list-column with the geometries for each feature\n\nwhich is composed of\n\nsfg, individual simple feature geometries"
  },
  {
    "objectID": "slides/week-2.html#sf-sfc-sfg-1",
    "href": "slides/week-2.html#sf-sfc-sfg-1",
    "title": "Week 2",
    "section": "sf, sfc, sfg",
    "text": "sf, sfc, sfg\n\nIn the output we see:\n\nin green a simple feature: a single record (row, consisting of attributes and geometry\nin blue a single simple feature geometry (an object of class sfg)\nin red a simple feature list-column (an object of class sfc, which is a column in the data.frame)\n\nEven though geometries are native R objects, they are printed as well-known text"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-blue",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-blue",
    "title": "Week 2",
    "section": "sfg: simple feature geometry (blue)",
    "text": "sfg: simple feature geometry (blue)\n\n\nSimple feature geometry (sfg) objects carry the geometry for a single feature\nSimple feature geometries are implemented as R native data, using the following rules\n\na single POINT is a numeric vector\na set of points (e.g.¬†in a LINESTRING or ring of a POLYGON) is a matrix, each row containing a point\nany other set is a list\n\n\nlist of numeric matrices for MULTILINESTRING and POLYGON\nlist of lists of numeric matrices for MULTIPOLYGON\nlist of (typed) geometries for GEOMETRYCOLLECTION"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry",
    "href": "slides/week-2.html#sfg-simple-feature-geometry",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nCreator functions are rarely used in practice, since we typically read existing spatial data. But, they are useful for illustration:\n\n(x &lt;- st_point(c(1,2)))\nPOINT (1 2)\nstr(x)\n 'XY' num [1:2] 1 2\n(x &lt;- st_linestring(matrix(c(1,2,3,4), ncol=2)))\nLINESTRING (1 3, 2 4)\nstr(x)\n 'XY' num [1:2, 1:2] 1 2 3 4"
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-1",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-1",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAll geometry objects have a S3 class indicating their (1) dimension, (2) type, and (3) superclass\n\n(pt = st_point(c(0,1)))\nPOINT (0 1)\nattributes(pt)\n$class\n[1] \"XY\"    \"POINT\" \"sfg\"  \n\n(pt2 = st_point(c(0,1,4)))\nPOINT Z (0 1 4)\nattributes(pt2)\n$class\n[1] \"XYZ\"   \"POINT\" \"sfg\""
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-2",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-2",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\n\n\n\n(m1 = rbind(c(8, 1), c(2, 5), c(3, 2)))\n     [,1] [,2]\n[1,]    8    1\n[2,]    2    5\n[3,]    3    2\n\n(mp = st_multipoint(m1))\nMULTIPOINT ((8 1), (2 5), (3 2))\nattributes(mp)\n$dim\n[1] 3 2\n\n$class\n[1] \"XY\"         \"MULTIPOINT\" \"sfg\"       \n\n\n\n(ls = st_linestring(m1))\nLINESTRING (8 1, 2 5, 3 2)\nattributes(ls)\n$dim\n[1] 3 2\n\n$class\n[1] \"XY\"         \"LINESTRING\" \"sfg\""
  },
  {
    "objectID": "slides/week-2.html#sfg-simple-feature-geometry-3",
    "href": "slides/week-2.html#sfg-simple-feature-geometry-3",
    "title": "Week 2",
    "section": "sfg: simple feature geometry",
    "text": "sfg: simple feature geometry\nAlthough these geometries contain the same points (m1), they have entirely different meaning: the point set is a zero-dimensional, the line a one-dimensional geometry:\nHere, dimensions is no the XY vs XYZ, but rather whether the geometry has length (1D) or area (2D) or greater‚Ä¶\n\nst_dimension(mp)\n[1] 0\nst_length(mp)\n[1] 0\nst_dimension(ls)\n[1] 1\nst_length(ls)\n[1] 10.37338"
  },
  {
    "objectID": "slides/week-2.html#geometrycollection",
    "href": "slides/week-2.html#geometrycollection",
    "title": "Week 2",
    "section": "GEOMETRYCOLLECTION",
    "text": "GEOMETRYCOLLECTION\n\nSingle features can have a geometry that consists of several geometries of different types.\nSuch cases arise rather naturally when looking for intersections. For instance, the intersection of two LINESTRING geometries may be the combination of a LINESTRING and a POINT.\nPutting this intersection into a single feature geometry needs a GEOMETRYCOLLECTION\n\n\npt &lt;- st_point(c(1, 0))\nls &lt;- st_linestring(matrix(c(4, 3, 0, 0), ncol = 2))\npoly1 &lt;- st_polygon(list(matrix(c(5.5, 7, 7, 6, 5.5, 0, 0, -0.5, -0.5, 0), ncol = 2)))\npoly2 &lt;- st_polygon(list(matrix(c(6.6, 8, 8, 7, 6.6, 1, 1, 1.5, 1.5, 1), ncol = 2)))\nmultipoly &lt;- st_multipolygon(list(poly1, poly2))\n\n(j &lt;- st_geometrycollection(list(pt, ls, poly1, poly2, multipoly)))\nGEOMETRYCOLLECTION (POINT (1 0), LINESTRING (4 0, 3 0), POLYGON ((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), POLYGON ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)), MULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5 0)), ((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1))))\n\n\nIn case we end up with GEOMETRYCOLLECTION objects, the next question is often what to do with them. One thing we can do is extract elements from them:\n\n\nst_collection_extract(j, \"POLYGON\")\nGeometry set for 3 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 5.5 ymin: -0.5 xmax: 8 ymax: 1.5\nCRS:           NA\nMULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\nMULTIPOLYGON (((6.6 1, 8 1, 8 1.5, 7 1.5, 6.6 1)))\nMULTIPOLYGON (((5.5 0, 7 0, 7 -0.5, 6 -0.5, 5.5...\n\nst_collection_extract(j, \"POINT\")\nPOINT (1 0)\n\nst_collection_extract(j, \"LINESTRING\")\nLINESTRING (4 0, 3 0)"
  },
  {
    "objectID": "slides/week-2.html#sfc-sets-of-geometries",
    "href": "slides/week-2.html#sfc-sets-of-geometries",
    "title": "Week 2",
    "section": "sfc: sets of geometries",
    "text": "sfc: sets of geometries\n\nsf provides a dedicated class for handeling geometry sets, called sfc (simple feature geometry list column).\nWe can create such a list column with constructor function st_sfc:\n\n\n(sfc = st_sfc(st_point(c(0,1)), st_point(c(-3,2))))\nGeometry set for 2 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -3 ymin: 1 xmax: 0 ymax: 2\nCRS:           NA\nPOINT (0 1)\nPOINT (-3 2)\n\nThe default report from the print method for sfc gives\n\nthe number of features geometries\nthe feature geometry type (here: POINT)\nthe feature geometry dimension (here: XY)\nthe bounding box for the set\nthe coordinate reference system for the set (epsg and proj4string)\nthe first few geometries, as (abbreviated) WKT\n\nThe class of the geometry list-column is a combination of a specific class, and a superclass.\n\nclass(sfc)\n[1] \"sfc_POINT\" \"sfc\"      \n\nIn addition to a class, the sfc object has further attributes (remember S3 class!)\n\nattributes(sfc) |&gt; names()\n[1] \"class\"     \"precision\" \"bbox\"      \"crs\"       \"n_empty\"  \n\nwhich are used to record for the whole set:\n\na precision value\nthe bounding box enclosing all geometries (for x and y)\na coordinate reference system\nthe number of empty geometries contained in the set\n\nThis means that all these properties are defined for the set (sfc), and not for geometries (sfg) individually.\nsfc objects are lists with each entry being an sfg object:\n\np[[2]]\nPOINT (1 1)\n\nand we will use these lists as list columns in data.frame or tibble objects to represent simple features with geometries in a list column."
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    1    1\n[3,]    1    0\n[4,]    0    1"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-1",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-2",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc()\n\n\n\nGeometry set for 1 feature \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-3",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\")\n\n\n\nGeometry set for 4 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nPOINT (1 1)\nPOINT (1 0)\nPOINT (0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-4",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-5",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1))\n\n\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    1    1\n[3,]    1    0\n[4,]    0    1"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-6",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring()\n\n\n\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "href": "slides/week-2.html#sets-of-geometries-arise-when-we-separate-compound-geometries-7",
    "title": "Week 2",
    "section": "Sets of geometries arise when we separate compound geometries:",
    "text": "Sets of geometries arise when we separate compound geometries:\n\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_sfc() |&gt;\n   st_cast(\"POINT\") -&gt;\n  p\n\n\nrbind(c(0,0), c(1,1), c(1,0), c(0,1)) |&gt;\n   st_linestring() |&gt;\n   st_cast(\"POINT\")\n\n\n\nPOINT (0 0)\n\n\n\nOn the last slide, st_sfc creates a set of one LINESTRING (p), with a size of 4.\nGoing the other way around (from set to feature), we need to combine geometries:\n\n\n\n\np\nGeometry set for 4 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nPOINT (1 1)\nPOINT (1 0)\nPOINT (0 1)\n\n\n\nst_combine(p)\nGeometry set for 1 feature \nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nMULTIPOINT ((0 0), (1 1), (1 0), (0 1))"
  },
  {
    "objectID": "slides/week-2.html#casting-must-be-done-the-level-of-the-feature",
    "href": "slides/week-2.html#casting-must-be-done-the-level-of-the-feature",
    "title": "Week 2",
    "section": "Casting must be done the level of the feature",
    "text": "Casting must be done the level of the feature\nIf we want to go from the 4 feature (p) object to a 1 feature LINESTRING, we must combine before casting ‚Ä¶\n\nst_combine(p) |&gt; \n  st_cast(\"LINESTRING\")\nGeometry set for 1 feature \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nLINESTRING (0 0, 1 1, 1 0, 0 1)"
  },
  {
    "objectID": "slides/week-2.html#mixed-geometries",
    "href": "slides/week-2.html#mixed-geometries",
    "title": "Week 2",
    "section": "Mixed geometries",
    "text": "Mixed geometries\nSets of simple features also consist of features with heterogeneous geometries. In this case, the geometry type of the set is GEOMETRY:\n.pull-left[\n\n(g = st_sfc(st_point(c(0,0)), \n            st_linestring(rbind(c(0,0), c(1,1)))))\nGeometry set for 2 features \nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\nPOINT (0 0)\nLINESTRING (0 0, 1 1)\n\n]\n.pull-right[ These set can be filtered by using st_is\n\ng |&gt; st_is(\"LINESTRING\")\n[1] FALSE  TRUE\n\nor, when working with sf objects,\n\n# Note need of %&gt;%\nst_sf(g) %&gt;%\n  filter(st_is(., \"LINESTRING\"))\nSimple feature collection with 1 feature and 0 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1\nCRS:           NA\n                      g\n1 LINESTRING (0 0, 1 1)\n\n]"
  },
  {
    "objectID": "slides/week-2.html#sf-objects-with-simple-features",
    "href": "slides/week-2.html#sf-objects-with-simple-features",
    "title": "Week 2",
    "section": "sf: objects with simple features",
    "text": "sf: objects with simple features\nSimple features geometries and feature attributes are put together in sf (simple feature) objects.\n\nco\nSimple feature collection with 64 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   geoid       name      aland state_nm                       geometry\n1  08001      Adams 3021840487 Colorado MULTIPOLYGON (((-105.0532 3...\n2  08003    Alamosa 1871643028 Colorado MULTIPOLYGON (((-105.4855 3...\n3  08005   Arapahoe 2066438714 Colorado MULTIPOLYGON (((-103.7065 3...\n4  08007  Archuleta 3496712164 Colorado MULTIPOLYGON (((-107.1287 3...\n5  08009       Baca 6617400567 Colorado MULTIPOLYGON (((-102.0416 3...\n6  08011       Bent 3918255148 Colorado MULTIPOLYGON (((-102.7476 3...\n7  08013    Boulder 1881325109 Colorado MULTIPOLYGON (((-105.3978 3...\n8  08014 Broomfield   85386685 Colorado MULTIPOLYGON (((-105.1092 3...\n9  08015    Chaffee 2624715692 Colorado MULTIPOLYGON (((-105.9698 3...\n10 08017   Cheyenne 4605713960 Colorado MULTIPOLYGON (((-103.1729 3...\n\nThis sf object is of class\n\nclass(co)\n[1] \"sf\"         \"data.frame\"\n\nmeaning it extends data.frame, but with a single list-column with geometries, which is held in the column named:\n\nattr(co, \"sf_column\")\n[1] \"geometry\""
  },
  {
    "objectID": "slides/week-2.html#sfc-simple-feature-geometry-list-column",
    "href": "slides/week-2.html#sfc-simple-feature-geometry-list-column",
    "title": "Week 2",
    "section": "sfc: simple feature geometry list-column",
    "text": "sfc: simple feature geometry list-column\nThe column in the sf data.frame that contains the geometries is a list, of class sfc.\nWe can retrieve the geometry list-column as we would any data.frame column (e.g.¬†ca$geometry), or more generally with st_geometry:\n\n(co_geom &lt;- st_geometry(co))\nGeometry set for 64 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -109.0602 ymin: 36.99246 xmax: -102.0415 ymax: 41.00342\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\nMULTIPOLYGON (((-105.0532 39.79106, -104.976 39...\nMULTIPOLYGON (((-105.4855 37.5779, -105.4859 37...\nMULTIPOLYGON (((-103.7065 39.73989, -103.7239 3...\nMULTIPOLYGON (((-107.1287 37.42294, -107.2803 3...\nMULTIPOLYGON (((-102.0416 37.64428, -102.0558 3...\n\nGeometries are printed in abbreviated form, but we can view a complete geometry by selecting it:\n\nco_geom[[1]]\nMULTIPOLYGON (((-105.0532 39.79106, -104.976 39.79104, -104.9731 39.79242, -104.9716 39.79829, -104.9687 39.7984, -104.9689 39.79104, -104.9602 39.79102, -104.9554 39.79463, -104.9405 39.7946, -104.9405 39.791, -104.927 39.79105, -104.927 39.78378, -104.9034 39.78381, -104.9036 39.79839, -104.8845 39.79832, -104.8844 39.81282, -104.8661 39.81285, -104.866 39.79839, -104.8291 39.79806, -104.7909 39.79825, -104.7909 39.8418, -104.7623 39.84179, -104.7623 39.84539, -104.731 39.84519, -104.7304 39.89613, -104.7033 39.89595, -104.7032 39.90693, -104.6921 39.90685, -104.6921 39.91418, -104.6796 39.91402, -104.6797 39.90701, -104.6309 39.90664, -104.6309 39.89929, -104.5996 39.89904, -104.5998 39.88131, -104.6052 39.88135, -104.6053 39.87311, -104.6192 39.87322, -104.6198 39.82242, -104.6554 39.82261, -104.6554 39.813, -104.6662 39.81307, -104.6661 39.82279, -104.7625 39.82344, -104.7626 39.79843, -104.7344 39.79844, -104.7346 39.76918, -104.7646 39.76919, -104.7646 39.77157, -104.7722 39.7715, -104.7722 39.77641, -104.7816 39.77648, -104.7816 39.7728, -104.8282 39.77278, -104.8282 39.76916, -104.833 39.76918, -104.8376 39.76717, -104.8564 39.76858, -104.8563 39.75813, -104.8482 39.75642, -104.8469 39.75469, -104.8799 39.75473, -104.88 39.74744, -104.8847 39.74747, -104.8846 39.74016, -104.8217 39.74029, -104.7256 39.74027, -104.6783 39.74, -104.6603 39.74048, -104.6528 39.73978, -104.6304 39.7395, -104.6246 39.74008, -104.5589 39.73933, -104.5074 39.73825, -104.3919 39.73804, -104.3401 39.73825, -104.265 39.73888, -104.2095 39.73902, -104.1151 39.73977, -104.0407 39.73998, -103.9776 39.74027, -103.9655 39.74052, -103.9075 39.74065, -103.8661 39.74024, -103.8002 39.7402, -103.794 39.74005, -103.7239 39.73978, -103.7065 39.73989, -103.7066 39.76555, -103.7063 39.82855, -103.7063 39.889, -103.7061 39.90854, -103.7062 39.95888, -103.7057 39.98511, -103.7057 40.00137, -103.8677 40.0012, -103.9546 40.00113, -104.0371 40.00113, -104.1503 40.00086, -104.1693 40.00078, -104.2674 40.00092, -104.3015 40.00077, -104.4523 40.00062, -104.6019 40.00053, -104.6406 40.00057, -104.7885 40.00041, -104.9048 40.00032, -104.9614 40.00034, -104.9809 40.00032, -104.9877 39.98648, -104.9878 39.97575, -104.9944 39.9758, -104.9971 39.97215, -104.9881 39.97218, -104.9881 39.96847, -104.9972 39.96853, -104.9974 39.98121, -105.0158 39.98119, -105.0156 39.95519, -105.0171 39.95281, -105.0122 39.95045, -105.0063 39.95044, -105.0063 39.9468, -104.9972 39.94677, -104.9971 39.94324, -105.0157 39.94313, -105.0155 39.9214, -105.0344 39.9213, -105.0343 39.91418, -105.0529 39.91422, -105.0532 39.86362, -105.0532 39.79106)))"
  },
  {
    "objectID": "slides/week-2.html#reading-and-writing",
    "href": "slides/week-2.html#reading-and-writing",
    "title": "Week 2",
    "section": "Reading and writing",
    "text": "Reading and writing\nAs we‚Äôve seen above, reading spatial data from an external file can be done via sf - reading data requires the ‚Äúparser function‚Äù and the file path\n\nco &lt;- st_read(\"data/co.shp\")\n\nwe can suppress the output by adding argument quiet=TRUE or by using the otherwise nearly identical but more quiet\n\nca &lt;- read_sf(\"data/co.shp\")\n\nWriting takes place in the same fashion, using st_write:\n\nst_write(co, \"data/co.shp\")\n\nor its quiet alternative that silently overwrites existing files by default,\n\nwrite_sf(co, \"co.shp\") # silently overwrites"
  },
  {
    "objectID": "slides/week-2.html#from-tables-e.g.-csv",
    "href": "slides/week-2.html#from-tables-e.g.-csv",
    "title": "Week 2",
    "section": "From Tables (e.g.¬†CSV)",
    "text": "From Tables (e.g.¬†CSV)\nSpatial data can also be created from CSV and other flat files once it is in R:\n\n(cities = readr::read_csv(\"../labs/data/uscities.csv\") |&gt; \n  select(city, state_name, county_name, population, lat, lng) )\n# A tibble: 31,254 √ó 6\n   city         state_name           county_name         population   lat    lng\n   &lt;chr&gt;        &lt;chr&gt;                &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 New York     New York             Queens                18832416  40.7  -73.9\n 2 Los Angeles  California           Los Angeles           11885717  34.1 -118. \n 3 Chicago      Illinois             Cook                   8489066  41.8  -87.7\n 4 Miami        Florida              Miami-Dade             6113982  25.8  -80.2\n 5 Houston      Texas                Harris                 6046392  29.8  -95.4\n 6 Dallas       Texas                Dallas                 5843632  32.8  -96.8\n 7 Philadelphia Pennsylvania         Philadelphia           5696588  40.0  -75.1\n 8 Atlanta      Georgia              Fulton                 5211164  33.8  -84.4\n 9 Washington   District of Columbia District of Columb‚Ä¶    5146120  38.9  -77.0\n10 Boston       Massachusetts        Suffolk                4355184  42.3  -71.1\n# ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2.html#data-manipulation",
    "href": "slides/week-2.html#data-manipulation",
    "title": "Week 2",
    "section": "Data Manipulation",
    "text": "Data Manipulation\nSince sf objects are data.frames, our dplyr verbs work!\nLets find the most populous city in each California county‚Ä¶"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr",
    "href": "slides/week-2.html#sf-and-dplyr",
    "title": "Week 2",
    "section": "##sf and dplyr",
    "text": "##sf and dplyr\n\n\n\ncities_sf\n\n\n\nSimple feature collection with 31254 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -176.6295 ymin: 17.9559 xmax: 174.111 ymax: 71.2727\nGeodetic CRS:  WGS 84\n# A tibble: 31,254 √ó 5\n   city         state_name      county_name population            geometry\n * &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 New York     New York        Queens        18832416  (-73.9249 40.6943)\n 2 Los Angeles  California      Los Angeles   11885717 (-118.4068 34.1141)\n 3 Chicago      Illinois        Cook           8489066  (-87.6866 41.8375)\n 4 Miami        Florida         Miami-Dade     6113982   (-80.2101 25.784)\n 5 Houston      Texas           Harris         6046392   (-95.3885 29.786)\n 6 Dallas       Texas           Dallas         5843632  (-96.7667 32.7935)\n 7 Philadelphia Pennsylvania    Philadelph‚Ä¶    5696588  (-75.1339 40.0077)\n 8 Atlanta      Georgia         Fulton         5211164   (-84.422 33.7628)\n 9 Washington   District of Co‚Ä¶ District o‚Ä¶    5146120  (-77.0163 38.9047)\n10 Boston       Massachusetts   Suffolk        4355184  (-71.0852 42.3188)\n# ‚Ñπ 31,244 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-1",
    "href": "slides/week-2.html#sf-and-dplyr-1",
    "title": "Week 2",
    "section": "##sf and dplyr",
    "text": "##sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\")\n\n\n\nSimple feature collection with 477 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 477 √ó 5\n   city             state_name county_name population            geometry\n * &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n 2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n 3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n 5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n 6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n 7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n 8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n 9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n# ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-2",
    "href": "slides/week-2.html#sf-and-dplyr-2",
    "title": "Week 2",
    "section": "##sf and dplyr",
    "text": "##sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name)\n\n\n\nSimple feature collection with 477 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -109.0066 ymin: 37.0155 xmax: -102.0804 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 477 √ó 5\n# Groups:   county_name [64]\n   city             state_name county_name population            geometry\n   &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Denver           Colorado   Denver         2691349  (-104.8758 39.762)\n 2 Colorado Springs Colorado   El Paso         638421 (-104.7605 38.8674)\n 3 Aurora           Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Fort Collins     Colorado   Larimer         339256 (-105.0656 40.5477)\n 5 Lakewood         Colorado   Jefferson       156309 (-105.1172 39.6977)\n 6 Greeley          Colorado   Weld            143554 (-104.7706 40.4152)\n 7 Thornton         Colorado   Adams           142878 (-104.9438 39.9197)\n 8 Grand Junction   Colorado   Mesa            141008 (-108.5673 39.0877)\n 9 Arvada           Colorado   Jefferson       122835   (-105.151 39.832)\n10 Boulder          Colorado   Boulder         120121 (-105.2524 40.0248)\n# ‚Ñπ 467 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-3",
    "href": "slides/week-2.html#sf-and-dplyr-3",
    "title": "Week 2",
    "section": "##sf and dplyr",
    "text": "##sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1)\n\n\n\nSimple feature collection with 64 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -108.9071 ymin: 37.1751 xmax: -102.2627 ymax: 40.9849\nGeodetic CRS:  WGS 84\n# A tibble: 64 √ó 5\n# Groups:   county_name [64]\n   city           state_name county_name population            geometry\n   &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;            &lt;dbl&gt;         &lt;POINT [¬∞]&gt;\n 1 Thornton       Colorado   Adams           142878 (-104.9438 39.9197)\n 2 Alamosa        Colorado   Alamosa           9847  (-105.877 37.4752)\n 3 Aurora         Colorado   Arapahoe        390201 (-104.7237 39.7083)\n 4 Pagosa Springs Colorado   Archuleta         1718 (-107.0307 37.2675)\n 5 Springfield    Colorado   Baca              1482  (-102.6189 37.405)\n 6 Las Animas     Colorado   Bent              2480 (-103.2236 38.0695)\n 7 Boulder        Colorado   Boulder         120121 (-105.2524 40.0248)\n 8 Broomfield     Colorado   Broomfield       75110 (-105.0526 39.9542)\n 9 Salida         Colorado   Chaffee           5786 (-105.9979 38.5298)\n10 Cheyenne Wells Colorado   Cheyenne           949 (-102.3521 38.8192)\n# ‚Ñπ 54 more rows"
  },
  {
    "objectID": "slides/week-2.html#sf-and-dplyr-4",
    "href": "slides/week-2.html#sf-and-dplyr-4",
    "title": "Week 2",
    "section": "##sf and dplyr",
    "text": "##sf and dplyr\n\n\n\ncities_sf |&gt;\n  filter(state_name == \"Colorado\") |&gt;\n  group_by(county_name) |&gt;\n  slice_max(population, n = 1) -&gt;\n  co_cities"
  },
  {
    "objectID": "slides/week-2.html#plotting",
    "href": "slides/week-2.html#plotting",
    "title": "Week 2",
    "section": "Plotting",
    "text": "Plotting\nWe‚Äôve already seen that ggplot() is a powerful visualization tool:\n‚Äì\nThe 5 steps we described for building a ggplot are: 1. canvas 2. layers (geoms) 3. labels 4. facets 5. themes\n‚Äì\nspatial work in R is becoming so common that ggplot() comes with a sf geom (geom_sf)"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot",
    "href": "slides/week-2.html#sf-an-ggplot",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot()"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-1",
    "href": "slides/week-2.html#sf-an-ggplot-1",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10))"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-2",
    "href": "slides/week-2.html#sf-an-ggplot-2",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\")"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-3",
    "href": "slides/week-2.html#sf-an-ggplot-3",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw()"
  },
  {
    "objectID": "slides/week-2.html#sf-an-ggplot-4",
    "href": "slides/week-2.html#sf-an-ggplot-4",
    "title": "Week 2",
    "section": "##sf an ggplot",
    "text": "##sf an ggplot\n\n\n\nggplot() +\n  geom_sf(data = co, aes(fill = aland/1e10)) +\n  geom_sf(data = co_cities, aes(size = population/1e5), col = \"red\") +\n  theme_linedraw() +\n  labs(title = \"California Counties: Land Area\",\n       size = \"Population \\n(100,000)\",\n       fill = \"Acres \\n(billions)\")"
  }
]